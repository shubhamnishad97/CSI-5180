{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering on COVID-bert",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c29a0fae89e341fcb2ee6f4a26c64386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7648f2f17a9e45eba74daf21b9d1b55c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_514418aa8ee944daaeb48079b6d978f5",
              "IPY_MODEL_a8d748693b5743a3ad13ac30dc71be71"
            ]
          }
        },
        "7648f2f17a9e45eba74daf21b9d1b55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "514418aa8ee944daaeb48079b6d978f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7a41501698c45d8b948ffd342e7fd45",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1754,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1754,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09114db8caec47aa92e08aea42df439e"
          }
        },
        "a8d748693b5743a3ad13ac30dc71be71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83fd7f852adf4188b51d0518d004f0e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.61k/? [00:00&lt;00:00, 7.16kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1508c44ce886482f87ca1de08b68bfeb"
          }
        },
        "e7a41501698c45d8b948ffd342e7fd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09114db8caec47aa92e08aea42df439e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83fd7f852adf4188b51d0518d004f0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1508c44ce886482f87ca1de08b68bfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73b699a38bcb4c35996bccb7473504d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c05097371d145eb8066412c599d0a4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_843228158eeb4ae3a1b56545b3dd0220",
              "IPY_MODEL_3bbe850c129147e49cc4d419118fc738"
            ]
          }
        },
        "6c05097371d145eb8066412c599d0a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "843228158eeb4ae3a1b56545b3dd0220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c9f5a6f6d41345b4ac90e03f680eaabe",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 794,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 794,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a28a47e906d4ac9b87ffaa1aae54376"
          }
        },
        "3bbe850c129147e49cc4d419118fc738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dff5d4dba37d4557b5cc73d64027bc03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.80k/? [00:00&lt;00:00, 4.14kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_759b0e6ec3fb4bb9a8f4ee225edd53b9"
          }
        },
        "c9f5a6f6d41345b4ac90e03f680eaabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a28a47e906d4ac9b87ffaa1aae54376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dff5d4dba37d4557b5cc73d64027bc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "759b0e6ec3fb4bb9a8f4ee225edd53b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "434c95e550c4424b88917b0692ead130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7ee298c9ac54f3d89cf37f74d7f207c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88452636c65d486180313f1b8732106c",
              "IPY_MODEL_8865a71c5dce4e48921a282fc51a6240"
            ]
          }
        },
        "c7ee298c9ac54f3d89cf37f74d7f207c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88452636c65d486180313f1b8732106c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b18080d609d4f52bf896a04a761e29b",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1346251,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1346251,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_409963f7b3294cc8832f7cf436e5de4c"
          }
        },
        "8865a71c5dce4e48921a282fc51a6240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_644e1285bacf40699e534dececa46897",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.42M/? [00:00&lt;00:00, 24.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b2ac1b5fd9543efb18508dfc2f9b468"
          }
        },
        "0b18080d609d4f52bf896a04a761e29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "409963f7b3294cc8832f7cf436e5de4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "644e1285bacf40699e534dececa46897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b2ac1b5fd9543efb18508dfc2f9b468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86ef98aadf9043b09700f89a7dfa8fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e72bfdf462e643c4b69a1d1adee8c7da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19cf0b792cb94126805f8894009fee2a",
              "IPY_MODEL_d4b5d99f35cc4552b47a5830420b1d7a"
            ]
          }
        },
        "e72bfdf462e643c4b69a1d1adee8c7da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19cf0b792cb94126805f8894009fee2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_032b4a5a1ce24da3a366a42ec8ba5693",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a40b6e20001f4bcb9ef0fbbc22869c55"
          }
        },
        "d4b5d99f35cc4552b47a5830420b1d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8be8ade65444c119b2bb024bf68334b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2019/0 [00:03&lt;00:00,  3.66s/ examples]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d225ff2326964ca085b8ab59faa9655e"
          }
        },
        "032b4a5a1ce24da3a366a42ec8ba5693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a40b6e20001f4bcb9ef0fbbc22869c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8be8ade65444c119b2bb024bf68334b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d225ff2326964ca085b8ab59faa9655e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "014a9b48b7bd4b0cb04831499b0173f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a53527798ac3496d9399b25c617d0ae4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4a3f3332f704ff284e5e14d3afe2320",
              "IPY_MODEL_020de7be303645b0bbe806137f3dad39"
            ]
          }
        },
        "a53527798ac3496d9399b25c617d0ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4a3f3332f704ff284e5e14d3afe2320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ce7a13f77584ef7a0d2cea30cb2fc9e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 443,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 443,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13a5fe46d0c14be7b4bb194331f1e2e2"
          }
        },
        "020de7be303645b0bbe806137f3dad39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3bf37131e4e64475a46f46b85c86ba99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443/443 [00:00&lt;00:00, 4.30kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5add5f3de7db4948a9f0fb277749b37a"
          }
        },
        "5ce7a13f77584ef7a0d2cea30cb2fc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13a5fe46d0c14be7b4bb194331f1e2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bf37131e4e64475a46f46b85c86ba99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5add5f3de7db4948a9f0fb277749b37a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b50ff397a93340e1bbeb7950cfc3de37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32b50233f4c3450cac34fb8f79dedabb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c9dd6f05b2f43419785a33d8b358af0",
              "IPY_MODEL_2bd8509e7932452990cafd9ef291ada4"
            ]
          }
        },
        "32b50233f4c3450cac34fb8f79dedabb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c9dd6f05b2f43419785a33d8b358af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45172f24c6e14d07879a14270d16cb32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_636962744b0f4d53ac0ff620a8355f73"
          }
        },
        "2bd8509e7932452990cafd9ef291ada4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65750956a5a141359fd43b3efee58c8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 427kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac92c47363f44ffda7b74c28632fdf84"
          }
        },
        "45172f24c6e14d07879a14270d16cb32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "636962744b0f4d53ac0ff620a8355f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65750956a5a141359fd43b3efee58c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac92c47363f44ffda7b74c28632fdf84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67b13101a59a4598896ff9d4c83ade61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_070493f876f64a2aa2a9597d5b6cf722",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_244d4ea77d474b959d4bf7b9ff2d9e11",
              "IPY_MODEL_e1c0562ca6584f71aca428e130772b5b"
            ]
          }
        },
        "070493f876f64a2aa2a9597d5b6cf722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "244d4ea77d474b959d4bf7b9ff2d9e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_257f8a39caf24ac1a7f10aee595c6401",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3c577ce5c9349ba95d0d815116e3643"
          }
        },
        "e1c0562ca6584f71aca428e130772b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33ec052899eb4b35bea85f8ad07ff6f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.86MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_207ee75b131b48bfa8a4297d23afc2e0"
          }
        },
        "257f8a39caf24ac1a7f10aee595c6401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3c577ce5c9349ba95d0d815116e3643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33ec052899eb4b35bea85f8ad07ff6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "207ee75b131b48bfa8a4297d23afc2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "567703d6060a45118a6efa2e2b29e37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_775ebccebb6b4f6b8f7ddde1e645d87e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c99e68b379db4b6dbf257d1acdfd2c94",
              "IPY_MODEL_38ec474b87dc44648918ce0a7bf7bcae"
            ]
          }
        },
        "775ebccebb6b4f6b8f7ddde1e645d87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c99e68b379db4b6dbf257d1acdfd2c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d168d47c3d5444f5983f143942055567",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7353e7933e94cf99675480c0add5001"
          }
        },
        "38ec474b87dc44648918ce0a7bf7bcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e453be2efd74789a25669f2430225e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 237B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26499136517844578ea47e62dab86259"
          }
        },
        "d168d47c3d5444f5983f143942055567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7353e7933e94cf99675480c0add5001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e453be2efd74789a25669f2430225e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26499136517844578ea47e62dab86259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a391bae8cf674db19a56e76a9a0e6e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_636cf2193dfe41b391a7f5c8ee0b9fa5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bad6f190d934b169476df1c956b00bc",
              "IPY_MODEL_4e7ebf2efcf44a2c84ccc5da17e8c12c"
            ]
          }
        },
        "636cf2193dfe41b391a7f5c8ee0b9fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bad6f190d934b169476df1c956b00bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc2055df92e145409ce2b220167fa00a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb32a7bdd71e4cfd814f69ee4a35778d"
          }
        },
        "4e7ebf2efcf44a2c84ccc5da17e8c12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99fbd6c0e5454cf98fbb1740b63a2eb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:46&lt;00:00, 23.32s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_181a33e06f8f4263a410bddaa46eb724"
          }
        },
        "cc2055df92e145409ce2b220167fa00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb32a7bdd71e4cfd814f69ee4a35778d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99fbd6c0e5454cf98fbb1740b63a2eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "181a33e06f8f4263a410bddaa46eb724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a69873d19e8e4fa49f9da0249b8edfec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da5b8a2cb6544ef1ab93199bf113b467",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d56b641f88ba41338beca1f9f8ac5b51",
              "IPY_MODEL_485f281bf2014dde8a64b108b9fba61e"
            ]
          }
        },
        "da5b8a2cb6544ef1ab93199bf113b467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d56b641f88ba41338beca1f9f8ac5b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3d2689bf03d405aa338bb4f79ddd185",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b43c05520f2b46e184c409934ff478d8"
          }
        },
        "485f281bf2014dde8a64b108b9fba61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2508ba88497146c0a48f0583c8cb5811",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:37&lt;00:00, 37.30s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4b6252ca8004fde8d9fd1a0e882ad49"
          }
        },
        "a3d2689bf03d405aa338bb4f79ddd185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b43c05520f2b46e184c409934ff478d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2508ba88497146c0a48f0583c8cb5811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4b6252ca8004fde8d9fd1a0e882ad49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dae29fdaf221465fb5275bc68ffe4249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_881d4f499d30426fafb98b4e7c86bc44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b63b97a983b2429384dbd7808a4b6e89",
              "IPY_MODEL_72ebe7f523e346feb4a0e010f39803b3"
            ]
          }
        },
        "881d4f499d30426fafb98b4e7c86bc44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b63b97a983b2429384dbd7808a4b6e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1892919e03394937b92a8e815f479d1c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1340675298,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1340675298,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_705c4f40326746578e86746e9c35d07f"
          }
        },
        "72ebe7f523e346feb4a0e010f39803b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbf5457b46ca470a8e38f45ad8f0f41d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:23&lt;00:00, 58.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac652d6b62524661a507838e53c47e78"
          }
        },
        "1892919e03394937b92a8e815f479d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "705c4f40326746578e86746e9c35d07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbf5457b46ca470a8e38f45ad8f0f41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac652d6b62524661a507838e53c47e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02a19b3421134f009ffcdd3f7363c8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_462afead56fe46a08e87180ccede2e9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_361a61761f0c47898f76d4e68dfa64db",
              "IPY_MODEL_75c20667696c4f118cc723cd1e5d62d1"
            ]
          }
        },
        "462afead56fe46a08e87180ccede2e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "361a61761f0c47898f76d4e68dfa64db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e58b6c67c9bd44c4a413ba3ed5135d61",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d9637e4713b488f818dc9489cc23977"
          }
        },
        "75c20667696c4f118cc723cd1e5d62d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f84de061e282478c8ac0591fc54b6748",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:16&lt;00:00, 16.10s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_136949fc9c48403fab67bb74304007a8"
          }
        },
        "e58b6c67c9bd44c4a413ba3ed5135d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d9637e4713b488f818dc9489cc23977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f84de061e282478c8ac0591fc54b6748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "136949fc9c48403fab67bb74304007a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4bc5962276441cd954462ac625e124a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e291e8807e947e0a31cad336840a888",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a35019971cc0459ab7bbd9efe8fd806c",
              "IPY_MODEL_b8119ebeaa9340268f43f9ddfaacd611"
            ]
          }
        },
        "4e291e8807e947e0a31cad336840a888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a35019971cc0459ab7bbd9efe8fd806c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d515f1e670341e8bd7e6a66c41edc25",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7b2fdee05e8493c88a41851b8d4d42e"
          }
        },
        "b8119ebeaa9340268f43f9ddfaacd611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4682823ae6e54d648fe399736f2e2cf0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/300 [00:16&lt;00:00, 17.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_587169aa3c6649d6aa71d2ed97d7d88c"
          }
        },
        "9d515f1e670341e8bd7e6a66c41edc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7b2fdee05e8493c88a41851b8d4d42e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4682823ae6e54d648fe399736f2e2cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "587169aa3c6649d6aa71d2ed97d7d88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cRE8IbIrIV"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If9gpSrtt1bT",
        "outputId": "d7828b55-d717-4b71-bd8e-90f7c5d2c86f"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=7164534ab3ef184db410b0a4918e9237b69124333cb4d930d54b68b0c4742dbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  |     Proc size: 112.2 MB\n",
            "GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total     15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZChVm6f-CIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f01bf8-b3a0-453d-84f8-881ea8f021eb"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "source": [
        "! pip install datasets transformers > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFASsisvIrIb"
      },
      "source": [
        "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
        "\n",
        "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/question-answering)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJBSTyZIrIb"
      },
      "source": [
        "# Fine-tuning a model on a question-answering task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chPBzdBU9csw"
      },
      "source": [
        "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model to a question answering task, which is the task of extracting the answer to a question from a given context. We will see how to easily load a dataset for these kinds of tasks and use the `Trainer` API to fine-tune a model on it.\n",
        "\n",
        "![Widget inference representing the QA task](https://github.com/huggingface/notebooks/blob/master/examples/images/question_answering.png?raw=1)\n",
        "\n",
        "**Note:** This notebook finetunes models that answer question by taking a substring of a context, not by generating new text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RRkXuteIrIh"
      },
      "source": [
        "This notebook is built to run on any question answering task with the same format as SQUAD (version 1 or 2), with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a token classification head and a fast tokenizer (check on [this table](https://huggingface.co/transformers/index.html#bigtable) if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "source": [
        "# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\n",
        "# answers are allowed or not).\n",
        "squad_v2 = False\n",
        "model_checkpoint = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7QYTpxXIrIl"
      },
      "source": [
        "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreSlFmlIrIm"
      },
      "source": [
        "from datasets import load_dataset, load_metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKx2zKs5IrIq"
      },
      "source": [
        "For our example here, we'll use the [SQUAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). The notebook should work with any question answering dataset provided by the 🤗 Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "c29a0fae89e341fcb2ee6f4a26c64386",
            "7648f2f17a9e45eba74daf21b9d1b55c",
            "514418aa8ee944daaeb48079b6d978f5",
            "a8d748693b5743a3ad13ac30dc71be71",
            "e7a41501698c45d8b948ffd342e7fd45",
            "09114db8caec47aa92e08aea42df439e",
            "83fd7f852adf4188b51d0518d004f0e8",
            "1508c44ce886482f87ca1de08b68bfeb",
            "73b699a38bcb4c35996bccb7473504d3",
            "6c05097371d145eb8066412c599d0a4c",
            "843228158eeb4ae3a1b56545b3dd0220",
            "3bbe850c129147e49cc4d419118fc738",
            "c9f5a6f6d41345b4ac90e03f680eaabe",
            "3a28a47e906d4ac9b87ffaa1aae54376",
            "dff5d4dba37d4557b5cc73d64027bc03",
            "759b0e6ec3fb4bb9a8f4ee225edd53b9",
            "434c95e550c4424b88917b0692ead130",
            "c7ee298c9ac54f3d89cf37f74d7f207c",
            "88452636c65d486180313f1b8732106c",
            "8865a71c5dce4e48921a282fc51a6240",
            "0b18080d609d4f52bf896a04a761e29b",
            "409963f7b3294cc8832f7cf436e5de4c",
            "644e1285bacf40699e534dececa46897",
            "3b2ac1b5fd9543efb18508dfc2f9b468",
            "86ef98aadf9043b09700f89a7dfa8fe8",
            "e72bfdf462e643c4b69a1d1adee8c7da",
            "19cf0b792cb94126805f8894009fee2a",
            "d4b5d99f35cc4552b47a5830420b1d7a",
            "032b4a5a1ce24da3a366a42ec8ba5693",
            "a40b6e20001f4bcb9ef0fbbc22869c55",
            "a8be8ade65444c119b2bb024bf68334b",
            "d225ff2326964ca085b8ab59faa9655e"
          ]
        },
        "id": "s_AY1ATSIrIq",
        "outputId": "de57d78c-cd59-4ac3-ea1d-e912565a22ad"
      },
      "source": [
        "datasets = load_dataset(\"covid_qa_deepset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c29a0fae89e341fcb2ee6f4a26c64386",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1754.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73b699a38bcb4c35996bccb7473504d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=794.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset covid_qa_deepset/covid_qa_deepset (download: 4.21 MiB, generated: 62.13 MiB, post-processed: Unknown size, total: 66.35 MiB) to /root/.cache/huggingface/datasets/covid_qa_deepset/covid_qa_deepset/1.0.0/db8b3251603d2c1afd9b1dd8a46d7ab63bce6e3d14d8fc48062fd68b5a0bc6d7...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "434c95e550c4424b88917b0692ead130",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1346251.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86ef98aadf9043b09700f89a7dfa8fe8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset covid_qa_deepset downloaded and prepared to /root/.cache/huggingface/datasets/covid_qa_deepset/covid_qa_deepset/1.0.0/db8b3251603d2c1afd9b1dd8a46d7ab63bce6e3d14d8fc48062fd68b5a0bc6d7. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg08rbRGFGxc",
        "outputId": "af780c45-13ea-4511-ce55-95aee287906b"
      },
      "source": [
        "datasets[\"train\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['document_id', 'context', 'question', 'is_impossible', 'id', 'answers'],\n",
              "    num_rows: 2019\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzfPtOMoIrIu"
      },
      "source": [
        "The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6HrpprwIrIz"
      },
      "source": [
        "\n",
        "datasets[\"validation\"] = datasets[\"train\"]\n",
        "datasets[\"validation\"] = datasets[\"validation\"].select([i for i in range(0,300)])\n",
        "datasets[\"train\"] = datasets[\"train\"].select([i for i in range(300,2019)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWiVUF0jIrIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761f2e03-bb24-4186-f1a4-34c800700584"
      },
      "source": [
        "len(datasets[\"validation\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtzXHZiu9cs0"
      },
      "source": [
        "We can see the training, validation and test sets all have a column for the context, the question and the answers to those questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3EtYfeHIrIz"
      },
      "source": [
        "To access an actual element, you need to select a split first, then give an index:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIA71hFd9cs1"
      },
      "source": [
        "We can see the answers are indicated by their start position in the text (here at character 515) and their full text, which is a substring of the context as we mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUmphG3IrI3"
      },
      "source": [
        "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j8APAoIrI3"
      },
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=1):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZy5tRB_IrI7",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d505d22-5f95-4a8d-d66d-18b725b44e76"
      },
      "source": [
        "show_random_elements(datasets[\"train\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>document_id</th>\n",
              "      <th>id</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'answer_start': [775], 'text': ['v-ATPase inhibitor']}</td>\n",
              "      <td>The vacuolar-type ATPase inhibitor archazolid increases tumor cell adhesion to endothelial cells by accumulating extracellular collagen\\n\\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6133348/\\n\\nSHA: f1b81916fac1ca3d50dde774df2e1bb26bf0fb39\\n\\nAuthors: Luong, Betty; Schwenk, Rebecca; Bräutigam, Jacqueline; Müller, Rolf; Menche, Dirk; Bischoff, Iris; Fürst, Robert\\nDate: 2018-09-11\\nDOI: 10.1371/journal.pone.0203053\\nLicense: cc-by\\n\\nAbstract: The vacuolar-type H(+)-ATPase (v-ATPase) is the major proton pump that acidifies intracellular compartments of eukaryotic cells. Since the inhibition of v-ATPase resulted in anti-tumor and anti-metastatic effects in different tumor models, this enzyme has emerged as promising strategy against cancer. Here, we used the well-established v-ATPase inhibitor archazolid, a natural product first isolated from the myxobacterium Archangium gephyra, to study the consequences of v-ATPase inhibition in endothelial cells (ECs), in particular on the interaction between ECs and cancer cells, which has been neglected so far. Human endothelial cells treated with archazolid showed an increased adhesion of tumor cells, whereas the transendothelial migration of tumor cells was reduced. The adhesion process was independent from the EC adhesion molecules ICAM-1, VCAM-1, E-selectin and N-cadherin. Instead, the adhesion was mediated by β1-integrins expressed on tumor cells, as blocking of the integrin β1 subunit reversed this process. Tumor cells preferentially adhered to the β1-integrin ligand collagen and archazolid led to an increase in the amount of collagen on the surface of ECs. The accumulation of collagen was accompanied by a strong decrease of the expression and activity of the protease cathepsin B. Overexpression of cathepsin B in ECs prevented the capability of archazolid to increase the adhesion of tumor cells onto ECs. Our study demonstrates that the inhibition of v-ATPase by archazolid induces a pro-adhesive phenotype in endothelial cells that promotes their interaction with cancer cells, whereas the transmigration of tumor cells was reduced. These findings further support archazolid as a promising anti-metastatic compound.\\n\\nText: The vacuolar-type H + -ATPase (v-ATPase) is the major proton pump responsible for acidification of intracellular compartments in eukaryotic cells [1] . The enzyme consists of two multi-subunit complexes, the soluble V 1 transmembrane V o subcomplex required for the proton transport across membranes [1, 2] . In most cell types v-ATPases are only expressed in the endomembrane system to regulate and maintain the acidic pH of intracellular compartments such as lysosomes, endosomes, the Golgi apparatus, secretory granules and coated vesicles [3] . The function of v-ATPases is essential for cellular processes such as vesicular trafficking, receptor-mediated endocytosis and protein degradation and processing. In specialized cell types including osteoclasts and renal epithelial cells, v-ATPases can also be expressed on the plasma membrane, where they pump protons into the extracellular space [2] [3] [4] . In cancer cells v-ATPases are expressed on the plasma membrane in order to eliminate toxic cytosolic H + . Most importantly, v-ATPases contribute to the acidic tumor microenvironment, which leads to the activation of proteases, thus facilitating tumor cell migration, invasion and angiogenesis [5] [6] [7] . Since the inhibition of v-ATPase was shown to reduce the invasiveness of cancer cells and metastasis formation [8, 9] , this enzyme has emerged as a promising drug target in the recent years. Archazolid A and B are highly potent and specific inhibitors of v-ATPases [10] . They were first isolated from the myxobacterium Archangium gephyra [11] . These compounds inhibit v-ATPase at low nanomolar concentrations [10, 12] by binding to the subunit c of the V o complex. As their biological activity is comparable to the v-ATPase inhibitors bafilomycin and concanamycin [10, 11] , archazolids are natural compounds of high interest that can be used both as a tool to study the consequences of v-ATPase inhibition and as a lead for drug development. Archazolids can be either produced by fermentation [11] or by total synthesis [13, 14] .\\n\\nIn the field of cancer research several studies reported on interesting pharmacological effects of archazolid: It reduced the migration of different invasive tumor cells in vitro and cancer cell metastasis in vivo in a breast tumor mouse model [15] . Furthermore, archazolid activated pathways of cellular stress response and apoptosis in highly invasive tumor cells [16] . In classically activated macrophages, archazolid selectively induced the generation of tumor necrosis factor α (TNFα), which may indirectly promote tumor suppression [17] .\\n\\nUp to now, the role of v-ATPases in endothelial cells has only rarely been investigated. The endothelium plays a crucial role in the pathogenesis and progression of cancer: The metastatic cascade includes local angiogenesis at the site of the primary tumor and adhesion of tumor cells at the site of metastasis [18] . Angiogenesis, the development of new blood vessels out of existing ones, depends on the proliferation, migration and differentiation of endothelial cells [19] . This process ensures the nutrient supply of the tumor and its growth [20] . Circulating cancer cells can adhere to the endothelium at distant sites. This adhesive interaction is mediated by receptors and corresponding ligands expressed on tumor and endothelial cells [18, 21] . V-ATPases have been reported to regulate intracellular pH and cell migration in microvascular endothelial cells [22, 23] . A recent study showed that the inhibition of v-ATPase by concanamycin prevented proliferation, reduced migration and impaired angiogenesis-related signaling in endothelial cells [24] . So far, there are no investigations on the role of endothelial v-ATPases for the process of tumor cell adhesion onto the endothelium. Thus, we were interested in the consequences of the inhibition of endothelial v-ATPase by archazolid on the interaction between endothelial and cancer cells. Various cell adhesion molecules on the endothelium, such as intercellular adhesion molecule 1 (ICAM-1), vascular cell adhesion protein (VCAM-1), E-selectin or N-cadherin [21] as well as integrins expressed on cancer cells have been reported to mediate cell adhesion of cancer cells onto endothelial cells [25] [26] [27] . Accordingly, we focused on these cell adhesion molecules and integrins. For the first time, our study revealed a link between the function of v-ATPases and the adhesion and transmigration properties of endothelial cells.\\n\\nCellTiter-Blue Cell Viability Assay (Promega, Mannheim, Germany) was performed according to the manufacturer's protocol for determining the cell viability of cells after treatment with archazolid. This assay is based on the ability of metabolically active cells to reduce resazurin which results in fluorescent resorufin. The CellTiter-Blue Reagent was added to the cells 4 h before the endpoint of treatment. Fluorescence was measured with an Infinite F200 pro microplate reader (Tecan, Männedorf, Switzerland) at 560 nm (excitation) and 590 nm (emission).\\n\\nCytoTox 96 Non-Radioactive Cytotoxicity Assay (Promega) was performed according to the manufacturer's instructions for determining the lactate dehydrogenase (LDH) release after treatment with archazolid. Lysis buffer was added to untreated cells 45 min before the end of treatment to induce the release of this enzyme. LDH is a cytosolic enzyme that is released by leaky cells. Released LDH catalyzes the enzymatic conversion of lactate to pyruvate which provides NADH for the conversion of iodonitrotetrazolium violet into a red formazan product in the presence of diaphorase. The absorbance was measured with a Varioskan Flash microplate reader (Thermo Fisher Scientific) at 490 nm.\\n\\nLysoTracker Red DND-99 (Life Technologies, Thermo Fisher Scientific) is a dye to measure pH values in viable cells. HUVECs were cultured to confluence on collagen G-coated μ-slides (80826, ibidi, Martinsried, Germany) before they were treated with archazolid for 24 h. 1 μg/ ml Hoechst 33342 (Sigma-Aldrich, Munich, Germany) was used to visualize the nuclei and 50 nM LysoTracker Red DND-99 was used to visualize the acidic compartments which correspond to the lysosomes. Both dyes were incubated for 10 min at 37˚C before acquisition of single images by a Leica DMI6000 B fluorescence microscope (Leica Microsystems, Wetzlar, Germany).\\n\\nHUVECs were seeded in collagen G-coated 24-well plates and grown to confluence for two days before treatment. The cells were incubated with indicated concentrations of archazolid for 24 h. Untreated MDA-MB-231 or PC-3 cells were labeled with CellTracker Green CMFDA Dye (5 μM in serum-free DMEM, 37˚C) for 30 min before 100,000 cells per well were added to HUVECs and were allowed to adhere for various time points at 37˚C. Non-adherent tumor cells were washed off three times with PBS containing Ca 2+ and Mg 2+ . Tumor cell adhesion was determined by fluorescence measurements with an Infinite F200 pro microplate reader (Tecan) at 485 nm (excitation) and 535 nm (emission).\\n\\nFor blocking the integrin β1 subunit on MDA-MB-231 or PC-3 cells, CellTracker Greenlabeled MDA-MB-231 or PC-3 cells were incubated with an anti-integrin β1 antibody (P5D2, ab24693, Abcam, Cambridge, United Kingdom) at a concentration of 1 μg antibody per one million cells in 1 ml DMEM. Before adding to archazolid-treated HUVECs, MDA-MB-231 or PC-3 cells were washed once with DMEM. For blocking the integrin β1 subunit on HUVECs, the cells were incubated with the anti-integrin β1 antibody (0.1 μg/well in ECGM). HUVECs were washed once with ECGM before untreated MDA-MB-231 or PC-3 cells were added to HUVECs.\\n\\nFor the adhesion of MDA-MB-231 or PC-3 cells onto extracellular matrix (ECM) components 24-well plates were coated with collagen G (10 μg/ml in PBS), human plasma fibronectin (10 μg/ml PBS) or laminin-411 (10 μg/ml in Dulbecco's PBS [DPBS] containing Ca 2+ and Mg 2+ ) at 4˚C overnight. The adhesion of MDA-MB-231 and PC-3 cells onto these three most prominent ECM components was carried out as described above (10 min adhesion at 37˚C).\\n\\nHUVECs were grown on a porous filter membrane (Transwell insert, polycarbonate membrane, 8 μm pores; Corning, New York, USA) for 48 h and were treated as indicated. Untreated MDA-MB-231 cells were labeled with CellTracker Green CMFDA Dye (as described in the section cell adhesion assay) and resuspended in medium 199 (PAN-Biotech) containing 0.1% BSA. HUVECs were washed twice with medium 199 containing 0.1% BSA before MDA-MB-231 cells were allowed to transmigrate through the endothelial monolayer for 24 h. Medium 199 containing 0.1% BSA was used as negative control and medium 199 containing 20% FCS was used as chemoattractant for transmigration in the lower compartment. Non-migrated cells remaining in the upper compartment were carefully removed using a cotton swab. Transmigrated cells were lysed in radioimmunoprecipitation assay (RIPA) buffer and transmigration was quantified by measuring the fluorescence signal at 485 nm (excitation) and 535 nm (emission).\\n\\nHUVECs were grown to confluence on 6-well plates before they were treated with archazolid for 12 h. The cells were induced to upregulate the gene expression of cell adhesion molecules by TNFα. RNA was isolated using the RNeasy Mini Kit from Qiagen (Hilden, Germany) according to the manufacturer's protocol. On-column DNase digestion was performed to remove genomic DNA. RNA was transcribed into cDNA by Superscript II (Life Technologies, Thermo Fisher Scientific). qPCR experiments were performed using a StepOnePlus System (Applied Biosystems, Thermo Fisher Scientific) and data was analyzed by the StepOne and Ste-pOnePlus Software v2.3. Power SYBR Green PCR Master Mix (Life Technologies) and the comparative C T quantitation method (2 -ΔΔCT ) were used. \\n\\nHUVECs were grown to confluence on 12-well plates before they were treated with archazolid for 24 h. Cells were treated with TNFα for 24 h to induce the expression of cell adhesion molecules. Subsequently, the cells were detached with HyClone HyQTase (GE Healthcare, Freiburg, Germany). In the case of ICAM-1 the detached cells were fixed with 4% formaldehyde (Polysciences, Hirschberg an der Bergstraße, Germany) in PBS for 10 min and washed once with PBS before incubating with the fluorescein isothiocyanate (FITC)-labeled anti-human CD54 (mouse, ICAM-1) antibody (MCA1615F, Biozol, Eching, Germany) at room temperature for 45 min. For all other proteins, the cells were not fixed and washed once with PBS before incubating with the antibodies phycoerythrin (PE)-labeled anti-human CD106 (mouse, VCAM-1), PE-labeled anti-human CD62E (mouse, E-selectin) and PE-labeled anti-human CD325 (mouse, N-cadherin) from Becton Dickinson on ice for 45 min. These antibodies were diluted in PBS containing 0.2% BSA. The surface expression of cell adhesion molecules was measured by flow cytometry (FACSVerse, Becton Dickinson, Heidelberg, Germany).\\n\\nTo stain the surface collagen on HUVECs, cells were incubated with an anti-human collagen antibody (rabbit, 1:40, ab36064, Abcam) on ice for 30 min. The staining procedure was performed on ice to ensure that surface proteins or antibodies are not endocytosed. The cells were washed once with PBS containing Ca 2+ and Mg 2+ before they were fixed with Roti-Histofix (Carl Roth). Alexa Fluor 488-conjugated anti-rabbit antibody (goat, 1:400, A11008, Life Technologies) was used as secondary antibody and Hoechst 33342 (1 μg/ml, Sigma-Aldrich) was used to visualize nuclei.\\n\\nConfluent HUVECs in 6-well plates were treated as indicated. Cells were washed with ice-cold PBS and lysed with RIPA buffer supplemented with protease inhibitors (Complete Mini EDTA-free; Roche, Mannheim, Germany), sodium orthovanadate, sodium fluoride, phenylmethylsulphonyl fluoride, β-glycerophosphate, sodium pyrophosphate and H 2 O 2 . Protein determination was performed using the Pierce BCA Protein Assay Kit (Thermo Fisher Scientific). Equal amounts of proteins (10-20 μg) were separated by sodium dodecyl sulfatepolyacrylamide gel electrophoresis (SDS-PAGE; Bio-Rad Laboratories, Munich, Germany). Separated proteins were transferred onto polyvinylidene difluoride membranes by tank blotting (Bio-Rad Laboratories) for immunodetection. Membranes were blocked with 5% boltinggrade milk powder (Carl Roth) in TBS containing 0.1% Tween 20 (Sigma-Aldrich). The following antibodies were used: mouse anti-human cathepsin B antibody (IM27L, Merck) (1:500), mouse anti-β-actin-peroxidase antibody (A3854, Sigma-Aldrich) (1:100,000) and antimouse IgG horse radish peroxidase (HRP)-linked antibody (7076, Cell Signaling, Frankfurt, Germany) (1:5,000). ImageJ version 1.49m was used for densitometric analysis.\\n\\nCathepsin B activity assay was performed as described in the publication by Kubisch et al. [28] . Confluent HUVECs or HMEC-1 seeded in 6-well plates were treated as indicated. Cells were washed with PBS and lysed with the non-denaturating M-PER mammalian protein extraction reagent (78501, Thermo Fisher Scientific) supplemented with protease inhibitors (Complete Mini EDTA-free, Roche), sodium orthovanadate, sodium fluoride, phenylmethylsulphonyl fluoride. The fluorogenic cathepsin B substrate Z-Arg-Arg-7-amido-4-methylcoumarin hydrochloride (C5429, Sigma-Aldrich) was added to 30 μg of the cell lysate diluted in assay buffer supplemented with 2 mM L-cysteine (C7880, Sigma-Aldrich) and incubated for 30 min at 40˚C. Fluorescence was measured at 348 nm (excitation) and 440 nm (emission) with a microplate reader (Varioskan Flash, Thermo Fisher Scientific). The intensity of the fluorescence signal corresponded to the cathepsin B enzyme activity. For background subtraction the cathepsin B inhibitor CA-074Me (Enzo Life Sciences, Lörrach, Germany) was added to an additional reaction.\\n\\nThe HUVEC Nucleofector Kit (Lonza, Cologne, Germany) was used to transfect HUVECs. The transfection was performed according to the manufacturer's protocol using 2.5 μg plasmid DNA for 500,000 cells (Nucleofector 2b Device, Lonza). 48 h after transfection the cells were treated for further experiments. The addgene plasmid #11249 hCathepsin B was kindly provided by Hyeryun Choe [29] . hCathepsin B was digested with PmeI and XbaI and the linear DNA fragment not corresponding to the human CTSB gene was religated to generate the empty pcDNA3.1 (-) delta MCS plasmid that was used for control transfections. The original backbone of hCathepsin B is the pcDNA3.1 (-) from Thermo Fisher Scientific. The control vector pcDNA3.1 (-) delta MCS used for our transfections was cloned on the basis of hCathepsin B and is therefore lacking almost the whole part of the multiple cloning site of the pcDNA3.1 (-).\\n\\nStatistical analyses were performed using GraphPad Prism 5.0 (San Diego, USA). One-way ANOVA followed by Tukey's post-hoc test or unpaired t-test was used for the evaluation of a minimum of three independent experiments. The numbers of independently performed experiments (n) are stated in the corresponding figure legends. p 0.05 was considered as statistically significant. Data are expressed as mean ± standard error of the mean (SEM).\\n\\nSince the v-ATPase inhibitor archazolid has never been used for studies in endothelial cells, we first performed cytotoxicity assays. We treated confluent HUVECs with up to 1 nM archazolid for 24 and 48 h and observed that this treatment has neither an influence on the metabolic activity nor on the release of LDH after 24 h (Fig 1A and 1B, left panels) . The metabolic activity and the release of LDH were only slightly affected by the highest concentration of archazolid after 48 h (Fig 1A and 1B, right panels) . Consequently, the following experiments were all carried out after 24 h (or less) of archazolid treatment in order to exclude any cytotoxic effects of archazolid within our experimental settings.\\n\\nMicroscopic analysis revealed that also the integrity of the endothelial monolayer was not affected by archazolid, but the cells showed a slightly different morphology (Fig 2A) : Archazolid-treated cells were swollen compared to control cells, which was not unexpected, as vacuolation of the endoplasmic reticulum (ER) has been described for other cell types and is typical for v-ATPase inhibitors [11, 16, 24, 30] . This effect was obvious both in subconfluent and in confluent cells (Fig 2A) . Inhibition of v-ATPase prevents the acidification of lysosomes [1, 31] . Using the cell-permeable dye LysoTracker Red DND-99, it is possible to label the acidic lysosomes in living cells. Thus, this dye can serve as an indicator of v-ATPase inhibition. To proof that archazolid is also functionally active as a v-ATPase inhibitor in HUVECs, cells were treated with 1 nM archazolid before they were incubated with LysoTracker Red DND-99 and Hoechst 33342. As shown in Fig 2B, the red vesicular staining corresponding to acidified lysosomes in control cells disappeared completely after treatment with archazolid. In summary, archazolid treatment for 24 h was not cytotoxic to quiescent HUVECs, but inhibited the functionality of the v-ATPase.\\n\\nWe analyzed the adhesion of MDA-MB-231 cells onto HUVECs. Confluent HUVECs were treated with up to 1 nM archazolid for 24 h. Untreated MDA-MB-231 cells were labeled with Cell-Tracker Green CMFDA Dye. Interestingly, v-ATPase inhibition strongly increased the attachment of the metastatic breast carcinoma cell line MDA-MB-231 onto HUVECs after 10 and 120 min of adhesion (Fig 3A and 3B) . We also investigated the influence of archazolid on the transendothelial migration of MDA-MB-231 cells. HUVECs seeded in a Boyden chamber were treated with 1 nM archazolid for 24 h. CellTracker Green-labeled MDA-MB-231 cells (not treated with archazolid) were allowed to transmigrate through the endothelial monolayer for 24 h. As shown in Fig 3C, archazolid significantly decreased the transendothelial migration of MDA-MB-231 cells.\\n\\nThe influence of archazolid on tumor cell adhesion was not only studied in HUVECs, which represent macrovascular endothelial cells, but also in microvascular HMEC-1 cells. Moreover, besides the breast cancer cell line MDA-MB-231, also PC-3 prostate cancer cells were used as a second metastatic cancer cell line. Archazolid treatment of endothelial cells increased the attachment of MDA-MB-231 cells onto the HMEC-1 monolayer after 120 min of adhesion ( Fig 4A) and increased the attachment of PC-3 cells onto the HUVEC monolayer after 30 and 60 min of adhesion (Fig 4B) . Of note, the adhesion of non-metastatic Jurkat cells, an acute T cell leukemia cell line, remained unaffected after treatment of HUVECs with archazolid (S1A Fig). Taken together, archazolid treatment augmented the adhesive properties of both micro-and macrovascular endothelial cells for metastatic tumor cells, but not for non-metastatic ones. Of note, cancer cell adhesion onto archazolid-activated endothelial cells increased with the time of adhesion.\\n\\nThe adhesion of tumor cells onto the endothelium is in principle similar to that of leukocytes, but slightly differs in the molecules that mediate the adhesion process. Ligands for the endothelial cell adhesion molecules ICAM-1, VCAM-1, E-selectin and N-cadherin were found to be expressed on tumor cells and to mediate tumor-endothelial cell interaction [21] . Inhibition of the v-ATPase might affect the expression of endothelial cell adhesion molecules on mRNA or protein levels. To determine the mRNA expression of ICAM-1, VCAM-1, E-selectin and Ncadherin, HUVECs were treated with archazolid for 12 h. TNFα is known to upregulate the expression of ICAM-1, VCAM-1 and E-selectin [32] and, thus, served as positive control. Quantitative real-time PCR showed that v-ATPase inhibition in HUVECs did not alter the mRNA levels of ICAM-1, VCAM-1, E-selectin and N-cadherin (Fig 5A) . The protein expression of these adhesion molecules on the surface of endothelial cells was analyzed by flow cytometry. Archazolid (1 nM, 24 h) did not affect the cell surface expression of ICAM-1, VCAM-1, E-selectin and N-cadherin (Fig 5B) .\\n\\nBesides ICAM-1, VCAM-1, E-selectin and N-cadherin, also integrins are able to mediate the process of cell adhesion [33] [34] [35] . Since none of the cell adhesion molecules expressed on HUVECs were regulated upon archazolid treatment, we considered integrins as potential interaction partners. Within this protein family β1-integrins have been reported to mediate tumor cell adhesion onto quiescent endothelial cells [25] . In order to elucidate the role of β1-integrins for the archazolid-induced tumor cell adhesion, the integrin β1-subunit was blocked either on MDA-MB-231 cells, PC-3 cells or on HUVECs. (Of note, as in all experiments throughout this study, only endothelial cells were treated with archazolid.) After blocking β1-integrins on MDA-MB-231 or PC-3 cells, the archazolid-induced tumor cell adhesion was reduced almost to control level (Fig 6A and 6B , left panels), whereas blocking of β1-integrins on HUVECs had no significant effect on the increase of tumor cell adhesion by v-ATPase inhibition (Fig 6A and 6B , right panels).\\n\\nDepending on their α subunit, β1-integrins have a variety of ligands including extracellular matrix (ECM) components such as collagen, fibronectin and laminin [35] . Therefore, we hypothesized that archazolid treatment of endothelial cells might lead to an upregulation of these components. MDA-MB-231 and PC-3 cells were allowed to adhere onto plastic that was coated with these ECM components. This cell adhesion assay revealed that MDA-MB-231 as well as PC-3 cells favor the interaction with the ECM component collagen, as the adhesion onto collagen is much higher than onto the uncoated plastic control (Fig 7A) . MDA-MB-231 and PC-3 cells also adhered to fibronectin-coated plastic, but to a much lesser extent compared to the collagen coating. Therefore, we focused on the interaction between these two tumor cell lines and collagen. Blocking of the integrin β1 subunit on MDA-MB-231 and PC-3 cells clearly abolished the interaction with collagen (Fig 7B) , indicating that the attachment of these tumor cells to collagen is mediated by β1-integrins.\\n\\nSince collagen is the major ECM component MDA-MB-231 and PC-3 cells interact with, the next step was to prove whether v-ATPase inhibition influences the amount of collagen expressed by HUVECs as extracellular matrix. To detect collagen on the endothelial surface, archazolid-treated HUVECs were labeled with an antibody against collagen type I-IV on ice to prevent endocytosis and to ensure that the antibody does not bind to intracellular collagen. Interestingly, archazolid increased the amount of surface collagen on HUVECs by about 50% (Fig 7C) . Control stainings were performed using an antibody against the cytosolic p65 subunit of the transcription factor nuclear factor κB (NFκB) to show that intracellular proteins were not detected by this staining method (S2 Fig) . \\n\\nIt was reported that v-ATPase inhibition by archazolid impairs the activity of cathepsin B [28, 36] , a lysosomal enzyme that degrades extracellular matrix components including collagen [37] [38] [39] [40] [41] . As collagen is degraded by cathepsin B and the activation of cathepsin B depends on v-ATPase activity [28, [36] [37] [38] 42] , we suggested that an accumulation of collagen on the surface of endothelial cells might be a consequence of an impaired functionality of cathepsin B. Therefore, an enzyme activity assay based on the proteolysis of a fluorogenic cathepsin B substrate was performed. In archazolid-treated HUVECs and HMEC-1 the activity of cathepsin B was induce both the mRNA (1 ng/ml TNF) and the cell surface expression (10 ng/ml TNF) of ICAM-1, VCAM-1, E-selectin and Ncadherin.\\n\\nhttps://doi.org/10.1371/journal.pone.0203053.g005 Inhibition of endothelial vATPase increases tumor cell adhesion to endothelial cells strongly decreased by approximately 50% compared to control cells at an archazolid concentration of 1 nM (Fig 8A) . In line with this result, western blot analysis showed that archazolid (1 nM) reduces the protein expression of the mature, active form of cathepsin B to less than 40% of the control in HUVECs (Fig 8B) . To proof whether the archazolid-induced tumor cell adhesion is a consequence of the decreased amount of cathepsin B, HUVECs were transfected with a plasmid coding for human cathepsin B or with the empty vector as control. After 48 h, the transfected cells were treated with 1 nM archazolid. The level of cathepsin B after transfection and treatment was assessed by western blot analysis (Fig 9A) . Overexpression of cathepsin B strongly diminished both the basal and the archazolid-induced adhesion of MDA-MB-231 cells (Fig 9B) .\\n\\nTargeting the proton pump v-ATPase for cancer therapy has gained great interest since its inhibition was reported to reduce the invasiveness of cancer cells and, most importantly, also metastasis [8, 9] . Thus, intensive research related to v-ATPases was done in cancer cells, whereas there are only few studies investigating v-ATPases in endothelial cells indicating a role in migration, proliferation and possibly angiogenesis [22] [23] [24] . In the present study we used the myxobacterial natural product archazolid to investigate the consequences of v-ATPase inhibition in the endothelium on tumor-endothelial cell interactions.\\n\\nFor the first time, we were able to show a link between v-ATPase and the adhesion and transmigration properties of the endothelium. Inhibition of the v-ATPase in endothelial cells by archazolid significantly increased the adhesion of metastatic cancer cells and decreased the transendothelial migration of cancer cells which was attributed to augmented collagen levels on the surface on archazolid-treated endothelial cells. Of note, adhesion of the non-metastatic Jurkat cell line onto archazolid-treated endothelial cells remained unaffected. The archazolidinduced adhesion of tumor cells was independent from the endothelial cell adhesion molecules ICAM-1, VCAM-1, E-selectin and N-cadherin, as their expression was not regulated by the compound. However, we found that the archazolid-induced tumor cell adhesion was mediated by β1-integrins expressed on MDA-MB-231 breast cancer and PC-3 prostate cancer cells as blocking of the integrin β1 subunit on these tumor cells reversed the pro-adhesive effect of archazolid. In adhesion experiments on plastic coated with extracellular matrix components, we could show that MDA-MB-231 and PC-3 cells clearly favored the interaction with collagen, whereas the adhesion of non-metastatic Jurkat cells was largely independent from extracellular matrix proteins (S1B Fig). The different adhesion properties of metastatic cancer cells and Jurkat cells might be a result of the distinct integrin expression pattern of each cell line. MDA-MB-231 and PC-3 cells express α2β1-and α3β1-integrins, which represent collagen receptors [43, 44] , while Jurkat cells express α4β1-integrins but lack α2β1-, α3β1-integrins [44] . α4β1integrins are receptors for VCAM-1 and fibronectin [35] and it has been shown that Jurkat cells interact with human endothelial cells that express VCAM-1 after cytokine treatment or cells transfected with VCAM-1 [45] . Our results are in line with previous studies showing that α2β1-and α3β1-integrin expressing MDA-MB-231 and PC-3 cells were able to rapidly attach to collagen in the cortical bone matrix. In contrast, Jurkat cells were not able to adhere [44] and might preferentially interact with cell adhesion molecules rather than with ECM proteins. α2β1-and α3β1-integrins can additionally act as laminin receptors [46] and at least α3β1integrins recognize fibronectin [46, 47] . Though expressing receptors for fibronectin and laminin, MDA-MB-231 and PC-3 cells adhered to fibronectin to a much lesser extent and did not adhere to laminin, probably due to lower affinities to these extracellular matrix components.\\n\\nImportantly, v-ATPase inhibition by archazolid increased the surface levels of the extracellular matrix component collagen, which might explain that the increase of MDA-MB-231 and PC-3 cells onto archazolid-treated HUVECs is independent of endothelial cell adhesion molecules. By performing a live cell proteolysis assay, Cavallo-Medved et al. demonstrated ECM degradation, in particular of gelatin and collagen IV, in association with active cathepsin B in caveolae of endothelial cells during tube formation [40] . In addition, recent studies reported that v-ATPase inhibition impairs the activity of cathepsin B in cancer cells [28, 36] . Therefore, we suggested that the accumulation of collagen on the endothelial surface might be a consequence of impaired cathepsin B activity or expression in endothelial cells. In fact, we confirmed the impairment of cathepsin B activity by archazolid as the expression levels of the mature active form of this enzyme was strongly reduced. Cathepsin B is synthesized as preprocathepsin B on membrane-bound ribosomes. Following transport to the Golgi apparatus, the preprocathepsin B is glycosylated with mannose-containing oligosaccharides. The targeting of procathepsin B to lysosomes is mannose-6-phosphate receptor-dependent and its dissociation from the receptor as well as its proteolytic processing into mature cathepsin B requires acidification of the compartment [48] . In cancer cells v-ATPase inhibition by archazolid impaired the mannose-6-phosphate receptor-mediated trafficking from the trans-Golgi network to prelysosomal compartments resulting in a decrease of active lysosomal proteases like cathepsin B [28] . We assumed that the archazolid-induced decrease in cathepsin B activity and expression was based on the same mechanism. Interestingly, overexpression of cathepsin B attenuated the archazolid-induced adhesion of breast cancer cells onto endothelial cells, indicating that the adhesion negatively correlates with the expression of cathepsin B.\\n\\nAs cathepsin B can also degrade other extracellular matrix components such as fibronectin and laminin [38, 49] , v-ATPase inhibition could lead to an accumulation of these proteins and an increased adhesion of cells expressing fibronectin or laminin receptors. However, we did not focus on these ECM components since they were not relevant for the adhesion of MDA-MB-231 and PC-3 cells. These cells predominantly adhered to collagen, while the adhesion of Jurkat cells is mostly independent from the ECM proteins collagen, fibronectin or laminin (S1B Fig). Interestingly [50] . In hepatic cancer cells, archazolid reduces Ras/Raf/MEK/ERK signaling by altering the membrane composition and fluidity [51] . We assume that archazolid affects endothelial cells in a similar way leading to inhibition of Ras signaling and, therefore, reduced transendothelial migration of MDA-MB-231 cells.\\n\\nTaken together, our study shows that archazolid reduces the activity and expression of cathepsin B in endothelial cells. As a result, the amount of collagen on the surface of endothelial cells was significantly upregulated, which finally resulted in an increased adhesion of the β1-integrin-expressing metastatic cancer cell lines MDA-MB-231 and PC-3 onto archazolidtreated endothelial cells, whereas the adhesion of non-metastatic Jurkat cells was unaffected. This study shows that the v-ATPase plays an important role in regulating the adhesion of cells expressing receptors for extracellular matrix components. Archazolid represents a promising tool to elucidate the role of v-ATPase in endothelial cells. Moreover, we for the first time linked the function of v-ATPase to the adhesion and transmigration of tumor cells onto endothelial cells as well as to the remodeling of the extracellular matrix on the surface of endothelial cells. The fact that the adhesion of metastatic tumor cells onto endothelial cells is increased while their transendothelial migration is reduced upon inhibition of endothelial v-ATPase by archazolid further supports the view of archazolid as a potential anti-metastatic compound.</td>\n",
              "      <td>1633</td>\n",
              "      <td>5302</td>\n",
              "      <td>False</td>\n",
              "      <td>What is archazolid?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9qywopnIrJH"
      },
      "source": [
        "## Preprocessing the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVx71GdAIrJH"
      },
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
        "\n",
        "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
        "\n",
        "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
        "- we download the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "014a9b48b7bd4b0cb04831499b0173f4",
            "a53527798ac3496d9399b25c617d0ae4",
            "d4a3f3332f704ff284e5e14d3afe2320",
            "020de7be303645b0bbe806137f3dad39",
            "5ce7a13f77584ef7a0d2cea30cb2fc9e",
            "13a5fe46d0c14be7b4bb194331f1e2e2",
            "3bf37131e4e64475a46f46b85c86ba99",
            "5add5f3de7db4948a9f0fb277749b37a",
            "b50ff397a93340e1bbeb7950cfc3de37",
            "32b50233f4c3450cac34fb8f79dedabb",
            "5c9dd6f05b2f43419785a33d8b358af0",
            "2bd8509e7932452990cafd9ef291ada4",
            "45172f24c6e14d07879a14270d16cb32",
            "636962744b0f4d53ac0ff620a8355f73",
            "65750956a5a141359fd43b3efee58c8b",
            "ac92c47363f44ffda7b74c28632fdf84",
            "67b13101a59a4598896ff9d4c83ade61",
            "070493f876f64a2aa2a9597d5b6cf722",
            "244d4ea77d474b959d4bf7b9ff2d9e11",
            "e1c0562ca6584f71aca428e130772b5b",
            "257f8a39caf24ac1a7f10aee595c6401",
            "e3c577ce5c9349ba95d0d815116e3643",
            "33ec052899eb4b35bea85f8ad07ff6f4",
            "207ee75b131b48bfa8a4297d23afc2e0",
            "567703d6060a45118a6efa2e2b29e37e",
            "775ebccebb6b4f6b8f7ddde1e645d87e",
            "c99e68b379db4b6dbf257d1acdfd2c94",
            "38ec474b87dc44648918ce0a7bf7bcae",
            "d168d47c3d5444f5983f143942055567",
            "b7353e7933e94cf99675480c0add5001",
            "5e453be2efd74789a25669f2430225e2",
            "26499136517844578ea47e62dab86259"
          ]
        },
        "outputId": "f59e7d88-d90a-4d8f-ef46-5d605dc4baa7"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "014a9b48b7bd4b0cb04831499b0173f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b50ff397a93340e1bbeb7950cfc3de37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67b13101a59a4598896ff9d4c83ade61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "567703d6060a45118a6efa2e2b29e37e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl6IidfdIrJK"
      },
      "source": [
        "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x1DUx_l9cs3"
      },
      "source": [
        "import transformers\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vdFCDTK9cs4"
      },
      "source": [
        "You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rowT4iCLIrJK"
      },
      "source": [
        "You can directly call this tokenizer on two sentences (one for the answer, one for the context):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5hBlsrHIrJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efeec83-721e-42a3-a495-eaf1b3287345"
      },
      "source": [
        "tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcKkiyXZ9cs4"
      },
      "source": [
        "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
        "\n",
        "Now one specific thing for the preprocessing in question answering is how to deal with very long documents. We usually truncate them in other tasks, when they are longer than the model maximum sentence length, but here, removing part of the the context might result in losing the answer we are looking for. To deal with this, we will allow one (long) example in our dataset to give several input features, each of length shorter than the maximum length of the model (or the one we set as a hyper-parameter). Also, just in case the answer lies at the point we split a long context, we allow some overlap between the features we generate controlled by the hyper-parameter `doc_stride`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO0kcG8j9cs5"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chc24MxJ9cs5"
      },
      "source": [
        "Let's find one long example in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiPyUS3x9cs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f410fd-8f47-4e20-d422-ecb89ab5156a"
      },
      "source": [
        "for i, example in enumerate(datasets[\"train\"]):\n",
        "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
        "        break\n",
        "example = datasets[\"train\"][i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5818 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdv-h7ZC9cs6"
      },
      "source": [
        "Without any truncation, we get the following length for the input IDs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmf9naV9cs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4369b7a6-c7c2-46ec-db2d-c5a8dd2de0be"
      },
      "source": [
        "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLkqnyX39cs7"
      },
      "source": [
        "Now, if we just truncate, we will lose information (and possibly the answer to our question):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TAOdp19cs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a61505c-19a0-4c00-ab49-63490072eb09"
      },
      "source": [
        "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmkoAhpS9cs8"
      },
      "source": [
        "Note that we never want to truncate the question, only the context, else the `only_second` truncation picked. Now, our tokenizer can automatically return us a list of features capped by a certain maximum length, with the overlap we talked above, we just have to tell it with `return_overflowing_tokens=True` and by passing the stride:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_GZnIKI9cs9"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    stride=doc_stride\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jecy03IX9cs9"
      },
      "source": [
        "Now we don't have one list of `input_ids`, but several: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shaSdrOx9cs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5251c434-b4a2-496e-cdf8-58f3b096067e"
      },
      "source": [
        "[len(x) for x in tokenized_example[\"input_ids\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_YQHpkd9cs9"
      },
      "source": [
        "And if we decode them, we can see the overlap:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110n-0t09cs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245fde0c-cd3f-4120-d6c6-fcfaa2fb5f59"
      },
      "source": [
        "for x in tokenized_example[\"input_ids\"][:2]:\n",
        "    print(tokenizer.decode(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] what can nuclear receptors regulate? [SEP] inr - drug : predicting the interaction of drugs with nuclear receptors in cellular networking https : / / www. ncbi. nlm. nih. gov / pmc / articles / pmc3975431 / sha : ee55aea26f816403476a7cb71816b8ecb1110329 authors : fan, yue - nong ; xiao, xuan ; min, jian - liang ; chou, kuo - chen date : 2014 - 03 - 19 doi : 10. 3390 / ijms15034915 license : cc - by abstract : nuclear receptors ( nrs ) are closely associated with various major diseases such as cancer, diabetes, inflammatory disease, and osteoporosis. therefore, nrs have become a frequent target for drug development. during the process of developing drugs against these diseases by targeting nrs, we are often facing a problem : given a nr and chemical compound, can we identify whether they are really in interaction with each other in a cell? to address this problem, a predictor called “ inr - drug ” was developed. in the predictor, the drug compound concerned was formulated by a 256 - d ( dimensional ) vector derived from its molecular fingerprint, and the nr by a 500 - d vector formed by incorporating its sequential evolution information and physicochemical features into the general form of pseudo amino acid composition, and the prediction engine was operated by the svm ( support vector machine ) algorithm. compared with the existing prediction methods in this area, inr - drug not only can yield a higher success rate, but is also featured by a user - friendly web - server established at http : / / www. jci - bioinfo. cn / inr - drug /, which is particularly useful for most experimental scientists to [SEP]\n",
            "[CLS] what can nuclear receptors regulate? [SEP] d ( dimensional ) vector derived from its molecular fingerprint, and the nr by a 500 - d vector formed by incorporating its sequential evolution information and physicochemical features into the general form of pseudo amino acid composition, and the prediction engine was operated by the svm ( support vector machine ) algorithm. compared with the existing prediction methods in this area, inr - drug not only can yield a higher success rate, but is also featured by a user - friendly web - server established at http : / / www. jci - bioinfo. cn / inr - drug /, which is particularly useful for most experimental scientists to obtain their desired data in a timely manner. it is anticipated that the inr - drug server may become a useful high throughput tool for both basic research and drug development, and that the current approach may be easily extended to study the interactions of drug with other targets as well. text : with the ability to directly bind to dna ( figure 1 ) and regulate the expression of adjacent genes, nuclear receptors ( nrs ) are a class of ligand - inducible transcription factors. they regulate various biological processes, such as homeostasis, differentiation, embryonic development, and organ physiology [ 1 ] [ 2 ] [ 3 ]. the nr superfamily has been classified into seven families : nr0 ( knirps or dax like ) [ 4, 5 ] ; nr1 ( thyroid hormone like ), nr2 ( hnf4 - like ), nr3 ( estrogen like ), nr4 ( nerve growth factor ib - like ), nr5 ( fushi tarazu - f1 like ), and nr6 ( germ cell nuclear factor like ). since they are involved in almost all aspects of human physiology and are implicated in many major diseases such as cancer, diabetes and osteoporosis, nuclear receptors have [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swGrMiXu9cs-"
      },
      "source": [
        "Now this will give us some work to properly treat the answers: we need to find in which of those features the answer actually is, and where exactly in that feature. The models we will use require the start and end positions of these answers in the tokens, so we will also need to to map parts of the original context to some tokens. Thankfully, the tokenizer we're using can help us with that by returning an `offset_mapping`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGHfmo1X9cs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286e715c-19fe-43e6-d95d-a40380570fe3"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    stride=doc_stride\n",
        ")\n",
        "print(tokenized_example[\"offset_mapping\"][0][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0), (0, 4), (5, 8), (9, 16), (17, 26), (27, 35), (35, 36), (0, 0), (0, 2), (2, 3), (3, 4), (4, 8), (8, 9), (10, 20), (21, 24), (25, 36), (37, 39), (40, 45), (46, 50), (51, 58), (59, 68), (69, 71), (72, 80), (81, 91), (93, 98), (98, 99), (99, 100), (100, 101), (101, 104), (104, 105), (105, 107), (107, 109), (109, 110), (110, 112), (112, 113), (113, 114), (114, 116), (116, 117), (117, 118), (118, 121), (121, 122), (122, 124), (124, 125), (125, 126), (126, 134), (134, 135), (135, 137), (137, 138), (138, 140), (140, 142), (142, 144), (144, 145), (145, 146), (148, 151), (151, 152), (153, 155), (155, 157), (157, 160), (160, 162), (162, 163), (163, 164), (164, 166), (166, 168), (168, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 176), (176, 177), (177, 179), (179, 181), (181, 182), (182, 183), (183, 185), (185, 186), (186, 188), (188, 190), (190, 192), (192, 193), (195, 202), (202, 203), (204, 207), (207, 208), (209, 212), (212, 213), (213, 216), (216, 217), (217, 218), (219, 223), (223, 224), (225, 227), (227, 229), (229, 230), (231, 234), (234, 235), (236, 240), (240, 241), (241, 246), (246, 247)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFiGXYEr9cs_"
      },
      "source": [
        "This gives, for each index of our input IDS, the corresponding start and end character in the original text that gave our token. The very first token (`[CLS]`) has (0, 0) because it doesn't correspond to any part of the question/answer, then the second token is the same as the characters 0 to 3 of the question:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jScQN1l89cs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c998753-4be8-4ebb-ff89-3962dbbf29dd"
      },
      "source": [
        "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
        "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
        "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what What\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI6r5gCo9cs_"
      },
      "source": [
        "So we can use this mapping to find the position of the start and end tokens of our answer in a given feature. We just have to distinguish which parts of the offsets correspond to the question and which part correspond to the context, this is where the `sequence_ids` method of our `tokenized_example` can be useful:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MblYjNk9cs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178b0471-5f87-4243-a182-780bde98156e"
      },
      "source": [
        "sequence_ids = tokenized_example.sequence_ids()\n",
        "print(sequence_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZov03gY9ctA"
      },
      "source": [
        "It returns `None` for the special tokens, then 0 or 1 depending on whether the corresponding token comes from the first sentence past (the question) or the second (the context). Now with all of this, we can find the first and last token of the answer in one of our input feature (or if the answer is not in this feature):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxHywWU-9ctA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5085ee-297f-405e-aba9-95a5e2aac0ac"
      },
      "source": [
        "answers = example[\"answers\"]\n",
        "start_char = answers[\"answer_start\"][0]\n",
        "end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "# Start token index of the current span in the text.\n",
        "token_start_index = 0\n",
        "while sequence_ids[token_start_index] != 1:\n",
        "    token_start_index += 1\n",
        "\n",
        "# End token index of the current span in the text.\n",
        "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "while sequence_ids[token_end_index] != 1:\n",
        "    token_end_index -= 1\n",
        "\n",
        "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "        token_start_index += 1\n",
        "    start_position = token_start_index - 1\n",
        "    while offsets[token_end_index][1] >= end_char:\n",
        "        token_end_index -= 1\n",
        "    end_position = token_end_index + 1\n",
        "    print(start_position, end_position)\n",
        "else:\n",
        "    print(\"The answer is not in this feature.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The answer is not in this feature.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KP5Zj8X9ctA"
      },
      "source": [
        "And we can double check that it is indeed the theoretical answer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMB4MzXc9ctB"
      },
      "source": [
        "# print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
        "# print(answers[\"text\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4M_X_QG9ctB"
      },
      "source": [
        "For this notebook to work with any kind of models, we need to account for the special case where the model expects padding on the left (in which case we switch the order of the question and the context):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuTolAUU9ctB"
      },
      "source": [
        "pad_on_right = tokenizer.padding_side == \"right\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNLrOvz49ctB"
      },
      "source": [
        "Now let's put everything together in one function we will apply to our training set. In the case of impossible answers (the answer is in another feature given by an example with a long context), we set the cls index for both the start and end position. We could also simply discard those examples from the training set if the flag `allow_impossible_answers` is `False`. Since the preprocessing is already complex enough as it is, we've kept is simple for this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QaapZj9ctC"
      },
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lm8ozrJIrJR"
      },
      "source": [
        "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b70jh26IrJS"
      },
      "source": [
        "features = prepare_train_features(datasets['train'][:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS-6iXTkIrJT"
      },
      "source": [
        "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command. Since our preprocessing changes the number of samples, we need to remove the old columns when applying it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "a391bae8cf674db19a56e76a9a0e6e78",
            "636cf2193dfe41b391a7f5c8ee0b9fa5",
            "9bad6f190d934b169476df1c956b00bc",
            "4e7ebf2efcf44a2c84ccc5da17e8c12c",
            "cc2055df92e145409ce2b220167fa00a",
            "bb32a7bdd71e4cfd814f69ee4a35778d",
            "99fbd6c0e5454cf98fbb1740b63a2eb4",
            "181a33e06f8f4263a410bddaa46eb724",
            "a69873d19e8e4fa49f9da0249b8edfec",
            "da5b8a2cb6544ef1ab93199bf113b467",
            "d56b641f88ba41338beca1f9f8ac5b51",
            "485f281bf2014dde8a64b108b9fba61e",
            "a3d2689bf03d405aa338bb4f79ddd185",
            "b43c05520f2b46e184c409934ff478d8",
            "2508ba88497146c0a48f0583c8cb5811",
            "c4b6252ca8004fde8d9fd1a0e882ad49"
          ]
        },
        "outputId": "deac2b57-ba31-44d3-fc51-6bd5b6d3bcd4"
      },
      "source": [
        "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a391bae8cf674db19a56e76a9a0e6e78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a69873d19e8e4fa49f9da0249b8edfec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voWiw8C7IrJV"
      },
      "source": [
        "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBiW8UpKIrJW"
      },
      "source": [
        "Now that our data is ready for training, we can download the pretrained model and fine-tune it. Since our task is question answering, we use the `AutoModelForQuestionAnswering` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "dae29fdaf221465fb5275bc68ffe4249",
            "881d4f499d30426fafb98b4e7c86bc44",
            "b63b97a983b2429384dbd7808a4b6e89",
            "72ebe7f523e346feb4a0e010f39803b3",
            "1892919e03394937b92a8e815f479d1c",
            "705c4f40326746578e86746e9c35d07f",
            "fbf5457b46ca470a8e38f45ad8f0f41d",
            "ac652d6b62524661a507838e53c47e78"
          ]
        },
        "outputId": "c3d8d400-3712-494d-a8a6-7b62a33892bf"
      },
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dae29fdaf221465fb5275bc68ffe4249",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CczA5lJlIrJX"
      },
      "source": [
        "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N8urzhyIrJY"
      },
      "source": [
        "To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bliy8zgjIrJY"
      },
      "source": [
        "args = TrainingArguments(\n",
        "    f\"test-squad\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km3pGVdTIrJc"
      },
      "source": [
        "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHpKDZM-9ctF"
      },
      "source": [
        "Then we will need a data collator that will batch our processed examples together, here the default one will work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILmIwJaA9ctF"
      },
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "data_collator = default_data_collator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXuFTAzDIrJe"
      },
      "source": [
        "We will evaluate our model and compute metrics in the next section (this is a very long operation, so we will only compute the evaluation loss during training).\n",
        "\n",
        "Then we just need to pass all of this along with our datasets to the `Trainer`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imY1oC3SIrJf"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzABDVcIrJg"
      },
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNx5pyRlIrJh"
      },
      "source": [
        "# trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9f1Z0rb9ctG"
      },
      "source": [
        "Since this training is particularly long, let's save the model just in case we need to restart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rLQGSnD9ctG"
      },
      "source": [
        "# trainer.save_model(\"distil-covid-trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nPvAZtk9ctG"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPN7XhHC9ctH"
      },
      "source": [
        "Evaluating our model will require a bit more work, as we will need to map the predictions of our model back to parts of the context. The model itself predicts logits for the start and en position of our answers: if we take a batch from our validation datalaoder, here is the output our model gives us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkp5oK29ctH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dac8989-1a9a-4c19-9745-872ce782c09c"
      },
      "source": [
        "import torch\n",
        "\n",
        "for batch in trainer.get_eval_dataloader():\n",
        "    break\n",
        "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
        "with torch.no_grad():\n",
        "    output = trainer.model(**batch)\n",
        "output.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'start_logits', 'end_logits'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtpoYs0z9ctI"
      },
      "source": [
        "The output of the model is a dict-like object that contains the loss (since we provided labels), the start and end logits. We won't need the loss for our predictions, let's have a look a the logits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX6ScXqh9ctI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa97018-e4b5-4767-d890-0fedcc391f46"
      },
      "source": [
        "output.start_logits.shape, output.end_logits.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 384]), torch.Size([16, 384]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAU7jFAM9ctI"
      },
      "source": [
        "We have one logit for each feature and each token. The most obvious thing to predict an answer for each featyre is to take the index for the maximum of the start logits as a start position and the index of the maximum of the end logits as an end position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqvOMsp9ctI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4758fa76-2fde-474d-9b8f-5a92cecbfae1"
      },
      "source": [
        "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([145,   0,   0,   0,   0, 293,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0], device='cuda:0'),\n",
              " tensor([150,  14,  14,   0,  14, 299,   0,   0,   0,   0,   0,  14,  14,  14,\n",
              "           0, 146], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMg6A6t9ctI"
      },
      "source": [
        "This will work great in a lot of cases, but what if this prediction gives us something impossible: the start position could be greater than the end position, or point to a span of text in the question instead of the answer. In that case, we might want to look at the second best prediction to see if it gives a possible answer and select that instead.\n",
        "\n",
        "However, picking the second best answer is not as easy as picking the best one: is it the second best index in the start logits with the best index in the end logits? Or the best index in the start logits with the second best index in the end logits? And if that second best answer is not possible either, it gets even trickier for the third best answer.\n",
        "\n",
        "\n",
        "To classify our answers, we will use the score obtained by adding the start and end logits. We won't try to order all the possible answers and limit ourselves to with a hyper-parameter we call `n_best_size`. We'll pick the best indices in the start and end logits and gather all the answers this predicts. After checking if each one is valid, we will sort them by their score and keep the best one. Here is how we would do this on the first feature in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv6pJ_B9ctJ"
      },
      "source": [
        "n_best_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICFbFU-19ctJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n",
        "                }\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFjwP8sH9ctJ"
      },
      "source": [
        "And then we can sort the `valid_answers` according to their `score` and only keep the best one. The only point left is how to check a given span is inside the context (and not the question) and how to get back the text inside. To do this, we need to add two things to our validation features:\n",
        "- the ID of the example that generated the feature (since each example can generate several features, as seen before);\n",
        "- the offset mapping that will give us a map from token indices to character positions in the context.\n",
        "\n",
        "That's why we will re-process the validation set with the following function, slightly different from `prepare_train_features`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL83DAkA9ctJ"
      },
      "source": [
        "def prepare_validation_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-KjpxL9ctJ"
      },
      "source": [
        "And like before, we can apply that function to our validation set easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr5VEPrW9ctK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "02a19b3421134f009ffcdd3f7363c8a2",
            "462afead56fe46a08e87180ccede2e9c",
            "361a61761f0c47898f76d4e68dfa64db",
            "75c20667696c4f118cc723cd1e5d62d1",
            "e58b6c67c9bd44c4a413ba3ed5135d61",
            "2d9637e4713b488f818dc9489cc23977",
            "f84de061e282478c8ac0591fc54b6748",
            "136949fc9c48403fab67bb74304007a8"
          ]
        },
        "outputId": "5e6c51a5-0fe1-4da5-9cba-1f35714e1fb7"
      },
      "source": [
        "validation_features = datasets[\"validation\"].map(\n",
        "    prepare_validation_features,\n",
        "    batched=True,\n",
        "    remove_columns=datasets[\"validation\"].column_names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02a19b3421134f009ffcdd3f7363c8a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amE-12DP9ctL"
      },
      "source": [
        "Now we can grab the predictions for all features by using the `Trainer.predict` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x43ECvME9ctL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "a399d6f3-c1a3-4e62-e46b-bbb399a69352"
      },
      "source": [
        "raw_predictions = trainer.predict(validation_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='383' max='383' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [383/383 09:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CPRYpDz9ctM"
      },
      "source": [
        "The `Trainer` *hides* the columns that are not used by the model (here `example_id` and `offset_mapping` which we will need for our post-processing), so we set them back:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP2mqlQ29ctM"
      },
      "source": [
        "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tvgv38H9ctM"
      },
      "source": [
        "We can now refine the test we had before: since we set `None` in the offset mappings when it corresponds to a part of the question, it's easy to check if an answer is fully inside the context. We also eliminate very long answers from our considerations (with an hyper-parameter we can tune)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67KqQEoe9ctM"
      },
      "source": [
        "max_answer_length = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLBwOxk39ctN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68bf908-baf6-4fa8-cd3d-a2bb65d8f634"
      },
      "source": [
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
        "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
        "# an example index\n",
        "context = datasets[\"validation\"][0][\"context\"]\n",
        "\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "        # to part of the input_ids that are not in the context.\n",
        "        if (\n",
        "            start_index >= len(offset_mapping)\n",
        "            or end_index >= len(offset_mapping)\n",
        "            or offset_mapping[start_index] is None\n",
        "            or offset_mapping[end_index] is None\n",
        "        ):\n",
        "            continue\n",
        "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "            continue\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            start_char = offset_mapping[start_index][0]\n",
        "            end_char = offset_mapping[end_index][1]\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": context[start_char: end_char]\n",
        "                }\n",
        "            )\n",
        "\n",
        "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "valid_answers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 15.663379, 'text': 'Mother-to-child transmission'},\n",
              " {'score': 14.666584, 'text': 'Mother-to-child transmission (MTCT)'},\n",
              " {'score': 13.394403, 'text': 'Mother-to-child transmission (MTCT'},\n",
              " {'score': 12.228895, 'text': 'MTCT)'},\n",
              " {'score': 11.11519, 'text': 'Mother-to-child'},\n",
              " {'score': 10.956715, 'text': 'MTCT'},\n",
              " {'score': 10.29887, 'text': 'Mother-to-Child Transmission'},\n",
              " {'score': 9.768068,\n",
              "  'text': 'Mother-to-child transmission (MTCT) is the main cause of HIV-1 infection'},\n",
              " {'score': 9.374699, 'text': '(MTCT)'},\n",
              " {'score': 9.229617,\n",
              "  'text': 'Mother-to-child transmission (MTCT) is the main cause of HIV-1 infection in children'},\n",
              " {'score': 8.881094, 'text': 'transmission'},\n",
              " {'score': 8.728713,\n",
              "  'text': 'Mother-to-child transmission (MTCT) is the main cause of HIV-1 infection in children worldwide'},\n",
              " {'score': 8.455909,\n",
              "  'text': 'Mother-to-child transmission (MTCT) is the main cause'},\n",
              " {'score': 8.389352,\n",
              "  'text': 'Mother-to-child transmission (MTCT) is the main cause of HIV-1 infection in children worldwide.'},\n",
              " {'score': 8.374409, 'text': 'Mother-to-Child'},\n",
              " {'score': 8.353028, 'text': 'Mother'},\n",
              " {'score': 8.102518, 'text': '(MTCT'},\n",
              " {'score': 8.005215,\n",
              "  'text': 'Mother-to-child transmission (MTCT) is the main cause of HIV-1'},\n",
              " {'score': 7.8843, 'text': 'transmission (MTCT)'},\n",
              " {'score': 7.5978475, 'text': 'to-child transmission'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_X6jPvS9ctN"
      },
      "source": [
        "We can compare to the actual ground-truth answer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpehUdr29ctN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fc5c8a-acde-4bdc-a1d4-9e1429000517"
      },
      "source": [
        "datasets[\"validation\"][0][\"answers\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': [370],\n",
              " 'text': ['Mother-to-child transmission (MTCT) is the main cause of HIV-1 infection in children worldwide.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uXbNGJR9ctN"
      },
      "source": [
        "Our model picked the right as the most likely answer!\n",
        "\n",
        "As we mentioned in the code above, this was easy on the first feature because we knew it comes from the first example. For the other features, we will need a map between examples and their corresponding features. Also, since one example can give several features, we will need to gather together all the answers in all the features generated by a given example, then pick the best one. The following code builds a map from example index to its corresponding features indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS7E-65_9ctO"
      },
      "source": [
        "import collections\n",
        "\n",
        "examples = datasets[\"validation\"]\n",
        "features = validation_features\n",
        "\n",
        "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "features_per_example = collections.defaultdict(list)\n",
        "for i, feature in enumerate(features):\n",
        "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROM9a3Ex9ctO"
      },
      "source": [
        "We're almost ready for our post-processing function. The last bit to deal with is the impossible answer (when `squad_v2 = True`). The code above only keeps answers that are inside the context, we need to also grab the score for the impossible answer (which has start and end indices corresponding to the index of the CLS token). When one example gives several features, we have to predict the impossible answer when all the features give a high score to the impossible answer (since one feature could predict the impossible answer just because the answer isn't in the part of the context it has access too), which is why the score of the impossible answer for one example is the *minimum* of the scores for the impossible answer in each feature generated by the example.\n",
        "\n",
        "We then predict the impossible answer when that score is greater than the score of the best non-impossible answer. All combined together, this gives us this post-processing function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-hMtfYr9ctO"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "        \n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        if not squad_v2:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "        else:\n",
        "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
        "            predictions[example[\"id\"]] = answer\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYvajPWv9ctO"
      },
      "source": [
        "And we can apply our post-processing function to our raw predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPxBukOn9ctO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "f4bc5962276441cd954462ac625e124a",
            "4e291e8807e947e0a31cad336840a888",
            "a35019971cc0459ab7bbd9efe8fd806c",
            "b8119ebeaa9340268f43f9ddfaacd611",
            "9d515f1e670341e8bd7e6a66c41edc25",
            "c7b2fdee05e8493c88a41851b8d4d42e",
            "4682823ae6e54d648fe399736f2e2cf0",
            "587169aa3c6649d6aa71d2ed97d7d88c"
          ]
        },
        "outputId": "60fa8ce8-48b5-4698-da57-93f7afafc06f"
      },
      "source": [
        "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post-processing 300 example predictions split into 6116 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4bc5962276441cd954462ac625e124a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9wG7Z0Am5I3"
      },
      "source": [
        "# import pickle\n",
        "import json\n",
        "\n",
        "# with open('output-distil-covid.pickle', 'wb') as handle:\n",
        "#     pickle.dump(final_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('bert-covid.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_predictions, f, indent=4, ensure_ascii=False)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st7yL4cAneyn"
      },
      "source": [
        "# import pickle\n",
        "# file = open(\"output-distil-covid.pickle\",'rb')\n",
        "# object_file = pickle.load(file)\n",
        "# file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Kd5usCPiBp"
      },
      "source": [
        "# import pickle\n",
        "\n",
        "\n",
        "# with open('output-distil-covid.pickle', 'wb') as handle:\n",
        "#     pickle.dump(final_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('{}-covid-1.json'.format(\"distil\"), 'w', encoding='utf-8') as f:\n",
        "#     json.dump(object_file, f, indent=4, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln2JjDYzFv4S"
      },
      "source": [
        "from __future__ import print_function\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klQXV54yNVhX"
      },
      "source": [
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = prediction.split()\n",
        "    ground_truth_tokens = ground_truth.split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (prediction == ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHiyOSR7NZ84"
      },
      "source": [
        "my_predictions = list(final_predictions.items())\n",
        "\n",
        "for i in range(0,len(my_predictions)):\n",
        "  my_predictions[i] = normalize_answer(my_predictions[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGuX984OK_X"
      },
      "source": [
        "orig = list(datasets[\"validation\"])\n",
        "for i in range(0,len(orig)):\n",
        "  orig[i] = normalize_answer(orig[i][\"answers\"][\"text\"][0])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLXyEGf-DWL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa892ab-36bd-46ab-d0a2-22a80f20568d"
      },
      "source": [
        "em = 0\n",
        "for i in range(0,len(orig)):\n",
        "  if orig[i] == my_predictions[i]: em+=1\n",
        "\n",
        "\n",
        "print(\"Exact Match {}\".format(em/len(orig)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exact Match 0.3342036553524804\n",
            "Exact Match 0.4266666666666667\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF5eIOfUMCnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0925dbf-72cd-4b66-c92b-0536751b31bf"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(orig, my_predictions, average='weighted')\n",
        "print(\"f1_score {} weighted\".format(f1))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(orig, my_predictions, average='micro')\n",
        "print(\"f1_score {} micro\".format(f1))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(orig, my_predictions, average='macro')\n",
        "print(\"f1_score {} macro\".format(f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score 0.4244444444444444 weighted\n",
            "f1_score 0.42666666666666675 micro\n",
            "f1_score 0.27279358132749815 macro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMXarARSRbWU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}