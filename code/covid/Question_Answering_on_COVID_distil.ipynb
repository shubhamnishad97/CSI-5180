{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering on COVID-distil",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5823f17b619740fbb924d327558ab7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_699f259944eb4b64baa4c0d8e9df538b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_371817858768420682fcf478fd345f89",
              "IPY_MODEL_1c58201da5a346d1855cf3fd387e289c"
            ]
          }
        },
        "699f259944eb4b64baa4c0d8e9df538b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "371817858768420682fcf478fd345f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_01f3a92c127843ceb4c6c6b4438b8c80",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1754,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1754,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27dd372472264e2b8266f0b7df6c24a6"
          }
        },
        "1c58201da5a346d1855cf3fd387e289c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2c3794a45544a299324510e201e457d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.61k/? [00:01&lt;00:00, 4.57kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5c27a2215a643059f14bfe24bece79a"
          }
        },
        "01f3a92c127843ceb4c6c6b4438b8c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27dd372472264e2b8266f0b7df6c24a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2c3794a45544a299324510e201e457d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5c27a2215a643059f14bfe24bece79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3113d7cb1b74ee38432fee114cee1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b0c3dd9e9354e928a9e3c57a8787556",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fafda04753be4716820b18b37cd08104",
              "IPY_MODEL_e07c87b229bc4f36940ca1faf0356a93"
            ]
          }
        },
        "8b0c3dd9e9354e928a9e3c57a8787556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fafda04753be4716820b18b37cd08104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a385ebd830c460d93717144e0acac52",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 794,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 794,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_787430a8b11d44aea7f0b0690ec45c14"
          }
        },
        "e07c87b229bc4f36940ca1faf0356a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ec57230e1484982bf3a1f3b14f092b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.80k/? [00:00&lt;00:00, 2.20kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbfa65d8e51b4859be35476d78598096"
          }
        },
        "9a385ebd830c460d93717144e0acac52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "787430a8b11d44aea7f0b0690ec45c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ec57230e1484982bf3a1f3b14f092b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbfa65d8e51b4859be35476d78598096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a58e875305f040af89422c939da32adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af8c1cf2c7d44710a858b71ea50d3dbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8bf833173b324ef2a774cda8e5e03a52",
              "IPY_MODEL_2ca54ebf827d45e1980379530d304520"
            ]
          }
        },
        "af8c1cf2c7d44710a858b71ea50d3dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bf833173b324ef2a774cda8e5e03a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38ba1daf882143789baf09458a54728c",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1346251,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1346251,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9058f6a4efd47ecac2d047f797e2ccb"
          }
        },
        "2ca54ebf827d45e1980379530d304520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28176c3c49ad4884bfd6e01f23800498",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.42M/? [00:00&lt;00:00, 22.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_285ce89ce45143369897402d8fbc2127"
          }
        },
        "38ba1daf882143789baf09458a54728c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9058f6a4efd47ecac2d047f797e2ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28176c3c49ad4884bfd6e01f23800498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "285ce89ce45143369897402d8fbc2127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe27c200eda40ebb9cef854adcbcfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41b44a3af70e44b4ac1981a8c6a0dbe2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c003791b15a0456bb4728286bfb4f57a",
              "IPY_MODEL_3e68a4b1c3da4469ad5797bca9955df8"
            ]
          }
        },
        "41b44a3af70e44b4ac1981a8c6a0dbe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c003791b15a0456bb4728286bfb4f57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e793dc81cc8041fd8cdc79388ad0da30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b69734d3aed4db78018c68feb981e91"
          }
        },
        "3e68a4b1c3da4469ad5797bca9955df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d9b379ad9934e828d776617cddcd00c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2019/0 [00:03&lt;00:00,  2.53s/ examples]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_081a279d384c4461b6f62fba6db4beba"
          }
        },
        "e793dc81cc8041fd8cdc79388ad0da30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b69734d3aed4db78018c68feb981e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d9b379ad9934e828d776617cddcd00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "081a279d384c4461b6f62fba6db4beba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f39221bcd1d04343bb5086ab20ab3a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb67899c4b5b441db55fc3358591cf6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_986fff7fa6a94eb8ad3528e783fff9f9",
              "IPY_MODEL_9146d89fc11e4cb29179cd0680c431dc"
            ]
          }
        },
        "eb67899c4b5b441db55fc3358591cf6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "986fff7fa6a94eb8ad3528e783fff9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b14bcab4f4b4b85b6130a123ac1c458",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_054347a3ad5147b6b330603c1f3df667"
          }
        },
        "9146d89fc11e4cb29179cd0680c431dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b74cc6ce8a8c4f51907e92c88d7598cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 5.19kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c181550174b24acaa737f4250dd7a7eb"
          }
        },
        "8b14bcab4f4b4b85b6130a123ac1c458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "054347a3ad5147b6b330603c1f3df667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b74cc6ce8a8c4f51907e92c88d7598cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c181550174b24acaa737f4250dd7a7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b4f421f2da048e5b5d0077ef27f133e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50ebc97a5d3e4b96b0e22a87e29d055d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0a9b00a9437414b8cc71dc5b6c5cf04",
              "IPY_MODEL_051f2da910834885bfcc5e5b96f59bea"
            ]
          }
        },
        "50ebc97a5d3e4b96b0e22a87e29d055d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0a9b00a9437414b8cc71dc5b6c5cf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3581e333280f46529507ff4f483cf18c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2452e2e66ee47db9b4ba54892f470a8"
          }
        },
        "051f2da910834885bfcc5e5b96f59bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c643cf0d44a94fb0b80d900a1e1d0be5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 891kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b359c762de234685bdc9eeb36e5856cc"
          }
        },
        "3581e333280f46529507ff4f483cf18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2452e2e66ee47db9b4ba54892f470a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c643cf0d44a94fb0b80d900a1e1d0be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b359c762de234685bdc9eeb36e5856cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ad29b56da5d41c2ba939fb7aaa1e8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b4eff535d614b9d830ef7d6bc44b6c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47072111339b4da2b1cc789c4857ea35",
              "IPY_MODEL_a3b77760ba1a4136a54d757a898f4623"
            ]
          }
        },
        "5b4eff535d614b9d830ef7d6bc44b6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47072111339b4da2b1cc789c4857ea35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7c59f032049b43198dfc9cc23e7a0178",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1313c17624234847a37d86e012ec1527"
          }
        },
        "a3b77760ba1a4136a54d757a898f4623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1bfca2f821949deba02e5ec49371ddb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 3.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38e2f6384ebd4e148a543e60c15fd49e"
          }
        },
        "7c59f032049b43198dfc9cc23e7a0178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1313c17624234847a37d86e012ec1527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1bfca2f821949deba02e5ec49371ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38e2f6384ebd4e148a543e60c15fd49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b6ec617cad14611a67491b2145e83e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3aaf7eacedf442d98db1d9a37074a16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bcccd6719ff4e779685236f4ac789f2",
              "IPY_MODEL_a32bbea16bb742a99d0d375f2e5ad6cc"
            ]
          }
        },
        "f3aaf7eacedf442d98db1d9a37074a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bcccd6719ff4e779685236f4ac789f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec1e5a0f7974f03899606348e9675e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92a96f8c9a6946d2aea7d0554f627c43"
          }
        },
        "a32bbea16bb742a99d0d375f2e5ad6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06bf206781a645c78332893b8b6ebb58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 92.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eee78f3e6f3e478baa6c10c52e114791"
          }
        },
        "1ec1e5a0f7974f03899606348e9675e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92a96f8c9a6946d2aea7d0554f627c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06bf206781a645c78332893b8b6ebb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eee78f3e6f3e478baa6c10c52e114791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbdfc0f38bb54d2dac9ab88c49480a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41514283be5e4619b9ef2d2df60aa73b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8decb6fff596423e8914b0ee82073f13",
              "IPY_MODEL_fbf248190c7e4d138bdf51e7f9104ba4"
            ]
          }
        },
        "41514283be5e4619b9ef2d2df60aa73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8decb6fff596423e8914b0ee82073f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84a3ccfcb4164da9838829860593ab02",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1351ac5c1a3b4d948acdd99dc523a188"
          }
        },
        "fbf248190c7e4d138bdf51e7f9104ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2263514808e458bbc9f77e2a5a77aa5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:58&lt;00:00, 29.05s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b7282d8bde043ac83a7dd641cfc6a5f"
          }
        },
        "84a3ccfcb4164da9838829860593ab02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1351ac5c1a3b4d948acdd99dc523a188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2263514808e458bbc9f77e2a5a77aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b7282d8bde043ac83a7dd641cfc6a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69aa393a09374549a3666d85e74747d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84edfdb818884b039d15173e3ddb3175",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_996bdd04d27a44d0b1be1832e6cfd333",
              "IPY_MODEL_6198fe6a9dfb4401a7b88c7b5a1d3839"
            ]
          }
        },
        "84edfdb818884b039d15173e3ddb3175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "996bdd04d27a44d0b1be1832e6cfd333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eed8b7e123cb431bb684751b6bcfb3ba",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_974efb77e1bf48e4b6c238a7000bf75e"
          }
        },
        "6198fe6a9dfb4401a7b88c7b5a1d3839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9739a9ee148b4e71b31e854ae2ff081b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:16&lt;00:00, 16.17s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce97202ebc0e400299c9f499427f8ff9"
          }
        },
        "eed8b7e123cb431bb684751b6bcfb3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "974efb77e1bf48e4b6c238a7000bf75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9739a9ee148b4e71b31e854ae2ff081b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce97202ebc0e400299c9f499427f8ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33127e677cf442468b45c2c221e8d2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_801683f93ddd4a939b83bfa23ca5dd89",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_075b5311e14144b7a30e72acf8f3f033",
              "IPY_MODEL_3e7663e1ebe149c093256c79d9bedc55"
            ]
          }
        },
        "801683f93ddd4a939b83bfa23ca5dd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "075b5311e14144b7a30e72acf8f3f033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a604b99027cb4affbfa080702124b486",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43348bcdcccf4c069db9ae32fcb20e70"
          }
        },
        "3e7663e1ebe149c093256c79d9bedc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff68bbaa23c34e17a19a9dc2e595bd92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:08&lt;00:00, 30.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcf57b4f018f4adf91cbe7228ba43379"
          }
        },
        "a604b99027cb4affbfa080702124b486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43348bcdcccf4c069db9ae32fcb20e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff68bbaa23c34e17a19a9dc2e595bd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcf57b4f018f4adf91cbe7228ba43379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a189cbf292844a7b44b12f24ffcf4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01b8f2fdcdd14e3685e4b5ce01506e21",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97927561c9d24ede95920bfb7eac7aef",
              "IPY_MODEL_4b53b3670b3840a1a98160f6db775ea8"
            ]
          }
        },
        "01b8f2fdcdd14e3685e4b5ce01506e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97927561c9d24ede95920bfb7eac7aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5870d1683f654fb8b6cd3ab8ff1c1cea",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f11b9d27abb948efa431386ab4f5662d"
          }
        },
        "4b53b3670b3840a1a98160f6db775ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edb2c517271141679cdfc5c24077f65c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:16&lt;00:00, 16.66s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25bb5ad22b12431c832ee32c1f1e2e2f"
          }
        },
        "5870d1683f654fb8b6cd3ab8ff1c1cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f11b9d27abb948efa431386ab4f5662d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edb2c517271141679cdfc5c24077f65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25bb5ad22b12431c832ee32c1f1e2e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "304c8a10c86948f5a31aac20904cb0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74a1ad52d44b4b4ea231022c50c69fa2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54508f4a996e4ded830c878db487e5a1",
              "IPY_MODEL_23aa82505bd9421aa90e8d7b2e18d55f"
            ]
          }
        },
        "74a1ad52d44b4b4ea231022c50c69fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54508f4a996e4ded830c878db487e5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d4cadd0318d4670acb70077a026e2ad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3c323a042ac49649b03519a0cd7e6d1"
          }
        },
        "23aa82505bd9421aa90e8d7b2e18d55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2d05e21c60c4c758715aa51d66f85f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/300 [00:15&lt;00:00, 19.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b28a357f92544b569a0305db6d3bb4ca"
          }
        },
        "2d4cadd0318d4670acb70077a026e2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3c323a042ac49649b03519a0cd7e6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2d05e21c60c4c758715aa51d66f85f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b28a357f92544b569a0305db6d3bb4ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cRE8IbIrIV"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZChVm6f-CIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8066d784-9448-43ad-cc1f-14f312dec515"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "source": [
        "! pip install datasets transformers > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFASsisvIrIb"
      },
      "source": [
        "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
        "\n",
        "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/question-answering)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJBSTyZIrIb"
      },
      "source": [
        "# Fine-tuning a model on a question-answering task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chPBzdBU9csw"
      },
      "source": [
        "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model to a question answering task, which is the task of extracting the answer to a question from a given context. We will see how to easily load a dataset for these kinds of tasks and use the `Trainer` API to fine-tune a model on it.\n",
        "\n",
        "![Widget inference representing the QA task](https://github.com/huggingface/notebooks/blob/master/examples/images/question_answering.png?raw=1)\n",
        "\n",
        "**Note:** This notebook finetunes models that answer question by taking a substring of a context, not by generating new text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RRkXuteIrIh"
      },
      "source": [
        "This notebook is built to run on any question answering task with the same format as SQUAD (version 1 or 2), with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a token classification head and a fast tokenizer (check on [this table](https://huggingface.co/transformers/index.html#bigtable) if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVvslsfMIrIh"
      },
      "source": [
        "# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\n",
        "# answers are allowed or not).\n",
        "squad_v2 = False\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7QYTpxXIrIl"
      },
      "source": [
        "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreSlFmlIrIm"
      },
      "source": [
        "from datasets import load_dataset, load_metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKx2zKs5IrIq"
      },
      "source": [
        "For our example here, we'll use the [SQUAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). The notebook should work with any question answering dataset provided by the 🤗 Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "5823f17b619740fbb924d327558ab7de",
            "699f259944eb4b64baa4c0d8e9df538b",
            "371817858768420682fcf478fd345f89",
            "1c58201da5a346d1855cf3fd387e289c",
            "01f3a92c127843ceb4c6c6b4438b8c80",
            "27dd372472264e2b8266f0b7df6c24a6",
            "c2c3794a45544a299324510e201e457d",
            "d5c27a2215a643059f14bfe24bece79a",
            "e3113d7cb1b74ee38432fee114cee1ea",
            "8b0c3dd9e9354e928a9e3c57a8787556",
            "fafda04753be4716820b18b37cd08104",
            "e07c87b229bc4f36940ca1faf0356a93",
            "9a385ebd830c460d93717144e0acac52",
            "787430a8b11d44aea7f0b0690ec45c14",
            "1ec57230e1484982bf3a1f3b14f092b2",
            "cbfa65d8e51b4859be35476d78598096",
            "a58e875305f040af89422c939da32adb",
            "af8c1cf2c7d44710a858b71ea50d3dbf",
            "8bf833173b324ef2a774cda8e5e03a52",
            "2ca54ebf827d45e1980379530d304520",
            "38ba1daf882143789baf09458a54728c",
            "a9058f6a4efd47ecac2d047f797e2ccb",
            "28176c3c49ad4884bfd6e01f23800498",
            "285ce89ce45143369897402d8fbc2127",
            "3fe27c200eda40ebb9cef854adcbcfce",
            "41b44a3af70e44b4ac1981a8c6a0dbe2",
            "c003791b15a0456bb4728286bfb4f57a",
            "3e68a4b1c3da4469ad5797bca9955df8",
            "e793dc81cc8041fd8cdc79388ad0da30",
            "6b69734d3aed4db78018c68feb981e91",
            "5d9b379ad9934e828d776617cddcd00c",
            "081a279d384c4461b6f62fba6db4beba"
          ]
        },
        "id": "s_AY1ATSIrIq",
        "outputId": "6a20e51b-6b31-41e4-ee9a-dc839e6ca43b"
      },
      "source": [
        "datasets = load_dataset(\"covid_qa_deepset\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5823f17b619740fbb924d327558ab7de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1754.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3113d7cb1b74ee38432fee114cee1ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=794.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset covid_qa_deepset/covid_qa_deepset (download: 4.21 MiB, generated: 62.13 MiB, post-processed: Unknown size, total: 66.35 MiB) to /root/.cache/huggingface/datasets/covid_qa_deepset/covid_qa_deepset/1.0.0/db8b3251603d2c1afd9b1dd8a46d7ab63bce6e3d14d8fc48062fd68b5a0bc6d7...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58e875305f040af89422c939da32adb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1346251.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fe27c200eda40ebb9cef854adcbcfce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset covid_qa_deepset downloaded and prepared to /root/.cache/huggingface/datasets/covid_qa_deepset/covid_qa_deepset/1.0.0/db8b3251603d2c1afd9b1dd8a46d7ab63bce6e3d14d8fc48062fd68b5a0bc6d7. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg08rbRGFGxc",
        "outputId": "38d644ce-9382-4e86-be93-048abdbf5fa0"
      },
      "source": [
        "datasets[\"train\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['document_id', 'context', 'question', 'is_impossible', 'id', 'answers'],\n",
              "    num_rows: 2019\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzfPtOMoIrIu"
      },
      "source": [
        "The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6HrpprwIrIz"
      },
      "source": [
        "\n",
        "datasets[\"validation\"] = datasets[\"train\"]\n",
        "datasets[\"validation\"] = datasets[\"validation\"].select([i for i in range(0,300)])\n",
        "datasets[\"train\"] = datasets[\"train\"].select([i for i in range(300,2019)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWiVUF0jIrIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9e6ee6-fe87-42af-adaf-aa6f67624114"
      },
      "source": [
        "datasets[\"train\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': {'answer_start': [2040],\n",
              "  'text': ['homeostasis, differentiation, embryonic development, and organ physiology']},\n",
              " 'context': 'iNR-Drug: Predicting the Interaction of Drugs with Nuclear Receptors in Cellular Networking\\n\\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3975431/\\n\\nSHA: ee55aea26f816403476a7cb71816b8ecb1110329\\n\\nAuthors: Fan, Yue-Nong; Xiao, Xuan; Min, Jian-Liang; Chou, Kuo-Chen\\nDate: 2014-03-19\\nDOI: 10.3390/ijms15034915\\nLicense: cc-by\\n\\nAbstract: Nuclear receptors (NRs) are closely associated with various major diseases such as cancer, diabetes, inflammatory disease, and osteoporosis. Therefore, NRs have become a frequent target for drug development. During the process of developing drugs against these diseases by targeting NRs, we are often facing a problem: Given a NR and chemical compound, can we identify whether they are really in interaction with each other in a cell? To address this problem, a predictor called “iNR-Drug” was developed. In the predictor, the drug compound concerned was formulated by a 256-D (dimensional) vector derived from its molecular fingerprint, and the NR by a 500-D vector formed by incorporating its sequential evolution information and physicochemical features into the general form of pseudo amino acid composition, and the prediction engine was operated by the SVM (support vector machine) algorithm. Compared with the existing prediction methods in this area, iNR-Drug not only can yield a higher success rate, but is also featured by a user-friendly web-server established at http://www.jci-bioinfo.cn/iNR-Drug/, which is particularly useful for most experimental scientists to obtain their desired data in a timely manner. It is anticipated that the iNR-Drug server may become a useful high throughput tool for both basic research and drug development, and that the current approach may be easily extended to study the interactions of drug with other targets as well.\\n\\nText: With the ability to directly bind to DNA ( Figure 1 ) and regulate the expression of adjacent genes, nuclear receptors (NRs) are a class of ligand-inducible transcription factors. They regulate various biological processes, such as homeostasis, differentiation, embryonic development, and organ physiology [1] [2] [3] . The NR superfamily has been classified into seven families: NR0 (knirps or DAX like) [4, 5] ; NR1 (thyroid hormone like), NR2 (HNF4-like), NR3 (estrogen like), NR4 (nerve growth factor IB-like), NR5 (fushi tarazu-F1 like), and NR6 (germ cell nuclear factor like). Since they are involved in almost all aspects of human physiology and are implicated in many major diseases such as cancer, diabetes and osteoporosis, nuclear receptors have become major drug targets [6, 7] , along with G protein-coupled receptors (GPCRs) [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] , ion channels [18] [19] [20] , and kinase proteins [21] [22] [23] [24] . Identification of drug-target interactions is one of the most important steps for the new medicine development [25, 26] . The method usually adopted in this step is molecular docking simulation [27] [28] [29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] [40] [41] [42] [43] . However, to make molecular docking study feasible, a reliable 3D (three dimensional) structure of the target protein is the prerequisite condition. Although X-ray crystallography is a powerful tool in determining protein 3D structures, it is time-consuming and expensive. Particularly, not all proteins can be successfully crystallized. For example, membrane proteins are very difficult to crystallize and most of them will not dissolve in normal solvents. Therefore, so far very few membrane protein 3D structures have been determined. Although NMR (Nuclear Magnetic Resonance) is indeed a very powerful tool in determining the 3D structures of membrane proteins as indicated by a series of recent publications (see, e.g., [44] [45] [46] [47] [48] [49] [50] [51] and a review article [20] ), it is also time-consuming and costly. To acquire the 3D structural information in a timely manner, one has to resort to various structural bioinformatics tools (see, e.g., [37] ), particularly the homologous modeling approach as utilized for a series of protein receptors urgently needed during the process of drug development [19, [52] [53] [54] [55] [56] [57] . Unfortunately, the number of dependable templates for developing high quality 3D structures by means of homology modeling is very limited [37] .\\n\\nTo overcome the aforementioned problems, it would be of help to develop a computational method for predicting the interactions of drugs with nuclear receptors in cellular networking based on the sequences information of the latter. The results thus obtained can be used to pre-exclude the compounds identified not in interaction with the nuclear receptors, so as to timely stop wasting time and money on those unpromising compounds [58] .\\n\\nActually, based on the functional groups and biological features, a powerful method was developed recently [59] for this purpose. However, further development in this regard is definitely needed due to the following reasons. (a) He et al. [59] did not provide a publicly accessible web-server for their method, and hence its practical application value is quite limited, particularly for the broad experimental scientists; (b) The prediction quality can be further enhanced by incorporating some key features into the formulation of NR-drug (nuclear receptor and drug) samples via the general form of pseudo amino acid composition [60] .\\n\\nThe present study was initiated with an attempt to develop a new method for predicting the interaction of drugs with nuclear receptors by addressing the two points.\\n\\nAs demonstrated by a series of recent publications [10, 18, [61] [62] [63] [64] [65] [66] [67] [68] [69] [70] and summarized in a comprehensive review [60] , to establish a really effective statistical predictor for a biomedical system, we need to consider the following steps: (a) select or construct a valid benchmark dataset to train and test the predictor; (b) represent the statistical samples with an effective formulation that can truly reflect their intrinsic correlation with the object to be predicted; (c) introduce or develop a powerful algorithm or engine to operate the prediction; (d) properly perform cross-validation tests to objectively evaluate the anticipated accuracy of the predictor; (e) establish a user-friendly web-server for the predictor that is accessible to the public. Below, let us elaborate how to deal with these steps.\\n\\nThe data used in the current study were collected from KEGG (Kyoto Encyclopedia of Genes and Genomes) [71] at http://www.kegg.jp/kegg/. KEGG is a database resource for understanding high-level functions and utilities of the biological system, such as the cell, the organism and the ecosystem, from molecular-level information, especially large-scale molecular datasets generated by genome sequencing and other high-throughput experimental technologies. Here, the benchmark dataset can be formulated as\\n\\nwhere is the positive subset that consists of the interactive drug-NR pairs only, while the negative subset that contains of the non-interactive drug-NR pairs only, and the symbol represents the union in the set theory. The so-called \"interactive\" pair here means the pair whose two counterparts are interacting with each other in the drug-target networks as defined in the KEGG database [71] ; while the \"non-interactive\" pair means that its two counterparts are not interacting with each other in the drug-target networks. The positive dataset contains 86 drug-NR pairs, which were taken from He et al. [59] . The negative dataset contains 172 non-interactive drug-NR pairs, which were derived according to the following procedures: (a) separating each of the pairs in into single drug and NR; (b) re-coupling each of the single drugs with each of the single NRs into pairs in a way that none of them occurred in ; (c) randomly picking the pairs thus formed until reaching the number two times as many as the pairs in . The 86 interactive drug-NR pairs and 172 non-interactive drug-NR pairs are given in Supplementary Information S1, from which we can see that the 86 + 172 = 258 pairs in the current benchmark dataset are actually formed by 25 different NRs and 53 different compounds.\\n\\nSince each of the samples in the current network system contains a drug (compound) and a NR (protein), the following procedures were taken to represent the drug-NR pair sample.\\n\\nFirst, for the drug part in the current benchmark dataset, we can use a 256-D vector to formulate it as given by\\n\\nwhere D represents the vector for a drug compound, and d i its i-th (i = 1,2, ,256) component that can be derived by following the \"2D molecular fingerprint procedure\" as elaborated in [10] . The 53 molecular fingerprint vectors thus obtained for the 53 drugs in are, respectively, given in Supplementary Information S2.\\n\\nThe protein sequences of the 25 different NRs in are listed in Supplementary Information S3. Suppose the sequence of a nuclear receptor protein P with L residues is generally expressed by\\n\\nwhere 1 R represents the 1st residue of the protein sequence P , 2 R the 2nd residue, and so forth. Now the problem is how to effectively represent the sequence of Equation (3) with a non-sequential or discrete model [72] . This is because all the existing operation engines, such as covariance discriminant (CD) [17, 65, [73] [74] [75] [76] [77] [78] [79] , neural network [80] [81] [82] , support vector machine (SVM) [62] [63] [64] 83] , random forest [84, 85] , conditional random field [66] , nearest neighbor (NN) [86, 87] ; K-nearest neighbor (KNN) [88] [89] [90] , OET-KNN [91] [92] [93] [94] , and Fuzzy K-nearest neighbor [10, 12, 18, 69, 95] , can only handle vector but not sequence samples. However, a vector defined in a discrete model may completely lose all the sequence-order information and hence limit the quality of prediction. Facing such a dilemma, can we find an approach to partially incorporate the sequence-order effects? Actually, one of the most challenging problems in computational biology is how to formulate a biological sequence with a discrete model or a vector, yet still keep considerable sequence order information. To avoid completely losing the sequence-order information for proteins, the pseudo amino acid composition [96, 97] or Chou\\'s PseAAC [98] was proposed. Ever since the concept of PseAAC was proposed in 2001 [96] , it has penetrated into almost all the areas of computational proteomics, such as predicting anticancer peptides [99] , predicting protein subcellular location [100] [101] [102] [103] [104] [105] [106] , predicting membrane protein types [107, 108] , predicting protein submitochondria locations [109] [110] [111] [112] , predicting GABA(A) receptor proteins [113] , predicting enzyme subfamily classes [114] , predicting antibacterial peptides [115] , predicting supersecondary structure [116] , predicting bacterial virulent proteins [117] , predicting protein structural class [118] , predicting the cofactors of oxidoreductases [119] , predicting metalloproteinase family [120] , identifying cysteine S-nitrosylation sites in proteins [66] , identifying bacterial secreted proteins [121] , identifying antibacterial peptides [115] , identifying allergenic proteins [122] , identifying protein quaternary structural attributes [123, 124] , identifying risk type of human papillomaviruses [125] , identifying cyclin proteins [126] , identifying GPCRs and their types [15, 16] , discriminating outer membrane proteins [127] , classifying amino acids [128] , detecting remote homologous proteins [129] , among many others (see a long list of papers cited in the References section of [60] ). Moreover, the concept of PseAAC was further extended to represent the feature vectors of nucleotides [65] , as well as other biological samples (see, e.g., [130] [131] [132] ). Because it has been widely and increasingly used, recently two powerful soft-wares, called \"PseAAC-Builder\" [133] and \"propy\" [134] , were established for generating various special Chou\\'s pseudo-amino acid compositions, in addition to the web-server \"PseAAC\" [135] built in 2008.\\n\\nAccording to a comprehensive review [60] , the general form of PseAAC for a protein sequence P is formulated by\\n\\nwhere the subscript \\uf057 is an integer, and its value as well as the components ( 1, 2, , ) u u \\uf079 \\uf03d\\uf057 will depend on how to extract the desired information from the amino acid sequence of P (cf. Equation (3)). Below, let us describe how to extract useful information to define the components of PseAAC for the NR samples concerned. First, many earlier studies (see, e.g., [136] [137] [138] [139] [140] [141] ) have indicated that the amino acid composition (AAC) of a protein plays an important role in determining its attributes. The AAC contains 20 components with each representing the occurrence frequency of one of the 20 native amino acids in the protein concerned. Thus, such 20 AAC components were used here to define the first 20 elements in Equation (4); i.e., (1) ( 1, 2, , 20) ii fi \\uf079 \\uf03d\\uf03d (5) where f i (1) is the normalized occurrence frequency of the i-th type native amino acid in the nuclear receptor concerned. Since AAC did not contain any sequence order information, the following steps were taken to make up this shortcoming.\\n\\nTo avoid completely losing the local or short-range sequence order information, we considered the approach of dipeptide composition. It contained 20 × 20 = 400 components [142] . Such 400 components were used to define the next 400 elements in Equation (4); i.e., (2) 20 ( 1, 2, , 400) jj fj\\n\\nwhere (2) j f is the normalized occurrence frequency of the j-th dipeptides in the nuclear receptor concerned. To incorporate the global or long-range sequence order information, let us consider the following approach. According to molecular evolution, all biological sequences have developed starting out from a very limited number of ancestral samples. Driven by various evolutionary forces such as mutation, recombination, gene conversion, genetic drift, and selection, they have undergone many changes including changes of single residues, insertions and deletions of several residues [143] , gene doubling, and gene fusion. With the accumulation of these changes over a long period of time, many original similarities between initial and resultant amino acid sequences are gradually faded out, but the corresponding proteins may still share many common attributes [37] , such as having basically the same biological function and residing at a same subcellular location [144, 145] . To extract the sequential evolution information and use it to define the components of Equation (4), the PSSM (Position Specific Scoring Matrix) was used as described below.\\n\\nAccording to Schaffer [146] , the sequence evolution information of a nuclear receptor protein P with L amino acid residues can be expressed by a 20 L\\uf0b4 matrix, as given by\\n\\nwhere (7) were generated by using PSI-BLAST [147] to search the UniProtKB/Swiss-Prot database (The Universal Protein Resource (UniProt); http://www.uniprot.org/) through three iterations with 0.001 as the E-value cutoff for multiple sequence alignment against the sequence of the nuclear receptor concerned. In order to make every element in Equation (7) be scaled from their original score ranges into the region of [0, 1], we performed a conversion through the standard sigmoid function to make it become\\n\\nNow we extract the useful information from Equation (8) \\n\\nMoreover, we used the grey system model approach as elaborated in [68] to further define the next 60 components of Equation (4) ( 1, 2, , 20)\\n\\nIn the above equation, w 1 , w 2 , and w 3 are weight factors, which were all set to 1 in the current study; f j (1) has the same meaning as in Equation (5) \\n\\nwhere \\uf028 \\uf029 \\n\\nand\\n\\nCombining Equations (5), (6), (10) and (12), we found that the total number of the components obtained via the current approach for the PseAAC of Equation (4) \\n\\nand each of the 500 components is given by (1) ( \\n\\nSince the elements in Equations (2) and (4) are well defined, we can now formulate the drug-NR pair by combining the two equations as given by \\uf05b \\uf05d (19) where G represents the drug-NR pair, Å the orthogonal sum, and the 256 + 500 = 756 components are defined by Equations (2) and (18) . For the sake of convenience, let us use x i (i = 1, 2, , 756) to represent the 756 components in Equation (19); i.e., (20) To optimize the prediction quality with a time-saving approach, similar to the treatment [148] [149] [150] , let us convert Equation (20) to\\n\\nwhere the symbol means taking the average of the quantity therein, and SD means the corresponding standard derivation.\\n\\nIn this study, the SVM (support vector machine) was used as the operation engine. SVM has been widely used in the realm of bioinformatics (see, e.g., [62] [63] [64] [151] [152] [153] [154] ). The basic idea of SVM is to transform the data into a high dimensional feature space, and then determine the optimal separating hyperplane using a kernel function. For a brief formulation of SVM and how it works, see the papers [155, 156] ; for more details about SVM, see a monograph [157] .\\n\\nIn this study, the LIBSVM package [158] was used as an implementation of SVM, which can be downloaded from http://www.csie.ntu.edu.tw/~cjlin/libsvm/, the popular radial basis function (RBF) was taken as the kernel function. For the current SVM classifier, there were two uncertain parameters: penalty parameter C and kernel parameter \\uf067 . The method of how to determine the two parameters will be given later.\\n\\nThe predictor obtained via the aforementioned procedure is called iNR-Drug, where \"i\" means identify, and \"NR-Drug\" means the interaction between nuclear receptor and drug compound. To provide an intuitive overall picture, a flowchart is provided in Figure 2 to show the process of how the predictor works in identifying the interactions between nuclear receptors and drug compounds. \\n\\nTo provide a more intuitive and easier-to-understand method to measure the prediction quality, the following set of metrics based on the formulation used by Chou [159] [160] [161] in predicting signal peptides was adopted. According to Chou\\'s formulation, the sensitivity, specificity, overall accuracy, and Matthew\\'s correlation coefficient can be respectively expressed as [62, [65] [66] [67] Sn 1\\n\\nwhere N \\uf02b is the total number of the interactive NR-drug pairs investigated while N \\uf02b \\uf02d the number of the interactive NR-drug pairs incorrectly predicted as the non-interactive NR-drug pairs; N \\uf02d the total number of the non-interactive NR-drug pairs investigated while N \\uf02d \\uf02b the number of the non-interactive NR-drug pairs incorrectly predicted as the interactive NR-drug pairs.\\n\\nAccording to Equation (23) we can easily see the following. When 0 N \\uf02b \\uf02d \\uf03d meaning none of the interactive NR-drug pairs was mispredicted to be a non-interactive NR-drug pair, we have the sensitivity Sn = 1; while NN \\uf02b\\uf02b \\uf02d \\uf03d meaning that all the interactive NR-drug pairs were mispredicted to be the non-interactive NR-drug pairs, we have the sensitivity Sn = 0 . Likewise, when 0 N \\uf02d \\uf02b \\uf03d meaning none of the non-interactive NR-drug pairs was mispredicted, we have the specificity Sp we have MCC = 0 meaning total disagreement between prediction and observation. As we can see from the above discussion, it is much more intuitive and easier to understand when using Equation (23) to examine a predictor for its four metrics, particularly for its Mathew\\'s correlation coefficient. It is instructive to point out that the metrics as defined in Equation (23) are valid for single label systems; for multi-label systems, a set of more complicated metrics should be used as given in [162] .\\n\\nHow to properly test a predictor for its anticipated success rates is very important for its development as well as its potential application value. Generally speaking, the following three cross-validation methods are often used to examine the quality of a predictor and its effectiveness in practical application: independent dataset test, subsampling or K-fold (such as five-fold, seven-fold, or 10-fold) crossover test and jackknife test [163] . However, as elaborated by a penetrating analysis in [164] , considerable arbitrariness exists in the independent dataset test. Also, as demonstrated in [165] , the subsampling (or K-fold crossover validation) test cannot avoid arbitrariness either. Only the jackknife test is the least arbitrary that can always yield a unique result for a given benchmark dataset [73, 74, 156, [166] [167] [168] . Therefore, the jackknife test has been widely recognized and increasingly utilized by investigators to examine the quality of various predictors (see, e.g., [14, 15, 68, 99, 106, 107, 124, 169, 170] ). Accordingly, in this study the jackknife test was also adopted to evaluate the accuracy of the current predictor.\\n\\nAs mentioned above, the SVM operation engine contains two uncertain parameters C and \\uf067 . To find their optimal values, a 2-D grid search was conducted by the jackknife test on the benchmark dataset . The results thus obtained are shown in Figure 3 , from which it can be seen that the iNR-Drug predictor reaches its optimal status when C = 2 3 and 9 2 \\uf067 \\uf02d \\uf03d . The corresponding rates for the four metrics (cf. Equation (23)) are given in Table 1 , where for facilitating comparison, the overall accuracy Acc reported by He et al. [59] on the same benchmark dataset is also given although no results were reported by them for Sn, Sp and MCC. It can be observed from the table that the overall accuracy obtained by iNR-Drug is remarkably higher that of He et al. [59] , and that the rates achieved by iNR-Drug for the other three metrics are also quite higher. These facts indicate that the current predictor not only can yield higher overall prediction accuracy but also is quite stable with low false prediction rates. \\n\\nAs mentioned above (Section 3.2), the jackknife test is the most objective method for examining the quality of a predictor. However, as a demonstration to show how to practically use the current predictor, we took 41 NR-drug pairs from the study by Yamanishi et al. [171] that had been confirmed by experiments as interactive pairs. For such an independent dataset, 34 were correctly identified by iNR-Drug as interactive pairs, i.e., Sn = 34 / 41 = 82.92%, which is quite consistent with the rate of 79.07% achieved by the predictor on the benchmark dataset via the jackknife test as reported in Table 1 .\\n\\nIt is anticipated that the iNR-Drug predictor developed in this paper may become a useful high throughput tool for both basic research and drug development, and that the current approach may be easily extended to study the interactions of drug with other targets as well. Since user-friendly and publicly accessible web-servers represent the future direction for developing practically more useful predictors [98, 172] , a publicly accessible web-server for iNR-Drug was established.\\n\\nFor the convenience of the vast majority of biologists and pharmaceutical scientists, here let us provide a step-by-step guide to show how the users can easily get the desired result by using iNR-Drug web-server without the need to follow the complicated mathematical equations presented in this paper for the process of developing the predictor and its integrity.\\n\\nStep 1. Open the web server at the site http://www.jci-bioinfo.cn/iNR-Drug/ and you will see the top page of the predictor on your computer screen, as shown in Figure 4 . Click on the Read Me button to see a brief introduction about iNR-Drug predictor and the caveat when using it.\\n\\nStep 2. Either type or copy/paste the query NR-drug pairs into the input box at the center of Figure 4 . Each query pair consists of two parts: one is for the nuclear receptor sequence, and the other for the drug. The NR sequence should be in FASTA format, while the drug in the KEGG code beginning with the symbol #. Examples for the query pairs input and the corresponding output can be seen by clicking on the Example button right above the input box. Step 3. Click on the Submit button to see the predicted result. For example, if you use the three query pairs in the Example window as the input, after clicking the Submit button, you will see on your screen that the \"hsa:2099\" NR and the \"D00066\" drug are an interactive pair, and that the \"hsa:2908\" NR and the \"D00088\" drug are also an interactive pair, but that the \"hsa:5468\" NR and the \"D00279\" drug are not an interactive pair. All these results are fully consistent with the experimental observations. It takes about 3 minutes before each of these results is shown on the screen; of course, the more query pairs there is, the more time that is usually needed.\\n\\nStep 4. Click on the Citation button to find the relevant paper that documents the detailed development and algorithm of iNR-Durg.\\n\\nStep 5. Click on the Data button to download the benchmark dataset used to train and test the iNR-Durg predictor.\\n\\nStep 6. The program code is also available by clicking the button download on the lower panel of Figure 4 .',\n",
              " 'document_id': 1572,\n",
              " 'id': 1635,\n",
              " 'is_impossible': False,\n",
              " 'question': 'What can nuclear receptors regulate?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtzXHZiu9cs0"
      },
      "source": [
        "We can see the training, validation and test sets all have a column for the context, the question and the answers to those questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3EtYfeHIrIz"
      },
      "source": [
        "To access an actual element, you need to select a split first, then give an index:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIA71hFd9cs1"
      },
      "source": [
        "We can see the answers are indicated by their start position in the text (here at character 515) and their full text, which is a substring of the context as we mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUmphG3IrI3"
      },
      "source": [
        "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j8APAoIrI3"
      },
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=1):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZy5tRB_IrI7",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae88ef85-2161-4852-92e0-9ae988a01183"
      },
      "source": [
        "show_random_elements(datasets[\"train\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>document_id</th>\n",
              "      <th>id</th>\n",
              "      <th>is_impossible</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'answer_start': [29857], 'text': ['The modified vaccinia virus Ankara (MVA) strain was attenuated by passage 530 times in chick embryo fibroblasts cultures. The second, New York vaccinia virus (NYVAC) was a plaque-purified clone of the Copenhagen vaccine strain rationally attenuated by deletion of 18 open reading frames']}</td>\n",
              "      <td>Virus-Vectored Influenza Virus Vaccines\\n\\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4147686/\\n\\nSHA: f6d2afb2ec44d8656972ea79f8a833143bbeb42b\\n\\nAuthors: Tripp, Ralph A.; Tompkins, S. Mark\\nDate: 2014-08-07\\nDOI: 10.3390/v6083055\\nLicense: cc-by\\n\\nAbstract: Despite the availability of an inactivated vaccine that has been licensed for &gt;50 years, the influenza virus continues to cause morbidity and mortality worldwide. Constant evolution of circulating influenza virus strains and the emergence of new strains diminishes the effectiveness of annual vaccines that rely on a match with circulating influenza strains. Thus, there is a continued need for new, efficacious vaccines conferring cross-clade protection to avoid the need for biannual reformulation of seasonal influenza vaccines. Recombinant virus-vectored vaccines are an appealing alternative to classical inactivated vaccines because virus vectors enable native expression of influenza antigens, even from virulent influenza viruses, while expressed in the context of the vector that can improve immunogenicity. In addition, a vectored vaccine often enables delivery of the vaccine to sites of inductive immunity such as the respiratory tract enabling protection from influenza virus infection. Moreover, the ability to readily manipulate virus vectors to produce novel influenza vaccines may provide the quickest path toward a universal vaccine protecting against all influenza viruses. This review will discuss experimental virus-vectored vaccines for use in humans, comparing them to licensed vaccines and the hurdles faced for licensure of these next-generation influenza virus vaccines.\\n\\nText: Seasonal influenza is a worldwide health problem causing high mobility and substantial mortality [1] [2] [3] [4] . Moreover, influenza infection often worsens preexisting medical conditions [5] [6] [7] . Vaccines against circulating influenza strains are available and updated annually, but many issues are still present, including low efficacy in the populations at greatest risk of complications from influenza virus infection, i.e., the young and elderly [8, 9] . Despite increasing vaccination rates, influenza-related hospitalizations are increasing [8, 10] , and substantial drug resistance has developed to two of the four currently approved anti-viral drugs [11, 12] . While adjuvants have the potential to improve efficacy and availability of current inactivated vaccines, live-attenuated and virus-vectored vaccines are still considered one of the best options for the induction of broad and efficacious immunity to the influenza virus [13] .\\n\\nThe general types of influenza vaccines available in the United States are trivalent inactivated influenza vaccine (TIV), quadrivalent influenza vaccine (QIV), and live attenuated influenza vaccine (LAIV; in trivalent and quadrivalent forms). There are three types of inactivated vaccines that include whole virus inactivated, split virus inactivated, and subunit vaccines. In split virus vaccines, the virus is disrupted by a detergent. In subunit vaccines, HA and NA have been further purified by removal of other viral components. TIV is administered intramuscularly and contains three or four inactivated viruses, i.e., two type A strains (H1 and H3) and one or two type B strains. TIV efficacy is measured by induction of humoral responses to the hemagglutinin (HA) protein, the major surface and attachment glycoprotein on influenza. Serum antibody responses to HA are measured by the hemagglutination-inhibition (HI) assay, and the strain-specific HI titer is considered the gold-standard correlate of immunity to influenza where a four-fold increase in titer post-vaccination, or a HI titer of ≥1:40 is considered protective [4, 14] . Protection against clinical disease is mainly conferred by serum antibodies; however, mucosal IgA antibodies also may contribute to resistance against infection. Split virus inactivated vaccines can induce neuraminidase (NA)-specific antibody responses [15] [16] [17] , and anti-NA antibodies have been associated with protection from infection in humans [18] [19] [20] [21] [22] . Currently, NA-specific antibody responses are not considered a correlate of protection [14] . LAIV is administered as a nasal spray and contains the same three or four influenza virus strains as inactivated vaccines but on an attenuated vaccine backbone [4] . LAIV are temperature-sensitive and cold-adapted so they do not replicate effectively at core body temperature, but replicate in the mucosa of the nasopharynx [23] . LAIV immunization induces serum antibody responses, mucosal antibody responses (IgA), and T cell responses. While robust serum antibody and nasal wash (mucosal) antibody responses are associated with protection from infection, other immune responses, such as CD8 + cytotoxic lymphocyte (CTL) responses may contribute to protection and there is not a clear correlate of immunity for LAIV [4, 14, 24] .\\n\\nCurrently licensed influenza virus vaccines suffer from a number of issues. The inactivated vaccines rely on specific antibody responses to the HA, and to a lesser extent NA proteins for protection. The immunodominant portions of the HA and NA molecules undergo a constant process of antigenic drift, a natural accumulation of mutations, enabling virus evasion from immunity [9, 25] . Thus, the circulating influenza A and B strains are reviewed annually for antigenic match with current vaccines, Replacement of vaccine strains may occur regularly, and annual vaccination is recommended to assure protection [4, 26, 27] . For the northern hemisphere, vaccine strain selection occurs in February and then manufacturers begin production, taking at least six months to produce the millions of vaccine doses required for the fall [27] . If the prediction is imperfect, or if manufacturers have issues with vaccine production, vaccine efficacy or availability can be compromised [28] . LAIV is not recommended for all populations; however, it is generally considered to be as effective as inactivated vaccines and may be more efficacious in children [4, 9, 24] . While LAIV relies on antigenic match and the HA and NA antigens are replaced on the same schedule as the TIV [4, 9] , there is some suggestion that LAIV may induce broader protection than TIV due to the diversity of the immune response consistent with inducing virus-neutralizing serum and mucosal antibodies, as well as broadly reactive T cell responses [9, 23, 29] . While overall both TIV and LAIV are considered safe and effective, there is a recognized need for improved seasonal influenza vaccines [26] . Moreover, improved understanding of immunity to conserved influenza virus antigens has raised the possibility of a universal vaccine, and these universal antigens will likely require novel vaccines for effective delivery [30] [31] [32] .\\n\\nVirus-vectored vaccines share many of the advantages of LAIV, as well as those unique to the vectors. Recombinant DNA systems exist that allow ready manipulation and modification of the vector genome. This in turn enables modification of the vectors to attenuate the virus or enhance immunogenicity, in addition to adding and manipulating the influenza virus antigens. Many of these vectors have been extensively studied or used as vaccines against wild type forms of the virus. Finally, each of these vaccine vectors is either replication-defective or causes a self-limiting infection, although like LAIV, safety in immunocompromised individuals still remains a concern [4, 13, [33] [34] [35] . Table 1 summarizes the benefits and concerns of each of the virus-vectored vaccines discussed here.\\n\\nThere are 53 serotypes of adenovirus, many of which have been explored as vaccine vectors. A live adenovirus vaccine containing serotypes 4 and 7 has been in use by the military for decades, suggesting adenoviruses may be safe for widespread vaccine use [36] . However, safety concerns have led to the majority of adenovirus-based vaccine development to focus on replication-defective vectors. Adenovirus 5 (Ad5) is the most-studied serotype, having been tested for gene delivery and anti-cancer agents, as well as for infectious disease vaccines.\\n\\nAdenovirus vectors are attractive as vaccine vectors because their genome is very stable and there are a variety of recombinant systems available which can accommodate up to 10 kb of recombinant genetic material [37] . Adenovirus is a non-enveloped virus which is relatively stable and can be formulated for long-term storage at 4 °C, or even storage up to six months at room temperature [33] . Adenovirus vaccines can be grown to high titers, exceeding 10 1° plaque forming units (PFU) per mL when cultured on 293 or PER.C6 cells [38] , and the virus can be purified by simple methods [39] . Adenovirus vaccines can also be delivered via multiple routes, including intramuscular injection, subcutaneous injection, intradermal injection, oral delivery using a protective capsule, and by intranasal delivery. Importantly, the latter two delivery methods induce robust mucosal immune responses and may bypass preexisting vector immunity [33] . Even replication-defective adenovirus vectors are naturally immunostimulatory and effective adjuvants to the recombinant antigen being delivered. Adenovirus has been extensively studied as a vaccine vector for human disease. The first report using adenovirus as a vaccine vector for influenza demonstrated immunogenicity of recombinant adenovirus 5 (rAd5) expressing the HA of a swine influenza virus, A/Swine/Iowa/1999 (H3N2). Intramuscular immunization of mice with this construct induced robust neutralizing antibody responses and protected mice from challenge with a heterologous virus, A/Hong Kong/1/1968 (H3N2) [40] . Replication defective rAd5 vaccines expressing influenza HA have also been tested in humans. A rAd5-HA expressing the HA from A/Puerto Rico/8/1934 (H1N1; PR8) was delivered to humans epicutaneously or intranasally and assayed for safety and immunogenicity. The vaccine was well tolerated and induced seroconversion with the intranasal administration had a higher conversion rate and higher geometric meant HI titers [41] . While clinical trials with rAd vectors have overall been successful, demonstrating safety and some level of efficacy, rAd5 as a vector has been negatively overshadowed by two clinical trial failures. The first trial was a gene therapy examination where high-dose intravenous delivery of an Ad vector resulted in the death of an 18-year-old male [42, 43] . The second clinical failure was using an Ad5-vectored HIV vaccine being tested as a part of a Step Study, a phase 2B clinical trial. In this study, individuals were vaccinated with the Ad5 vaccine vector expressing HIV-1 gag, pol, and nef genes. The vaccine induced HIV-specific T cell responses; however, the study was stopped after interim analysis suggested the vaccine did not achieve efficacy and individuals with high preexisting Ad5 antibody titers might have an increased risk of acquiring HIV-1 [44] [45] [46] . Subsequently, the rAd5 vaccine-associated risk was confirmed [47] . While these two instances do not suggest Ad-vector vaccines are unsafe or inefficacious, the umbra cast by the clinical trials notes has affected interest for all adenovirus vaccines, but interest still remains.\\n\\nImmunization with adenovirus vectors induces potent cellular and humoral immune responses that are initiated through toll-like receptor-dependent and independent pathways which induce robust pro-inflammatory cytokine responses. Recombinant Ad vaccines expressing HA antigens from pandemic H1N1 (pH1N1), H5 and H7 highly pathogenic avian influenza (HPAI) virus (HPAIV), and H9 avian influenza viruses have been tested for efficacy in a number of animal models, including chickens, mice, and ferrets, and been shown to be efficacious and provide protection from challenge [48, 49] . Several rAd5 vectors have been explored for delivery of non-HA antigens, influenza nucleoprotein (NP) and matrix 2 (M2) protein [29, [50] [51] [52] . The efficacy of non-HA antigens has led to their inclusion with HA-based vaccines to improve immunogenicity and broaden breadth of both humoral and cellular immunity [53, 54] . However, as both CD8 + T cell and neutralizing antibody responses are generated by the vector and vaccine antigens, immunological memory to these components can reduce efficacy and limit repeated use [48] .\\n\\nOne drawback of an Ad5 vector is the potential for preexisting immunity, so alternative adenovirus serotypes have been explored as vectors, particularly non-human and uncommon human serotypes. Non-human adenovirus vectors include those from non-human primates (NHP), dogs, sheep, pigs, cows, birds and others [48, 55] . These vectors can infect a variety of cell types, but are generally attenuated in humans avoiding concerns of preexisting immunity. Swine, NHP and bovine adenoviruses expressing H5 HA antigens have been shown to induce immunity comparable to human rAd5-H5 vaccines [33, 56] . Recombinant, replication-defective adenoviruses from low-prevalence serotypes have also been shown to be efficacious. Low prevalence serotypes such as adenovirus types 3, 7, 11, and 35 can evade anti-Ad5 immune responses while maintaining effective antigen delivery and immunogenicity [48, 57] . Prime-boost strategies, using DNA or protein immunization in conjunction with an adenovirus vaccine booster immunization have also been explored as a means to avoided preexisting immunity [52] .\\n\\nAdeno-associated viruses (AAV) were first explored as gene therapy vectors. Like rAd vectors, rAAV have broad tropism infecting a variety of hosts, tissues, and proliferating and non-proliferating cell types [58] . AAVs had been generally not considered as vaccine vectors because they were widely considered to be poorly immunogenic. A seminal study using AAV-2 to express a HSV-2 glycoprotein showed this virus vaccine vector effectively induced potent CD8 + T cell and serum antibody responses, thereby opening the door to other rAAV vaccine-associated studies [59, 60] .\\n\\nAAV vector systems have a number of engaging properties. The wild type viruses are non-pathogenic and replication incompetent in humans and the recombinant AAV vector systems are even further attenuated [61] . As members of the parvovirus family, AAVs are small non-enveloped viruses that are stable and amenable to long-term storage without a cold chain. While there is limited preexisting immunity, availability of non-human strains as vaccine candidates eliminates these concerns. Modifications to the vector have increased immunogenicity, as well [60] .\\n\\nThere are limited studies using AAVs as vaccine vectors for influenza. An AAV expressing an HA antigen was first shown to induce protective in 2001 [62] . Later, a hybrid AAV derived from two non-human primate isolates (AAVrh32.33) was used to express influenza NP and protect against PR8 challenge in mice [63] . Most recently, following the 2009 H1N1 influenza virus pandemic, rAAV vectors were generated expressing the HA, NP and matrix 1 (M1) proteins of A/Mexico/4603/2009 (pH1N1), and in murine immunization and challenge studies, the rAAV-HA and rAAV-NP were shown to be protective; however, mice vaccinated with rAAV-HA + NP + M1 had the most robust protection. Also, mice vaccinated with rAAV-HA + rAAV-NP + rAAV-M1 were also partially protected against heterologous (PR8, H1N1) challenge [63] . Most recently, an AAV vector was used to deliver passive immunity to influenza [64, 65] . In these studies, AAV (AAV8 and AAV9) was used to deliver an antibody transgene encoding a broadly cross-protective anti-influenza monoclonal antibody for in vivo expression. Both intramuscular and intranasal delivery of the AAVs was shown to protect against a number of influenza virus challenges in mice and ferrets, including H1N1 and H5N1 viruses [64, 65] . These studies suggest that rAAV vectors are promising vaccine and immunoprophylaxis vectors. To this point, while approximately 80 phase I, I/II, II, or III rAAV clinical trials are open, completed, or being reviewed, these have focused upon gene transfer studies and so there is as yet limited safety data for use of rAAV as vaccines [66] .\\n\\nAlphaviruses are positive-sense, single-stranded RNA viruses of the Togaviridae family. A variety of alphaviruses have been developed as vaccine vectors, including Semliki Forest virus (SFV), Sindbis (SIN) virus, Venezuelan equine encephalitis (VEE) virus, as well as chimeric viruses incorporating portions of SIN and VEE viruses. The replication defective vaccines or replicons do not encode viral structural proteins, having these portions of the genome replaces with transgenic material.\\n\\nThe structural proteins are provided in cell culture production systems. One important feature of the replicon systems is the self-replicating nature of the RNA. Despite the partial viral genome, the RNAs are self-replicating and can express transgenes at very high levels [67] .\\n\\nSIN, SFV, and VEE have all been tested for efficacy as vaccine vectors for influenza virus [68] [69] [70] [71] . A VEE-based replicon system encoding the HA from PR8 was demonstrated to induce potent HA-specific immune response and protected from challenge in a murine model, despite repeated immunization with the vector expressing a control antigen, suggesting preexisting immunity may not be an issue for the replicon vaccine [68] . A separate study developed a VEE replicon system expressing the HA from A/Hong Kong/156/1997 (H5N1) and demonstrated varying efficacy after in ovo vaccination or vaccination of 1-day-old chicks [70] . A recombinant SIN virus was use as a vaccine vector to deliver a CD8 + T cell epitope only. The well-characterized NP epitope was transgenically expressed in the SIN system and shown to be immunogenic in mice, priming a robust CD8 + T cell response and reducing influenza virus titer after challenge [69] . More recently, a VEE replicon system expressing the HA protein of PR8 was shown to protect young adult (8-week-old) and aged (12-month-old) mice from lethal homologous challenge [72] .\\n\\nThe VEE replicon systems are particularly appealing as the VEE targets antigen-presenting cells in the lymphatic tissues, priming rapid and robust immune responses [73] . VEE replicon systems can induce robust mucosal immune responses through intranasal or subcutaneous immunization [72] [73] [74] , and subcutaneous immunization with virus-like replicon particles (VRP) expressing HA-induced antigen-specific systemic IgG and fecal IgA antibodies [74] . VRPs derived from VEE virus have been developed as candidate vaccines for cytomegalovirus (CMV). A phase I clinical trial with the CMV VRP showed the vaccine was immunogenic, inducing CMV-neutralizing antibody responses and potent T cell responses. Moreover, the vaccine was well tolerated and considered safe [75] . A separate clinical trial assessed efficacy of repeated immunization with a VRP expressing a tumor antigen. The vaccine was safe and despite high vector-specific immunity after initial immunization, continued to boost transgene-specific immune responses upon boost [76] . While additional clinical data is needed, these reports suggest alphavirus replicon systems or VRPs may be safe and efficacious, even in the face of preexisting immunity.\\n\\nBaculovirus has been extensively used to produce recombinant proteins. Recently, a baculovirus-derived recombinant HA vaccine was approved for human use and was first available for use in the United States for the 2013-2014 influenza season [4] . Baculoviruses have also been explored as vaccine vectors. Baculoviruses have a number of advantages as vaccine vectors. The viruses have been extensively studied for protein expression and for pesticide use and so are readily manipulated. The vectors can accommodate large gene insertions, show limited cytopathic effect in mammalian cells, and have been shown to infect and express genes of interest in a spectrum of mammalian cells [77] . While the insect promoters are not effective for mammalian gene expression, appropriate promoters can be cloned into the baculovirus vaccine vectors.\\n\\nBaculovirus vectors have been tested as influenza vaccines, with the first reported vaccine using Autographa californica nuclear polyhedrosis virus (AcNPV) expressing the HA of PR8 under control of the CAG promoter (AcCAG-HA) [77] . Intramuscular, intranasal, intradermal, and intraperitoneal immunization or mice with AcCAG-HA elicited HA-specific antibody responses, however only intranasal immunization provided protection from lethal challenge. Interestingly, intranasal immunization with the wild type AcNPV also resulted in protection from PR8 challenge. The robust innate immune response to the baculovirus provided non-specific protection from subsequent influenza virus infection [78] . While these studies did not demonstrate specific protection, there were antigen-specific immune responses and potential adjuvant effects by the innate response.\\n\\nBaculovirus pseudotype viruses have also been explored. The G protein of vesicular stomatitis virus controlled by the insect polyhedron promoter and the HA of A/Chicken/Hubei/327/2004 (H5N1) HPAIV controlled by a CMV promoter were used to generate the BV-G-HA. Intramuscular immunization of mice or chickens with BV-G-HA elicited strong HI and VN serum antibody responses, IFN-γ responses, and protected from H5N1 challenge [79] . A separate study demonstrated efficacy using a bivalent pseudotyped baculovirus vector [80] .\\n\\nBaculovirus has also been used to generate an inactivated particle vaccine. The HA of A/Indonesia/CDC669/2006(H5N1) was incorporated into a commercial baculovirus vector controlled by the e1 promoter from White Spot Syndrome Virus. The resulting recombinant virus was propagated in insect (Sf9) cells and inactivated as a particle vaccine [81, 82] . Intranasal delivery with cholera toxin B as an adjuvant elicited robust HI titers and protected from lethal challenge [81] . Oral delivery of this encapsulated vaccine induced robust serum HI titers and mucosal IgA titers in mice, and protected from H5N1 HPAIV challenge. More recently, co-formulations of inactivated baculovirus vectors have also been shown to be effective in mice [83] .\\n\\nWhile there is growing data on the potential use of baculovirus or pseudotyped baculovirus as a vaccine vector, efficacy data in mammalian animal models other than mice is lacking. There is also no data on the safety in humans, reducing enthusiasm for baculovirus as a vaccine vector for influenza at this time.\\n\\nNewcastle disease virus (NDV) is a single-stranded, negative-sense RNA virus that causes disease in poultry. NDV has a number of appealing qualities as a vaccine vector. As an avian virus, there is little or no preexisting immunity to NDV in humans and NDV propagates to high titers in both chicken eggs and cell culture. As a paramyxovirus, there is no DNA phase in the virus lifecycle reducing concerns of integration events, and the levels of gene expression are driven by the proximity to the leader sequence at the 3' end of the viral genome. This gradient of gene expression enables attenuation through rearrangement of the genome, or by insertion of transgenes within the genome. Finally, pathogenicity of NDV is largely determined by features of the fusion protein enabling ready attenuation of the vaccine vector [84] .\\n\\nReverse genetics, a method that allows NDV to be rescued from plasmids expressing the viral RNA polymerase and nucleocapsid proteins, was first reported in 1999 [85, 86] . This process has enabled manipulation of the NDV genome as well as incorporation of transgenes and the development of NDV vectors. Influenza was the first infectious disease targeted with a recombinant NDV (rNDV) vector. The HA protein of A/WSN/1933 (H1N1) was inserted into the Hitchner B1 vaccine strain. The HA protein was expressed on infected cells and was incorporated into infectious virions. While the virus was attenuated compared to the parental vaccine strain, it induced a robust serum antibody response and protected against homologous influenza virus challenge in a murine model of infection [87] . Subsequently, rNDV was tested as a vaccine vector for HPAIV having varying efficacy against H5 and H7 influenza virus infections in poultry [88] [89] [90] [91] [92] [93] [94] . These vaccines have the added benefit of potentially providing protection against both the influenza virus and NDV infection.\\n\\nNDV has also been explored as a vaccine vector for humans. Two NHP studies assessed the immunogenicity and efficacy of an rNDV expressing the HA or NA of A/Vietnam/1203/2004 (H5N1; VN1203) [95, 96] . Intranasal and intratracheal delivery of the rNDV-HA or rNDV-NA vaccines induced both serum and mucosal antibody responses and protected from HPAIV challenge [95, 96] . NDV has limited clinical data; however, phase I and phase I/II clinical trials have shown that the NDV vector is well-tolerated, even at high doses delivered intravenously [44, 97] . While these results are promising, additional studies are needed to advance NDV as a human vaccine vector for influenza.\\n\\nParainfluenza virus type 5 (PIV5) is a paramyxovirus vaccine vector being explored for delivery of influenza and other infectious disease vaccine antigens. PIV5 has only recently been described as a vaccine vector [98] . Similar to other RNA viruses, PIV5 has a number of features that make it an attractive vaccine vector. For example, PIV5 has a stable RNA genome and no DNA phase in virus replication cycle reducing concerns of host genome integration or modification. PIV5 can be grown to very high titers in mammalian vaccine cell culture substrates and is not cytopathic allowing for extended culture and harvest of vaccine virus [98, 99] . Like NDV, PIV5 has a 3'-to 5' gradient of gene expression and insertion of transgenes at different locations in the genome can variably attenuate the virus and alter transgene expression [100] . PIV5 has broad tropism, infecting many cell types, tissues, and species without causing clinical disease, although PIV5 has been associated with -kennel cough‖ in dogs [99] . A reverse genetics system for PIV5 was first used to insert the HA gene from A/Udorn/307/72 (H3N2) into the PIV5 genome between the hemagglutinin-neuraminidase (HN) gene and the large (L) polymerase gene. Similar to NDV, the HA was expressed at high levels in infected cells and replicated similarly to the wild type virus, and importantly, was not pathogenic in immunodeficient mice [98] . Additionally, a single intranasal immunization in a murine model of influenza infection was shown to induce neutralizing antibody responses and protect against a virus expressing homologous HA protein [98] . PIV5 has also been explored as a vaccine against HPAIV. Recombinant PIV5 vaccines expressing the HA or NP from VN1203 were tested for efficacy in a murine challenge model. Mice intranasally vaccinated with a single dose of PIV5-H5 vaccine had robust serum and mucosal antibody responses, and were protected from lethal challenge. Notably, although cellular immune responses appeared to contribute to protection, serum antibody was sufficient for protection from challenge [100, 101] . Intramuscular immunization with PIV5-H5 was also shown to be effective at inducing neutralizing antibody responses and protecting against lethal influenza virus challenge [101] . PIV5 expressing the NP protein of HPAIV was also efficacious in the murine immunization and challenge model, where a single intranasal immunization induced robust CD8 + T cell responses and protected against homologous (H5N1) and heterosubtypic (H1N1) virus challenge [102] .\\n\\nCurrently there is no clinical safety data for use of PIV5 in humans. However, live PIV5 has been a component of veterinary vaccines for -kennel cough‖ for &gt;30 years, and veterinarians and dog owners are exposed to live PIV5 without reported disease [99] . This combined with preclinical data from a variety of animal models suggests that PIV5 as a vector is likely to be safe in humans. As preexisting immunity is a concern for all virus-vectored vaccines, it should be noted that there is no data on the levels of preexisting immunity to PIV5 in humans. However, a study evaluating the efficacy of a PIV5-H3 vaccine in canines previously vaccinated against PIV5 (kennel cough) showed induction of robust anti-H3 serum antibody responses as well as high serum antibody levels to the PIV5 vaccine, suggesting preexisting immunity to the PIV5 vector may not affect immunogenicity of vaccines even with repeated use [99] .\\n\\nPoxvirus vaccines have a long history and the notable hallmark of being responsible for eradication of smallpox. The termination of the smallpox virus vaccination program has resulted in a large population of poxvirus-naï ve individuals that provides the opportunity for the use of poxviruses as vectors without preexisting immunity concerns [103] . Poxvirus-vectored vaccines were first proposed for use in 1982 with two reports of recombinant vaccinia viruses encoding and expressing functional thymidine kinase gene from herpes virus [104, 105] . Within a year, a vaccinia virus encoding the HA of an H2N2 virus was shown to express a functional HA protein (cleaved in the HA1 and HA2 subunits) and be immunogenic in rabbits and hamsters [106] . Subsequently, all ten of the primary influenza proteins have been expressed in vaccine virus [107] .\\n\\nEarly work with intact vaccinia virus vectors raised safety concerns, as there was substantial reactogenicity that hindered recombinant vaccine development [108] . Two vaccinia vectors were developed to address these safety concerns. The modified vaccinia virus Ankara (MVA) strain was attenuated by passage 530 times in chick embryo fibroblasts cultures. The second, New York vaccinia virus (NYVAC) was a plaque-purified clone of the Copenhagen vaccine strain rationally attenuated by deletion of 18 open reading frames [109] [110] [111] .\\n\\nModified vaccinia virus Ankara (MVA) was developed prior to smallpox eradication to reduce or prevent adverse effects of other smallpox vaccines [109] . Serial tissue culture passage of MVA resulted in loss of 15% of the genome, and established a growth restriction for avian cells. The defects affected late stages in virus assembly in non-avian cells, a feature enabling use of the vector as single-round expression vector in non-permissive hosts. Interestingly, over two decades ago, recombinant MVA expressing the HA and NP of influenza virus was shown to be effective against lethal influenza virus challenge in a murine model [112] . Subsequently, MVA expressing various antigens from seasonal, pandemic (A/California/04/2009, pH1N1), equine (A/Equine/Kentucky/1/81 H3N8), and HPAI (VN1203) viruses have been shown to be efficacious in murine, ferret, NHP, and equine challenge models [113] . MVA vaccines are very effective stimulators of both cellular and humoral immunity. For example, abortive infection provides native expression of the influenza antigens enabling robust antibody responses to native surface viral antigens. Concurrently, the intracellular influenza peptides expressed by the pox vector enter the class I MHC antigen processing and presentation pathway enabling induction of CD8 + T cell antiviral responses. MVA also induces CD4 + T cell responses further contributing to the magnitude of the antigen-specific effector functions [107, [112] [113] [114] [115] . MVA is also a potent activator of early innate immune responses further enhancing adaptive immune responses [116] . Between early smallpox vaccine development and more recent vaccine vector development, MVA has undergone extensive safety testing and shown to be attenuated in severely immunocompromised animals and safe for use in children, adults, elderly, and immunocompromised persons. With extensive pre-clinical data, recombinant MVA vaccines expressing influenza antigens have been tested in clinical trials and been shown to be safe and immunogenic in humans [117] [118] [119] . These results combined with data from other (non-influenza) clinical and pre-clinical studies support MVA as a leading viral-vectored candidate vaccine.\\n\\nThe NYVAC vector is a highly attenuated vaccinia virus strain. NYVAC is replication-restricted; however, it grows in chick embryo fibroblasts and Vero cells enabling vaccine-scale production. In non-permissive cells, critical late structural proteins are not produced stopping replication at the immature virion stage [120] . NYVAC is very attenuated and considered safe for use in humans of all ages; however, it predominantly induces a CD4 + T cell response which is different compared to MVA [114] . Both MVA and NYVAC provoke robust humoral responses, and can be delivered mucosally to induce mucosal antibody responses [121] . There has been only limited exploration of NYVAC as a vaccine vector for influenza virus; however, a vaccine expressing the HA from A/chicken/Indonesia/7/2003 (H5N1) was shown to induce potent neutralizing antibody responses and protect against challenge in swine [122] .\\n\\nWhile there is strong safety and efficacy data for use of NYVAC or MVA-vectored influenza vaccines, preexisting immunity remains a concern. Although the smallpox vaccination campaign has resulted in a population of poxvirus-naï ve people, the initiation of an MVA or NYVAC vaccination program for HIV, influenza or other pathogens will rapidly reduce this susceptible population. While there is significant interest in development of pox-vectored influenza virus vaccines, current influenza vaccination strategies rely upon regular immunization with vaccines matched to circulating strains. This would likely limit the use and/or efficacy of poxvirus-vectored influenza virus vaccines for regular and seasonal use [13] . Intriguingly, NYVAC may have an advantage for use as an influenza vaccine vector, because immunization with this vector induces weaker vaccine-specific immune responses compared to other poxvirus vaccines, a feature that may address the concerns surrounding preexisting immunity [123] .\\n\\nWhile poxvirus-vectored vaccines have not yet been approved for use in humans, there is a growing list of licensed poxvirus for veterinary use that include fowlpox-and canarypox-vectored vaccines for avian and equine influenza viruses, respectively [124, 125] . The fowlpox-vectored vaccine expressing the avian influenza virus HA antigen has the added benefit of providing protection against fowlpox infection. Currently, at least ten poxvirus-vectored vaccines have been licensed for veterinary use [126] . These poxvirus vectors have the potential for use as vaccine vectors in humans, similar to the first use of cowpox for vaccination against smallpox [127] . The availability of these non-human poxvirus vectors with extensive animal safety and efficacy data may address the issues with preexisting immunity to the human vaccine strains, although the cross-reactivity originally described with cowpox could also limit use.\\n\\nInfluenza vaccines utilizing vesicular stomatitis virus (VSV), a rhabdovirus, as a vaccine vector have a number of advantages shared with other RNA virus vaccine vectors. Both live and replication-defective VSV vaccine vectors have been shown to be immunogenic [128, 129] , and like Paramyxoviridae, the Rhabdoviridae genome has a 3'-to-5' gradient of gene expression enabling attention by selective vaccine gene insertion or genome rearrangement [130] . VSV has a number of other advantages including broad tissue tropism, and the potential for intramuscular or intranasal immunization. The latter delivery method enables induction of mucosal immunity and elimination of needles required for vaccination. Also, there is little evidence of VSV seropositivity in humans eliminating concerns of preexisting immunity, although repeated use may be a concern. Also, VSV vaccine can be produced using existing mammalian vaccine manufacturing cell lines.\\n\\nInfluenza antigens were first expressed in a VSV vector in 1997. Both the HA and NA were shown to be expressed as functional proteins and incorporated into the recombinant VSV particles [131] . Subsequently, VSV-HA, expressing the HA protein from A/WSN/1933 (H1N1) was shown to be immunogenic and protect mice from lethal influenza virus challenge [129] . To reduce safety concerns, attenuated VSV vectors were developed. One candidate vaccine had a truncated VSV G protein, while a second candidate was deficient in G protein expression and relied on G protein expressed by a helper vaccine cell line to the provide the virus receptor. Both vectors were found to be attenuated in mice, but maintained immunogenicity [128] . More recently, single-cycle replicating VSV vaccines have been tested for efficacy against H5N1 HPAIV. VSV vectors expressing the HA from A/Hong Kong/156/97 (H5N1) were shown to be immunogenic and induce cross-reactive antibody responses and protect against challenge with heterologous H5N1 challenge in murine and NHP models [132] [133] [134] .\\n\\nVSV vectors are not without potential concerns. VSV can cause disease in a number of species, including humans [135] . The virus is also potentially neuroinvasive in some species [136] , although NHP studies suggest this is not a concern in humans [137] . Also, while the incorporation of the influenza antigen in to the virion may provide some benefit in immunogenicity, changes in tropism or attenuation could arise from incorporation of different influenza glycoproteins. There is no evidence for this, however [134] . Currently, there is no human safety data for VSV-vectored vaccines. While experimental data is promising, additional work is needed before consideration for human influenza vaccination.\\n\\nCurrent influenza vaccines rely on matching the HA antigen of the vaccine with circulating strains to provide strain-specific neutralizing antibody responses [4, 14, 24] . There is significant interest in developing universal influenza vaccines that would not require annual reformulation to provide protective robust and durable immunity. These vaccines rely on generating focused immune responses to highly conserved portions of the virus that are refractory to mutation [30] [31] [32] . Traditional vaccines may not be suitable for these vaccination strategies; however, vectored vaccines that have the ability to be readily modified and to express transgenes are compatible for these applications.\\n\\nThe NP and M2 proteins have been explored as universal vaccine antigens for decades. Early work with recombinant viral vectors demonstrated that immunization with vaccines expressing influenza antigens induced potent CD8 + T cell responses [107, [138] [139] [140] [141] . These responses, even to the HA antigen, could be cross-protective [138] . A number of studies have shown that immunization with NP expressed by AAV, rAd5, alphavirus vectors, MVA, or other vector systems induces potent CD8 + T cell responses and protects against influenza virus challenge [52, 63, 69, 102, 139, 142] . As the NP protein is highly conserved across influenza A viruses, NP-specific T cells can protect against heterologous and even heterosubtypic virus challenges [30] .\\n\\nThe M2 protein is also highly conserved and expressed on the surface of infected cells, although to a lesser extent on the surface of virus particles [30] . Much of the vaccine work in this area has focused on virus-like or subunit particles expressing the M2 ectodomain; however, studies utilizing a DNA-prime, rAd-boost strategies to vaccinate against the entire M2 protein have shown the antigen to be immunogenic and protective [50] . In these studies, antibodies to the M2 protein protected against homologous and heterosubtypic challenge, including a H5N1 HPAIV challenge. More recently, NP and M2 have been combined to induce broadly cross-reactive CD8 + T cell and antibody responses, and rAd5 vaccines expressing these antigens have been shown to protect against pH1N1 and H5N1 challenges [29, 51] .\\n\\nHistorically, the HA has not been widely considered as a universal vaccine antigen. However, the recent identification of virus neutralizing monoclonal antibodies that cross-react with many subtypes of influenza virus [143] has presented the opportunity to design vaccine antigens to prime focused antibody responses to the highly conserved regions recognized by these monoclonal antibodies. The majority of these broadly cross-reactive antibodies recognize regions on the stalk of the HA protein [143] . The HA stalk is generally less immunogenic compared to the globular head of the HA protein so most approaches have utilized -headless‖ HA proteins as immunogens. HA stalk vaccines have been designed using DNA and virus-like particles [144] and MVA [142] ; however, these approaches are amenable to expression in any of the viruses vectors described here.\\n\\nThe goal of any vaccine is to protect against infection and disease, while inducing population-based immunity to reduce or eliminate virus transmission within the population. It is clear that currently licensed influenza vaccines have not fully met these goals, nor those specific to inducing long-term, robust immunity. There are a number of vaccine-related issues that must be addressed before population-based influenza vaccination strategies are optimized. The concept of a -one size fits all‖ vaccine needs to be updated, given the recent ability to probe the virus-host interface through RNA interference approaches that facilitate the identification of host genes affecting virus replication, immunity, and disease. There is also a need for revision of the current influenza virus vaccine strategies for at-risk populations, particularly those at either end of the age spectrum. An example of an improved vaccine regime might include the use of a vectored influenza virus vaccine that expresses the HA, NA and M and/or NP proteins for the two currently circulating influenza A subtypes and both influenza B strains so that vaccine take and vaccine antigen levels are not an issue in inducing protective immunity. Recombinant live-attenuated or replication-deficient influenza viruses may offer an advantage for this and other approaches.\\n\\nVectored vaccines can be constructed to express full-length influenza virus proteins, as well as generate conformationally restricted epitopes, features critical in generating appropriate humoral protection. Inclusion of internal influenza antigens in a vectored vaccine can also induce high levels of protective cellular immunity. To generate sustained immunity, it is an advantage to induce immunity at sites of inductive immunity to natural infection, in this case the respiratory tract. Several vectored vaccines target the respiratory tract. Typically, vectored vaccines generate antigen for weeks after immunization, in contrast to subunit vaccination. This increased presence and level of vaccine antigen contributes to and helps sustain a durable memory immune response, even augmenting the selection of higher affinity antibody secreting cells. The enhanced memory response is in part linked to the intrinsic augmentation of immunity induced by the vector. Thus, for weaker antigens typical of HA, vectored vaccines have the capacity to overcome real limitations in achieving robust and durable protection.\\n\\nMeeting the mandates of seasonal influenza vaccine development is difficult, and to respond to a pandemic strain is even more challenging. Issues with influenza vaccine strain selection based on recently circulating viruses often reflect recommendations by the World Health Organization (WHO)-a process that is cumbersome. The strains of influenza A viruses to be used in vaccine manufacture are not wild-type viruses but rather reassortants that are hybrid viruses containing at least the HA and NA gene segments from the target strains and other gene segments from the master strain, PR8, which has properties of high growth in fertilized hen's eggs. This additional process requires more time and quality control, and specifically for HPAI viruses, it is a process that may fail because of the nature of those viruses. In contrast, viral-vectored vaccines are relatively easy to manipulate and produce, and have well-established safety profiles. There are several viral-based vectors currently employed as antigen delivery systems, including poxviruses, adenoviruses baculovirus, paramyxovirus, rhabdovirus, and others; however, the majority of human clinical trials assessing viral-vectored influenza vaccines use poxvirus and adenovirus vectors. While each of these vector approaches has unique features and is in different stages of development, the combined successes of these approaches supports the virus-vectored vaccine approach as a whole. Issues such as preexisting immunity and cold chain requirements, and lingering safety concerns will have to be overcome; however, each approach is making progress in addressing these issues, and all of the approaches are still viable. Virus-vectored vaccines hold particular promise for vaccination with universal or focused antigens where traditional vaccination methods are not suited to efficacious delivery of these antigens. The most promising approaches currently in development are arguably those targeting conserved HA stalk region epitopes. Given the findings to date, virus-vectored vaccines hold great promise and may overcome the current limitations of influenza vaccines.</td>\n",
              "      <td>1719</td>\n",
              "      <td>1637</td>\n",
              "      <td>False</td>\n",
              "      <td>What vaccinia vectors were created to address safety concerns?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9qywopnIrJH"
      },
      "source": [
        "## Preprocessing the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVx71GdAIrJH"
      },
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
        "\n",
        "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
        "\n",
        "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
        "- we download the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "f39221bcd1d04343bb5086ab20ab3a50",
            "eb67899c4b5b441db55fc3358591cf6a",
            "986fff7fa6a94eb8ad3528e783fff9f9",
            "9146d89fc11e4cb29179cd0680c431dc",
            "8b14bcab4f4b4b85b6130a123ac1c458",
            "054347a3ad5147b6b330603c1f3df667",
            "b74cc6ce8a8c4f51907e92c88d7598cc",
            "c181550174b24acaa737f4250dd7a7eb",
            "5b4f421f2da048e5b5d0077ef27f133e",
            "50ebc97a5d3e4b96b0e22a87e29d055d",
            "c0a9b00a9437414b8cc71dc5b6c5cf04",
            "051f2da910834885bfcc5e5b96f59bea",
            "3581e333280f46529507ff4f483cf18c",
            "e2452e2e66ee47db9b4ba54892f470a8",
            "c643cf0d44a94fb0b80d900a1e1d0be5",
            "b359c762de234685bdc9eeb36e5856cc",
            "0ad29b56da5d41c2ba939fb7aaa1e8c8",
            "5b4eff535d614b9d830ef7d6bc44b6c8",
            "47072111339b4da2b1cc789c4857ea35",
            "a3b77760ba1a4136a54d757a898f4623",
            "7c59f032049b43198dfc9cc23e7a0178",
            "1313c17624234847a37d86e012ec1527",
            "e1bfca2f821949deba02e5ec49371ddb",
            "38e2f6384ebd4e148a543e60c15fd49e",
            "9b6ec617cad14611a67491b2145e83e5",
            "f3aaf7eacedf442d98db1d9a37074a16",
            "7bcccd6719ff4e779685236f4ac789f2",
            "a32bbea16bb742a99d0d375f2e5ad6cc",
            "1ec1e5a0f7974f03899606348e9675e5",
            "92a96f8c9a6946d2aea7d0554f627c43",
            "06bf206781a645c78332893b8b6ebb58",
            "eee78f3e6f3e478baa6c10c52e114791"
          ]
        },
        "outputId": "a51245eb-0cc6-4a01-c755-6da48de92b0c"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f39221bcd1d04343bb5086ab20ab3a50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b4f421f2da048e5b5d0077ef27f133e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ad29b56da5d41c2ba939fb7aaa1e8c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b6ec617cad14611a67491b2145e83e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl6IidfdIrJK"
      },
      "source": [
        "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x1DUx_l9cs3"
      },
      "source": [
        "import transformers\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vdFCDTK9cs4"
      },
      "source": [
        "You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rowT4iCLIrJK"
      },
      "source": [
        "You can directly call this tokenizer on two sentences (one for the answer, one for the context):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5hBlsrHIrJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a558e46f-60b7-4df1-cd9c-7b0e474d99c8"
      },
      "source": [
        "tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcKkiyXZ9cs4"
      },
      "source": [
        "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
        "\n",
        "Now one specific thing for the preprocessing in question answering is how to deal with very long documents. We usually truncate them in other tasks, when they are longer than the model maximum sentence length, but here, removing part of the the context might result in losing the answer we are looking for. To deal with this, we will allow one (long) example in our dataset to give several input features, each of length shorter than the maximum length of the model (or the one we set as a hyper-parameter). Also, just in case the answer lies at the point we split a long context, we allow some overlap between the features we generate controlled by the hyper-parameter `doc_stride`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO0kcG8j9cs5"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chc24MxJ9cs5"
      },
      "source": [
        "Let's find one long example in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiPyUS3x9cs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91710c7-c168-4878-dfc0-bd6dae6f112c"
      },
      "source": [
        "for i, example in enumerate(datasets[\"train\"]):\n",
        "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
        "        break\n",
        "example = datasets[\"train\"][i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5818 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdv-h7ZC9cs6"
      },
      "source": [
        "Without any truncation, we get the following length for the input IDs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmf9naV9cs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2b3ff2-93a9-476b-c85b-fc803f40e44b"
      },
      "source": [
        "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLkqnyX39cs7"
      },
      "source": [
        "Now, if we just truncate, we will lose information (and possibly the answer to our question):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TAOdp19cs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e8c079-f215-49ed-efcc-5be5477ccde5"
      },
      "source": [
        "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmkoAhpS9cs8"
      },
      "source": [
        "Note that we never want to truncate the question, only the context, else the `only_second` truncation picked. Now, our tokenizer can automatically return us a list of features capped by a certain maximum length, with the overlap we talked above, we just have to tell it with `return_overflowing_tokens=True` and by passing the stride:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_GZnIKI9cs9"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    stride=doc_stride\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jecy03IX9cs9"
      },
      "source": [
        "Now we don't have one list of `input_ids`, but several: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shaSdrOx9cs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb65379-74f5-40a7-a9c6-05095ba96a1d"
      },
      "source": [
        "[len(x) for x in tokenized_example[\"input_ids\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384,\n",
              " 384]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_YQHpkd9cs9"
      },
      "source": [
        "And if we decode them, we can see the overlap:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110n-0t09cs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb7e60b-1b3f-4f8b-f77a-bcf34eb699c8"
      },
      "source": [
        "for x in tokenized_example[\"input_ids\"][:2]:\n",
        "    print(tokenizer.decode(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] what can nuclear receptors regulate? [SEP] inr - drug : predicting the interaction of drugs with nuclear receptors in cellular networking https : / / www. ncbi. nlm. nih. gov / pmc / articles / pmc3975431 / sha : ee55aea26f816403476a7cb71816b8ecb1110329 authors : fan, yue - nong ; xiao, xuan ; min, jian - liang ; chou, kuo - chen date : 2014 - 03 - 19 doi : 10. 3390 / ijms15034915 license : cc - by abstract : nuclear receptors ( nrs ) are closely associated with various major diseases such as cancer, diabetes, inflammatory disease, and osteoporosis. therefore, nrs have become a frequent target for drug development. during the process of developing drugs against these diseases by targeting nrs, we are often facing a problem : given a nr and chemical compound, can we identify whether they are really in interaction with each other in a cell? to address this problem, a predictor called “ inr - drug ” was developed. in the predictor, the drug compound concerned was formulated by a 256 - d ( dimensional ) vector derived from its molecular fingerprint, and the nr by a 500 - d vector formed by incorporating its sequential evolution information and physicochemical features into the general form of pseudo amino acid composition, and the prediction engine was operated by the svm ( support vector machine ) algorithm. compared with the existing prediction methods in this area, inr - drug not only can yield a higher success rate, but is also featured by a user - friendly web - server established at http : / / www. jci - bioinfo. cn / inr - drug /, which is particularly useful for most experimental scientists to [SEP]\n",
            "[CLS] what can nuclear receptors regulate? [SEP] d ( dimensional ) vector derived from its molecular fingerprint, and the nr by a 500 - d vector formed by incorporating its sequential evolution information and physicochemical features into the general form of pseudo amino acid composition, and the prediction engine was operated by the svm ( support vector machine ) algorithm. compared with the existing prediction methods in this area, inr - drug not only can yield a higher success rate, but is also featured by a user - friendly web - server established at http : / / www. jci - bioinfo. cn / inr - drug /, which is particularly useful for most experimental scientists to obtain their desired data in a timely manner. it is anticipated that the inr - drug server may become a useful high throughput tool for both basic research and drug development, and that the current approach may be easily extended to study the interactions of drug with other targets as well. text : with the ability to directly bind to dna ( figure 1 ) and regulate the expression of adjacent genes, nuclear receptors ( nrs ) are a class of ligand - inducible transcription factors. they regulate various biological processes, such as homeostasis, differentiation, embryonic development, and organ physiology [ 1 ] [ 2 ] [ 3 ]. the nr superfamily has been classified into seven families : nr0 ( knirps or dax like ) [ 4, 5 ] ; nr1 ( thyroid hormone like ), nr2 ( hnf4 - like ), nr3 ( estrogen like ), nr4 ( nerve growth factor ib - like ), nr5 ( fushi tarazu - f1 like ), and nr6 ( germ cell nuclear factor like ). since they are involved in almost all aspects of human physiology and are implicated in many major diseases such as cancer, diabetes and osteoporosis, nuclear receptors have [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swGrMiXu9cs-"
      },
      "source": [
        "Now this will give us some work to properly treat the answers: we need to find in which of those features the answer actually is, and where exactly in that feature. The models we will use require the start and end positions of these answers in the tokens, so we will also need to to map parts of the original context to some tokens. Thankfully, the tokenizer we're using can help us with that by returning an `offset_mapping`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGHfmo1X9cs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14527cf1-0e3f-42b1-fb6d-2d2dbcd9739f"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    stride=doc_stride\n",
        ")\n",
        "print(tokenized_example[\"offset_mapping\"][0][:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0), (0, 4), (5, 8), (9, 16), (17, 26), (27, 35), (35, 36), (0, 0), (0, 2), (2, 3), (3, 4), (4, 8), (8, 9), (10, 20), (21, 24), (25, 36), (37, 39), (40, 45), (46, 50), (51, 58), (59, 68), (69, 71), (72, 80), (81, 91), (93, 98), (98, 99), (99, 100), (100, 101), (101, 104), (104, 105), (105, 107), (107, 109), (109, 110), (110, 112), (112, 113), (113, 114), (114, 116), (116, 117), (117, 118), (118, 121), (121, 122), (122, 124), (124, 125), (125, 126), (126, 134), (134, 135), (135, 137), (137, 138), (138, 140), (140, 142), (142, 144), (144, 145), (145, 146), (148, 151), (151, 152), (153, 155), (155, 157), (157, 160), (160, 162), (162, 163), (163, 164), (164, 166), (166, 168), (168, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 176), (176, 177), (177, 179), (179, 181), (181, 182), (182, 183), (183, 185), (185, 186), (186, 188), (188, 190), (190, 192), (192, 193), (195, 202), (202, 203), (204, 207), (207, 208), (209, 212), (212, 213), (213, 216), (216, 217), (217, 218), (219, 223), (223, 224), (225, 227), (227, 229), (229, 230), (231, 234), (234, 235), (236, 240), (240, 241), (241, 246), (246, 247)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFiGXYEr9cs_"
      },
      "source": [
        "This gives, for each index of our input IDS, the corresponding start and end character in the original text that gave our token. The very first token (`[CLS]`) has (0, 0) because it doesn't correspond to any part of the question/answer, then the second token is the same as the characters 0 to 3 of the question:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jScQN1l89cs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9d71d0-a67d-4ffc-9c3b-e000a90e94fb"
      },
      "source": [
        "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
        "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
        "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what What\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI6r5gCo9cs_"
      },
      "source": [
        "So we can use this mapping to find the position of the start and end tokens of our answer in a given feature. We just have to distinguish which parts of the offsets correspond to the question and which part correspond to the context, this is where the `sequence_ids` method of our `tokenized_example` can be useful:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MblYjNk9cs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8e45bc-d28a-49df-8fd7-5914f3dc44a0"
      },
      "source": [
        "sequence_ids = tokenized_example.sequence_ids()\n",
        "print(sequence_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZov03gY9ctA"
      },
      "source": [
        "It returns `None` for the special tokens, then 0 or 1 depending on whether the corresponding token comes from the first sentence past (the question) or the second (the context). Now with all of this, we can find the first and last token of the answer in one of our input feature (or if the answer is not in this feature):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxHywWU-9ctA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec829d28-d3dd-443c-9aef-bb5c3c0efc4e"
      },
      "source": [
        "answers = example[\"answers\"]\n",
        "start_char = answers[\"answer_start\"][0]\n",
        "end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "# Start token index of the current span in the text.\n",
        "token_start_index = 0\n",
        "while sequence_ids[token_start_index] != 1:\n",
        "    token_start_index += 1\n",
        "\n",
        "# End token index of the current span in the text.\n",
        "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "while sequence_ids[token_end_index] != 1:\n",
        "    token_end_index -= 1\n",
        "\n",
        "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "        token_start_index += 1\n",
        "    start_position = token_start_index - 1\n",
        "    while offsets[token_end_index][1] >= end_char:\n",
        "        token_end_index -= 1\n",
        "    end_position = token_end_index + 1\n",
        "    print(start_position, end_position)\n",
        "else:\n",
        "    print(\"The answer is not in this feature.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The answer is not in this feature.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KP5Zj8X9ctA"
      },
      "source": [
        "And we can double check that it is indeed the theoretical answer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMB4MzXc9ctB"
      },
      "source": [
        "# print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
        "# print(answers[\"text\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4M_X_QG9ctB"
      },
      "source": [
        "For this notebook to work with any kind of models, we need to account for the special case where the model expects padding on the left (in which case we switch the order of the question and the context):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuTolAUU9ctB"
      },
      "source": [
        "pad_on_right = tokenizer.padding_side == \"right\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNLrOvz49ctB"
      },
      "source": [
        "Now let's put everything together in one function we will apply to our training set. In the case of impossible answers (the answer is in another feature given by an example with a long context), we set the cls index for both the start and end position. We could also simply discard those examples from the training set if the flag `allow_impossible_answers` is `False`. Since the preprocessing is already complex enough as it is, we've kept is simple for this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QaapZj9ctC"
      },
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lm8ozrJIrJR"
      },
      "source": [
        "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b70jh26IrJS"
      },
      "source": [
        "features = prepare_train_features(datasets['train'][:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS-6iXTkIrJT"
      },
      "source": [
        "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command. Since our preprocessing changes the number of samples, we need to remove the old columns when applying it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "dbdfc0f38bb54d2dac9ab88c49480a90",
            "41514283be5e4619b9ef2d2df60aa73b",
            "8decb6fff596423e8914b0ee82073f13",
            "fbf248190c7e4d138bdf51e7f9104ba4",
            "84a3ccfcb4164da9838829860593ab02",
            "1351ac5c1a3b4d948acdd99dc523a188",
            "e2263514808e458bbc9f77e2a5a77aa5",
            "6b7282d8bde043ac83a7dd641cfc6a5f",
            "69aa393a09374549a3666d85e74747d9",
            "84edfdb818884b039d15173e3ddb3175",
            "996bdd04d27a44d0b1be1832e6cfd333",
            "6198fe6a9dfb4401a7b88c7b5a1d3839",
            "eed8b7e123cb431bb684751b6bcfb3ba",
            "974efb77e1bf48e4b6c238a7000bf75e",
            "9739a9ee148b4e71b31e854ae2ff081b",
            "ce97202ebc0e400299c9f499427f8ff9"
          ]
        },
        "outputId": "6dde4a5b-701e-4941-c920-25c494e65621"
      },
      "source": [
        "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbdfc0f38bb54d2dac9ab88c49480a90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69aa393a09374549a3666d85e74747d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voWiw8C7IrJV"
      },
      "source": [
        "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBiW8UpKIrJW"
      },
      "source": [
        "Now that our data is ready for training, we can download the pretrained model and fine-tune it. Since our task is question answering, we use the `AutoModelForQuestionAnswering` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "33127e677cf442468b45c2c221e8d2ca",
            "801683f93ddd4a939b83bfa23ca5dd89",
            "075b5311e14144b7a30e72acf8f3f033",
            "3e7663e1ebe149c093256c79d9bedc55",
            "a604b99027cb4affbfa080702124b486",
            "43348bcdcccf4c069db9ae32fcb20e70",
            "ff68bbaa23c34e17a19a9dc2e595bd92",
            "bcf57b4f018f4adf91cbe7228ba43379"
          ]
        },
        "outputId": "dc4a5237-1f02-48c4-99d1-1333c0aa7a8f"
      },
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33127e677cf442468b45c2c221e8d2ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CczA5lJlIrJX"
      },
      "source": [
        "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N8urzhyIrJY"
      },
      "source": [
        "To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bliy8zgjIrJY"
      },
      "source": [
        "args = TrainingArguments(\n",
        "    f\"test-squad\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km3pGVdTIrJc"
      },
      "source": [
        "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHpKDZM-9ctF"
      },
      "source": [
        "Then we will need a data collator that will batch our processed examples together, here the default one will work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILmIwJaA9ctF"
      },
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "data_collator = default_data_collator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXuFTAzDIrJe"
      },
      "source": [
        "We will evaluate our model and compute metrics in the next section (this is a very long operation, so we will only compute the evaluation loss during training).\n",
        "\n",
        "Then we just need to pass all of this along with our datasets to the `Trainer`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imY1oC3SIrJf"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzABDVcIrJg"
      },
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNx5pyRlIrJh"
      },
      "source": [
        "# trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9f1Z0rb9ctG"
      },
      "source": [
        "Since this training is particularly long, let's save the model just in case we need to restart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rLQGSnD9ctG"
      },
      "source": [
        "# trainer.save_model(\"distil-covid-trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nPvAZtk9ctG"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPN7XhHC9ctH"
      },
      "source": [
        "Evaluating our model will require a bit more work, as we will need to map the predictions of our model back to parts of the context. The model itself predicts logits for the start and en position of our answers: if we take a batch from our validation datalaoder, here is the output our model gives us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkp5oK29ctH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330b3638-36b0-40bf-a666-7b99f5a77718"
      },
      "source": [
        "import torch\n",
        "\n",
        "for batch in trainer.get_eval_dataloader():\n",
        "    break\n",
        "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
        "with torch.no_grad():\n",
        "    output = trainer.model(**batch)\n",
        "output.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'start_logits', 'end_logits'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtpoYs0z9ctI"
      },
      "source": [
        "The output of the model is a dict-like object that contains the loss (since we provided labels), the start and end logits. We won't need the loss for our predictions, let's have a look a the logits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX6ScXqh9ctI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5944a2-95e6-4c33-9b33-3e102caa599d"
      },
      "source": [
        "output.start_logits.shape, output.end_logits.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 384]), torch.Size([32, 384]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAU7jFAM9ctI"
      },
      "source": [
        "We have one logit for each feature and each token. The most obvious thing to predict an answer for each featyre is to take the index for the maximum of the start logits as a start position and the index of the maximum of the end logits as an end position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqvOMsp9ctI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6afb04ee-4cf1-4b0b-b98e-aede04ef5e0d"
      },
      "source": [
        "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 77, 339, 155,  19, 378, 138, 145, 172, 257, 365, 125, 346, 309, 316,\n",
              "         223, 358, 237, 295, 306, 287, 377, 318, 323, 341, 101,  32, 276,  36,\n",
              "         107,  33,  18,  60], device='cuda:0'),\n",
              " tensor([ 96, 146,  79, 115, 370, 251, 145, 172, 187, 178, 214, 361, 121, 316,\n",
              "         223, 202, 237, 158, 122, 328,  88, 253, 190,  85, 156, 154, 306, 172,\n",
              "         151,  33, 230, 211], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMg6A6t9ctI"
      },
      "source": [
        "This will work great in a lot of cases, but what if this prediction gives us something impossible: the start position could be greater than the end position, or point to a span of text in the question instead of the answer. In that case, we might want to look at the second best prediction to see if it gives a possible answer and select that instead.\n",
        "\n",
        "However, picking the second best answer is not as easy as picking the best one: is it the second best index in the start logits with the best index in the end logits? Or the best index in the start logits with the second best index in the end logits? And if that second best answer is not possible either, it gets even trickier for the third best answer.\n",
        "\n",
        "\n",
        "To classify our answers, we will use the score obtained by adding the start and end logits. We won't try to order all the possible answers and limit ourselves to with a hyper-parameter we call `n_best_size`. We'll pick the best indices in the start and end logits and gather all the answers this predicts. After checking if each one is valid, we will sort them by their score and keep the best one. Here is how we would do this on the first feature in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv6pJ_B9ctJ"
      },
      "source": [
        "n_best_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICFbFU-19ctJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n",
        "                }\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFjwP8sH9ctJ"
      },
      "source": [
        "And then we can sort the `valid_answers` according to their `score` and only keep the best one. The only point left is how to check a given span is inside the context (and not the question) and how to get back the text inside. To do this, we need to add two things to our validation features:\n",
        "- the ID of the example that generated the feature (since each example can generate several features, as seen before);\n",
        "- the offset mapping that will give us a map from token indices to character positions in the context.\n",
        "\n",
        "That's why we will re-process the validation set with the following function, slightly different from `prepare_train_features`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL83DAkA9ctJ"
      },
      "source": [
        "def prepare_validation_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-KjpxL9ctJ"
      },
      "source": [
        "And like before, we can apply that function to our validation set easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr5VEPrW9ctK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2a189cbf292844a7b44b12f24ffcf4b9",
            "01b8f2fdcdd14e3685e4b5ce01506e21",
            "97927561c9d24ede95920bfb7eac7aef",
            "4b53b3670b3840a1a98160f6db775ea8",
            "5870d1683f654fb8b6cd3ab8ff1c1cea",
            "f11b9d27abb948efa431386ab4f5662d",
            "edb2c517271141679cdfc5c24077f65c",
            "25bb5ad22b12431c832ee32c1f1e2e2f"
          ]
        },
        "outputId": "7f8fa915-f10f-43a8-803c-a0acc550ebb5"
      },
      "source": [
        "validation_features = datasets[\"validation\"].map(\n",
        "    prepare_validation_features,\n",
        "    batched=True,\n",
        "    remove_columns=datasets[\"validation\"].column_names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a189cbf292844a7b44b12f24ffcf4b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amE-12DP9ctL"
      },
      "source": [
        "Now we can grab the predictions for all features by using the `Trainer.predict` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x43ECvME9ctL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "2415256a-4ae3-409a-cf30-371448129217"
      },
      "source": [
        "raw_predictions = trainer.predict(validation_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [192/192 01:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CPRYpDz9ctM"
      },
      "source": [
        "The `Trainer` *hides* the columns that are not used by the model (here `example_id` and `offset_mapping` which we will need for our post-processing), so we set them back:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP2mqlQ29ctM"
      },
      "source": [
        "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tvgv38H9ctM"
      },
      "source": [
        "We can now refine the test we had before: since we set `None` in the offset mappings when it corresponds to a part of the question, it's easy to check if an answer is fully inside the context. We also eliminate very long answers from our considerations (with an hyper-parameter we can tune)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67KqQEoe9ctM"
      },
      "source": [
        "max_answer_length = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLBwOxk39ctN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c18749-e88a-4122-aec9-94d51aede8ea"
      },
      "source": [
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
        "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
        "# an example index\n",
        "context = datasets[\"validation\"][0][\"context\"]\n",
        "\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "        # to part of the input_ids that are not in the context.\n",
        "        if (\n",
        "            start_index >= len(offset_mapping)\n",
        "            or end_index >= len(offset_mapping)\n",
        "            or offset_mapping[start_index] is None\n",
        "            or offset_mapping[end_index] is None\n",
        "        ):\n",
        "            continue\n",
        "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "            continue\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            start_char = offset_mapping[start_index][0]\n",
        "            end_char = offset_mapping[end_index][1]\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": context[start_char: end_char]\n",
        "                }\n",
        "            )\n",
        "\n",
        "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "valid_answers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 1.291454,\n",
              "  'text': ', Anne-Laure; Zijenah, Lynn S.; Humphrey, Jean H.'},\n",
              " {'score': 1.2803247, 'text': ', Anne-Laure; Zijenah, Lynn S.'},\n",
              " {'score': 1.2514489,\n",
              "  'text': ', Anne-Laure; Zijenah, Lynn S.; Humphrey, Jean H.; Mouland, Andrew J.'},\n",
              " {'score': 1.218819, 'text': ','},\n",
              " {'score': 1.1993948, 'text': ', Brian J.'},\n",
              " {'score': 1.1938689, 'text': ', Jean H.'},\n",
              " {'score': 1.1680977,\n",
              "  'text': ', Geneviève; Iscache, Anne-Laure; Zijenah, Lynn S.; Humphrey, Jean H.'},\n",
              " {'score': 1.1609994, 'text': ', Lynn S.; Humphrey, Jean H.'},\n",
              " {'score': 1.1569684,\n",
              "  'text': ', Geneviève; Iscache, Anne-Laure; Zijenah, Lynn S.'},\n",
              " {'score': 1.1538638, 'text': ', Jean H.; Mouland, Andrew J.'},\n",
              " {'score': 1.1498702, 'text': ', Lynn S.'},\n",
              " {'score': 1.148658, 'text': ', Jean H.; Mouland, Andrew J.; Ward, Brian J.'},\n",
              " {'score': 1.1367645, 'text': ', Andrew J.'},\n",
              " {'score': 1.1316233, 'text': ','},\n",
              " {'score': 1.1315587, 'text': ', Andrew J.; Ward, Brian J.'},\n",
              " {'score': 1.1209943,\n",
              "  'text': ', Lynn S.; Humphrey, Jean H.; Mouland, Andrew J.'},\n",
              " {'score': 1.1166674,\n",
              "  'text': ', Brian J.; Roger, Michel\\n2009-10-07\\nDOI:10.1371/journal.pone.'},\n",
              " {'score': 1.1157885,\n",
              "  'text': ', Lynn S.; Humphrey, Jean H.; Mouland, Andrew J.; Ward, Brian J.'},\n",
              " {'score': 1.0820787,\n",
              "  'text': ', we carried out a genetic association study of DC-SIGNR in a well-characterized cohort'},\n",
              " {'score': 1.0738182,\n",
              "  'text': ', we carried out a genetic association study of DC-SIGNR in a well-characterized co'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_X6jPvS9ctN"
      },
      "source": [
        "We can compare to the actual ground-truth answer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpehUdr29ctN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6a4abf-8d07-436c-dc5c-002ae1bd9b53"
      },
      "source": [
        "datasets[\"validation\"][0][\"answers\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': [370],\n",
              " 'text': ['Mother-to-child transmission (MTCT) is the main cause of HIV-1 infection in children worldwide.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uXbNGJR9ctN"
      },
      "source": [
        "Our model picked the right as the most likely answer!\n",
        "\n",
        "As we mentioned in the code above, this was easy on the first feature because we knew it comes from the first example. For the other features, we will need a map between examples and their corresponding features. Also, since one example can give several features, we will need to gather together all the answers in all the features generated by a given example, then pick the best one. The following code builds a map from example index to its corresponding features indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS7E-65_9ctO"
      },
      "source": [
        "import collections\n",
        "\n",
        "examples = datasets[\"validation\"]\n",
        "features = validation_features\n",
        "\n",
        "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "features_per_example = collections.defaultdict(list)\n",
        "for i, feature in enumerate(features):\n",
        "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROM9a3Ex9ctO"
      },
      "source": [
        "We're almost ready for our post-processing function. The last bit to deal with is the impossible answer (when `squad_v2 = True`). The code above only keeps answers that are inside the context, we need to also grab the score for the impossible answer (which has start and end indices corresponding to the index of the CLS token). When one example gives several features, we have to predict the impossible answer when all the features give a high score to the impossible answer (since one feature could predict the impossible answer just because the answer isn't in the part of the context it has access too), which is why the score of the impossible answer for one example is the *minimum* of the scores for the impossible answer in each feature generated by the example.\n",
        "\n",
        "We then predict the impossible answer when that score is greater than the score of the best non-impossible answer. All combined together, this gives us this post-processing function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-hMtfYr9ctO"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Logging.\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "\n",
        "        min_null_score = None # Only used if squad_v2 is True.\n",
        "        valid_answers = []\n",
        "        \n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\n",
        "                min_null_score = feature_null_score\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "        \n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
        "        if not squad_v2:\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "        else:\n",
        "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
        "            predictions[example[\"id\"]] = answer\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYvajPWv9ctO"
      },
      "source": [
        "And we can apply our post-processing function to our raw predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPxBukOn9ctO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "304c8a10c86948f5a31aac20904cb0be",
            "74a1ad52d44b4b4ea231022c50c69fa2",
            "54508f4a996e4ded830c878db487e5a1",
            "23aa82505bd9421aa90e8d7b2e18d55f",
            "2d4cadd0318d4670acb70077a026e2ad",
            "b3c323a042ac49649b03519a0cd7e6d1",
            "d2d05e21c60c4c758715aa51d66f85f6",
            "b28a357f92544b569a0305db6d3bb4ca"
          ]
        },
        "outputId": "c04c9a5e-ec4e-4aa6-99ec-bc92eedae8b4"
      },
      "source": [
        "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post-processing 300 example predictions split into 6116 features.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "304c8a10c86948f5a31aac20904cb0be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LDg4DuFUISi",
        "outputId": "a26419db-a6cd-4b9b-de17-21de637096f6"
      },
      "source": [
        "final_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(262,\n",
              "              ', IN, USA) according to the manufacturer and were PCR-amplified with DNA Platinum Taq Polymerase (Invi'),\n",
              "             (276, 'placentas from WT individuals (27816638, P ='),\n",
              "             (278,\n",
              "              ', IN, USA) according to the manufacturer and were PCR-amplified with DNA Platinum Taq Polymerase (Invi'),\n",
              "             (316,\n",
              "              ', IN, USA) according to the manufacturer and were PCR-amplified with DNA Platinum Taq Polymerase (Invi'),\n",
              "             (305, ','),\n",
              "             (306,\n",
              "              ', USA). Differences in baseline characteristics and genot'),\n",
              "             (307, 'placentas from WT individuals (27816638, P ='),\n",
              "             (277, 'placentas from WT individuals (27816638, P ='),\n",
              "             (312, ','),\n",
              "             (318, 'placentas from WT individuals (27816638, P ='),\n",
              "             (321,\n",
              "              ', IN, USA) according to the manufacturer and were PCR-amplified with DNA Platinum Taq Polymerase (Invi'),\n",
              "             (568, ', CA) and goat anti-mouse IgG (H+L) (Sigma'),\n",
              "             (569, ', CA) and goat anti-mouse IgG (H+L) (Sigma'),\n",
              "             (570, ', CA) and goat anti-mouse IgG (H+L) (Sigma'),\n",
              "             (571,\n",
              "              \",000 cells/cm 2 in 40 mm dishes and cultured in α-Modified Eagle's Medium (α-MEM; Sigma\"),\n",
              "             (572,\n",
              "              \",000 cells/cm 2 in 40 mm dishes and cultured in α-Modified Eagle's Medium (α-MEM; Sigma\"),\n",
              "             (573, ', CA) and goat anti-mouse IgG (H+L) (Sigma'),\n",
              "             (574, ', CA) and goat anti-mouse IgG (H+L) (Sigma'),\n",
              "             (575, ', CA) and goat anti-mouse IgG (H+L) (Sigma'),\n",
              "             (576, ','),\n",
              "             (577,\n",
              "              \",000 cells/cm 2 in 40 mm dishes and cultured in α-Modified Eagle's Medium (α-MEM; Sigma\"),\n",
              "             (580, ','),\n",
              "             (917, ', and two Human coronavirus OC43 (HCoV'),\n",
              "             (918, ', and two Human coronavirus OC43 (HCoV'),\n",
              "             (919, ', and two Human coronavirus OC43 (HCoV'),\n",
              "             (920, ','),\n",
              "             (921, ','),\n",
              "             (1658, ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV'),\n",
              "             (1659, ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV'),\n",
              "             (1660, ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV'),\n",
              "             (1717, ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV'),\n",
              "             (1718, ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV'),\n",
              "             (1719, ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV'),\n",
              "             (1720,\n",
              "              ', as has been reported elsewhere. 8, 9, 11, 12, 14 HCoV-OC43 and HCoV'),\n",
              "             (2996, ','),\n",
              "             (2997, ','),\n",
              "             (2998, ','),\n",
              "             (2999, ','),\n",
              "             (3000, ','),\n",
              "             (3001, ','),\n",
              "             (3002, ','),\n",
              "             (3003, ','),\n",
              "             (3004, ','),\n",
              "             (3005,\n",
              "              ', and 4E11 as capture antibodies, detection antibodies (2A10, 1 F1,'),\n",
              "             (3006, ','),\n",
              "             (3007,\n",
              "              ', USA) on ELISA plates (30 nl/dot). The plates were blocked with 3% BS'),\n",
              "             (3008, ','),\n",
              "             (3009, ','),\n",
              "             (3010, ','),\n",
              "             (3011, ','),\n",
              "             (3012, ','),\n",
              "             (3013, ','),\n",
              "             (3014, ','),\n",
              "             (3015, ','),\n",
              "             (3016, ','),\n",
              "             (3017, ','),\n",
              "             (3018, ','),\n",
              "             (3019, ','),\n",
              "             (3020, ','),\n",
              "             (3021, ','),\n",
              "             (3022, ','),\n",
              "             (3023, ','),\n",
              "             (3024, ','),\n",
              "             (3025, ','),\n",
              "             (3026, ','),\n",
              "             (3027, ','),\n",
              "             (3028, ','),\n",
              "             (3029, ','),\n",
              "             (3030, ','),\n",
              "             (3031, ','),\n",
              "             (3041, ','),\n",
              "             (3042, ','),\n",
              "             (3043, ','),\n",
              "             (3044, ','),\n",
              "             (1612, ','),\n",
              "             (1615, ','),\n",
              "             (1616, ','),\n",
              "             (1617, ','),\n",
              "             (1618, ','),\n",
              "             (1619, ', such as upper respiratory infection by RSV,'),\n",
              "             (1620,\n",
              "              ', such as asthma, bronchitis, and chronic obstructive pulmonary disease (COPD),'),\n",
              "             (1621,\n",
              "              ', such as asthma, bronchitis, and chronic obstructive pulmonary disease (COPD),'),\n",
              "             (1622,\n",
              "              ', and 87.7% to the most popularly used IBV vaccine strains, H120, H52, and M41,'),\n",
              "             (1623, ','),\n",
              "             (1624, ','),\n",
              "             (257,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (248,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (249,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (250,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (251,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (252,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (253,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (254, ','),\n",
              "             (255,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (1657,\n",
              "              ', 2020\\nPractical Aspects of Otolaryngologic Clinical Services During the COVID'),\n",
              "             (5193, ', USA).'),\n",
              "             (5194, ','),\n",
              "             (5195, ','),\n",
              "             (5196, ', USA).'),\n",
              "             (5197, ', USA).'),\n",
              "             (5198, ','),\n",
              "             (5199, ', USA).'),\n",
              "             (5200, ', USA).'),\n",
              "             (502, ', including rhinovirus, adenov'),\n",
              "             (504,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (507,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (510,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (511,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (512,\n",
              "              ', as well as the WHO recommendations for low-and middleincome countries,'),\n",
              "             (513,\n",
              "              ', which do not recommend routine antibiotic treatment for children younger than 2 years with evidence of pneum'),\n",
              "             (514, ', including rhinovirus, adenov'),\n",
              "             (515, 'neumovirus and adenov'),\n",
              "             (516,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (517,\n",
              "              ', and severe cases are referred for parenteral antibiotics. When implemented in highburden areas before the availability of conjugate vaccines,'),\n",
              "             (518,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (520,\n",
              "              ', as well as the WHO recommendations for low-and middleincome countries,'),\n",
              "             (521,\n",
              "              ', which do not recommend routine antibiotic treatment for children younger than 2 years with evidence of pneum'),\n",
              "             (522,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (524, ', including rhinovirus, adenov'),\n",
              "             (530, ','),\n",
              "             (532,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (533,\n",
              "              ', which do not recommend routine antibiotic treatment for children younger than 2 years with evidence of pneum'),\n",
              "             (534, 'neumovirus and adenov'),\n",
              "             (535, ','),\n",
              "             (536,\n",
              "              ', as well as the WHO recommendations for low-and middleincome countries,'),\n",
              "             (537,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (538,\n",
              "              ', as well as the WHO recommendations for low-and middleincome countries,'),\n",
              "             (539,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (540,\n",
              "              ', as well as the WHO recommendations for low-and middleincome countries,'),\n",
              "             (541, 'neumovirus and adenov'),\n",
              "             (923,\n",
              "              ', reported good evidence of causal attribution for respiratory syncytial virus, influenza, metapneumov'),\n",
              "             (4573,\n",
              "              ', which do not recommend routine antibiotic treatment for children younger than 2 years with evidence of pneum'),\n",
              "             (5217, ','),\n",
              "             (5218, ','),\n",
              "             (5219,\n",
              "              ', or biological control of E. adenophorum has hindered its comprehensive development and utilization for economic benefit.'),\n",
              "             (5220, ','),\n",
              "             (5221,\n",
              "              ', or biological control of E. adenophorum has hindered its comprehensive development and utilization for economic benefit.'),\n",
              "             (5222,\n",
              "              ', or biological control of E. adenophorum has hindered its comprehensive development and utilization for economic benefit.'),\n",
              "             (5223,\n",
              "              ', or biological control of E. adenophorum has hindered its comprehensive development and utilization for economic benefit.'),\n",
              "             (5224,\n",
              "              ', or biological control of E. adenophorum has hindered its comprehensive development and utilization for economic benefit.'),\n",
              "             (5225, ','),\n",
              "             (550, ','),\n",
              "             (553, ','),\n",
              "             (544,\n",
              "              ', Inc.) with an exposure time of 5 s. Fluorescent microspheres were enume'),\n",
              "             (545,\n",
              "              ', Inc.) with an exposure time of 5 s. Fluorescent microspheres were enume'),\n",
              "             (327,\n",
              "              ', such as rhinovirus, coronavirus, human metapneumovirus, parainfluenza virus, adenov'),\n",
              "             (465,\n",
              "              ', or streptavidin and BCRs from humans and mice never exposed to these antigens are generally of low affinity,'),\n",
              "             (467,\n",
              "              ', or streptavidin and BCRs from humans and mice never exposed to these antigens are generally of low affinity,'),\n",
              "             (474,\n",
              "              ', even when tetramers are utilized for dual labeling, streptavidin-specific B cells will contaminate the double'),\n",
              "             (476,\n",
              "              ', even when tetramers are utilized for dual labeling, streptavidin-specific B cells will contaminate the double'),\n",
              "             (478,\n",
              "              ', even when tetramers are utilized for dual labeling, streptavidin-specific B cells will contaminate the double'),\n",
              "             (485,\n",
              "              ', even when tetramers are utilized for dual labeling, streptavidin-specific B cells will contaminate the double'),\n",
              "             (489, ','),\n",
              "             (490,\n",
              "              ', even when tetramers are utilized for dual labeling, streptavidin-specific B cells will contaminate the double'),\n",
              "             (494,\n",
              "              ', even when tetramers are utilized for dual labeling, streptavidin-specific B cells will contaminate the double'),\n",
              "             (497, ','),\n",
              "             (557, ','),\n",
              "             (558,\n",
              "              ', or eyes with their hands until washed properly. Repeatedly touched surfaces, such as door knobs,'),\n",
              "             (559, ','),\n",
              "             (560,\n",
              "              ', or eyes with their hands until washed properly. Repeatedly touched surfaces, such as door knobs,'),\n",
              "             (562,\n",
              "              ', or eyes with their hands until washed properly. Repeatedly touched surfaces, such as door knobs,'),\n",
              "             (563,\n",
              "              ', or eyes with their hands until washed properly. Repeatedly touched surfaces, such as door knobs,'),\n",
              "             (564,\n",
              "              ', a 60-year-old male who is presenting MERS-CoV signs with a negative lab result may need retest'),\n",
              "             (565,\n",
              "              ', or eyes with their hands until washed properly. Repeatedly touched surfaces, such as door knobs,'),\n",
              "             (5232, ','),\n",
              "             (5233, ','),\n",
              "             (5234, ','),\n",
              "             (5235, ','),\n",
              "             (1631,\n",
              "              'the other hand, cotton rat is susceptible to many human pathogens and is the ideal model of choice for measles (paramyxov'),\n",
              "             (1632,\n",
              "              'the other hand, cotton rat is susceptible to many human pathogens and is the ideal model of choice for measles (paramyxov'),\n",
              "             (1633,\n",
              "              'the other hand, cotton rat is susceptible to many human pathogens and is the ideal model of choice for measles (paramyxov'),\n",
              "             (1634,\n",
              "              'the other hand, cotton rat is susceptible to many human pathogens and is the ideal model of choice for measles (paramyxov'),\n",
              "             (567,\n",
              "              ', respectively. It suggests that nucleotide constraint may influence synonymous codon usage patterns. However, A 3 % has non-correlation'),\n",
              "             (566,\n",
              "              \", respectively, which haven't indicated any peculiarity about synonymous codon usage. Furthermore, C 3 % and G 3 % have non-correlation\"),\n",
              "             (328,\n",
              "              ', ORs were adjusted by respective variables. Subjects with incomplete covar'),\n",
              "             (329,\n",
              "              ', ORs were adjusted by respective variables. Subjects with incomplete covar'),\n",
              "             (330, ','),\n",
              "             (331,\n",
              "              ', ORs were adjusted by respective variables. Subjects with incomplete covar'),\n",
              "             (332,\n",
              "              ', ORs were adjusted by respective variables. Subjects with incomplete covar'),\n",
              "             (1592,\n",
              "              ', and evaluate progress toward better health for people in all countries.'),\n",
              "             (1593, ', can hope to meet.'),\n",
              "             (1595,\n",
              "              ', and evaluate progress toward better health for people in all countries.'),\n",
              "             (1596,\n",
              "              ', and evaluate progress toward better health for people in all countries.'),\n",
              "             (1625,\n",
              "              ', conversely, 3.5% displayed a titer below the cut-off value, i.'),\n",
              "             (1626, ', respectively, and good reproduc'),\n",
              "             (1627,\n",
              "              \", respectively. A set of 20 anti-HCV-negative serum samples was used to evaluate the assay's specif-icity,\"),\n",
              "             (1628, ', respectively.\\n\\nFifty-seven HCV'),\n",
              "             (2129, ', especially enteritis and pneumonia, antiox'),\n",
              "             (2131, ','),\n",
              "             (2130, ','),\n",
              "             (2132, ','),\n",
              "             (2133, ','),\n",
              "             (2134, ', especially enteritis and pneumonia, antiox'),\n",
              "             (2135, ','),\n",
              "             (2136, ','),\n",
              "             (2137, ','),\n",
              "             (2138, ','),\n",
              "             (2139, ','),\n",
              "             (2140, ','),\n",
              "             (3032, 'cryoprecipitate, 6 units of fresh frozen plasma,'),\n",
              "             (3033, 'cryoprecipitate, 6 units of fresh frozen plasma,'),\n",
              "             (3034, ', and acyclov'),\n",
              "             (3035, 'cryoprecipitate, 6 units of fresh frozen plasma,'),\n",
              "             (3036, 'cryoprecipitate, 6 units of fresh frozen plasma,'),\n",
              "             (3037, 'cryoprecipitate, 6 units of fresh frozen plasma,'),\n",
              "             (3038, 'cryoprecipitate, 6 units of fresh frozen plasma,'),\n",
              "             (3039, ','),\n",
              "             (3040,\n",
              "              'dermal microvacsular endothelial cells (HMEC-1). Isoxazolidines trans-11a (R ='),\n",
              "             (3267, ','),\n",
              "             (3268, ','),\n",
              "             (3269, ','),\n",
              "             (3270,\n",
              "              ', has a maritime subtropical monsoon climate. Between July 2009 and June 2016, the mean temperature was 21.8 ± 5.8°C (mean'),\n",
              "             (3271,\n",
              "              ', has a maritime subtropical monsoon climate. Between July 2009 and June 2016'),\n",
              "             (3272, ','),\n",
              "             (3273, ','),\n",
              "             (4059, ','),\n",
              "             (4060, ','),\n",
              "             (4061, ','),\n",
              "             (4062, ','),\n",
              "             (4063, ','),\n",
              "             (4064, ','),\n",
              "             (4065, ','),\n",
              "             (4066, ','),\n",
              "             (4067, ', apart from one metapneumov'),\n",
              "             (4068, ', in 2015.'),\n",
              "             (4069, ','),\n",
              "             (4077, ', such as human metapneumov'),\n",
              "             (4078,\n",
              "              ', likely because the kit was not designed for the detection of enterovirus and rhinovirus. 8 Enterov'),\n",
              "             (4079, ', such as human metapneumov'),\n",
              "             (4080,\n",
              "              ', likely because the kit was not designed for the detection of enterovirus and rhinovirus. 8 Enterov'),\n",
              "             (4081, ', such as human metapneumov'),\n",
              "             (4082, ', such as human metapneumov'),\n",
              "             (4083, ', such as human metapneumov'),\n",
              "             (4084, ', such as human metapneumov'),\n",
              "             (4085, ', such as human metapneumov'),\n",
              "             (5201, ', 2003.'),\n",
              "             (5202, ','),\n",
              "             (5203,\n",
              "              ', 2003 . Of these, 3 ewes including the one that had lambed tested'),\n",
              "             (5204, ', 2003.'),\n",
              "             (5205, ', 2003.'),\n",
              "             (5206, ','),\n",
              "             (5207, ', 2003.'),\n",
              "             (5208, ', respectively.'),\n",
              "             (5209, ', 2003.'),\n",
              "             (5210, ', 2003.'),\n",
              "             (3687,\n",
              "              ', have extended the association from just direct protein interactions to more distant connections in various ways.'),\n",
              "             (3688,\n",
              "              ', have extended the association from just direct protein interactions to more distant connections in various ways.'),\n",
              "             (3689,\n",
              "              ', which is a path-based measure to calculate the relevance between objects in heterogeneous network 25 .'),\n",
              "             (3690,\n",
              "              ', have extended the association from just direct protein interactions to more distant connections in various ways.'),\n",
              "             (593, ', thus,'),\n",
              "             (595, 'hoeic lambs at the time of infection (day 0, n ='),\n",
              "             (581,\n",
              "              ', though not identical, locations ( Figure 3 ). Patients 1 and 6, who underwent ICGA,'),\n",
              "             (582,\n",
              "              ', though not identical, locations ( Figure 3 ). Patients 1 and 6, who underwent ICGA,'),\n",
              "             (583,\n",
              "              ', though not identical, locations ( Figure 3 ). Patients 1 and 6, who underwent ICGA,'),\n",
              "             (584,\n",
              "              ', though not identical, locations ( Figure 3 ). Patients 1 and 6, who underwent ICGA,'),\n",
              "             (1597, ','),\n",
              "             (1598,\n",
              "              ', yet research regarding the molecular epidemiology of ARI viruses in Nigeria is limited.'),\n",
              "             (1599, ','),\n",
              "             (1600,\n",
              "              ', who are employed by the State Ministry of Health and familiar with the communities in this study,'),\n",
              "             (1601, ','),\n",
              "             (1602,\n",
              "              ', who are employed by the State Ministry of Health and familiar with the communities in this study,'),\n",
              "             (1603,\n",
              "              ', yet research regarding the molecular epidemiology of ARI viruses in Nigeria is limited.'),\n",
              "             (1604,\n",
              "              ', yet research regarding the molecular epidemiology of ARI viruses in Nigeria is limited.'),\n",
              "             (1605,\n",
              "              ', yet research regarding the molecular epidemiology of ARI viruses in Nigeria is limited.'),\n",
              "             (1606,\n",
              "              ', yet research regarding the molecular epidemiology of ARI viruses in Nigeria is limited.'),\n",
              "             (1607,\n",
              "              ', who are employed by the State Ministry of Health and familiar with the communities in this study,'),\n",
              "             (1608,\n",
              "              ', respectively. On the other hand, the viruses most rarely seen in co-infections were influenza viruses A and B as well as RSV.'),\n",
              "             (1609,\n",
              "              ', respectively. On the other hand, the viruses most rarely seen in co-infections were influenza viruses A and B as well as RSV.'),\n",
              "             (1610, ', and human adenov'),\n",
              "             (1611,\n",
              "              ', respectively. On the other hand, the viruses most rarely seen in co-infections were influenza viruses A and B as well as RSV.'),\n",
              "             (1613,\n",
              "              ', whereas the opposite is observed for influenza and adenov'),\n",
              "             (1614,\n",
              "              ', which was unavailable. In summary, the established assays were able to correctly identify all viruses tested, proving their suitability'),\n",
              "             (1629,\n",
              "              ', respectively. On the other hand, the viruses most rarely seen in co-infections were influenza viruses A and B as well as RSV.'),\n",
              "             (1630,\n",
              "              ', respectively. On the other hand, the viruses most rarely seen in co-infections were influenza viruses A and B as well as RSV.'),\n",
              "             (2125,\n",
              "              ', USA) was used for sequencing analysis of two of the five ECoV samples identified.'),\n",
              "             (2126,\n",
              "              ', USA) was used for sequencing analysis of two of the five ECoV samples identified.'),\n",
              "             (2127,\n",
              "              ', USA) was used for sequencing analysis of two of the five ECoV samples identified.'),\n",
              "             (2128,\n",
              "              ', USA) was used for sequencing analysis of two of the five ECoV samples identified.'),\n",
              "             (2167, ','),\n",
              "             (2168, ','),\n",
              "             (2169, ','),\n",
              "             (2170, ','),\n",
              "             (2171, ','),\n",
              "             (2173, ','),\n",
              "             (2174, ','),\n",
              "             (2175,\n",
              "              ', as a function of viral identifications for influenza, RSV, adenov'),\n",
              "             (2176,\n",
              "              ', as a function of viral identifications for influenza, RSV, adenov'),\n",
              "             (2177,\n",
              "              ', and reports weekly data from participating laboratories on the number of tests performed and the number of specimens confirmed'),\n",
              "             (2466,\n",
              "              ', 2014) . Access to potential cleavage substrate for RNaseL is conjectured to be facilitated through its association with polyribosomes,'),\n",
              "             (2467,\n",
              "              ', 2014) . Access to potential cleavage substrate for RNaseL is conjectured to be facilitated through its association with polyribosomes,'),\n",
              "             (2468,\n",
              "              ', 2014) . Access to potential cleavage substrate for RNaseL is conjectured to be facilitated through its association with polyribosomes,'),\n",
              "             (2469,\n",
              "              ', 2008) . Gene transcripts regulated by RIDD pathway includes that from IRE1 (i.'),\n",
              "             (2988, ', similar to other enterov'),\n",
              "             (2989, ', similar to other enterov'),\n",
              "             (2990, ', similar to other enterov'),\n",
              "             (2991, ', similar to other enterov'),\n",
              "             (2992, ', similar to other enterov'),\n",
              "             (2993, ', similar to other enterov'),\n",
              "             (2994, ', similar to other enterov'),\n",
              "             (2995, ', similar to other enterov')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9wG7Z0Am5I3"
      },
      "source": [
        "# import pickle\n",
        "import json\n",
        "\n",
        "# with open('output-distil-covid.pickle', 'wb') as handle:\n",
        "#     pickle.dump(final_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('{}-covid.json'.format(model_checkpoint), 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_predictions, f, indent=4, ensure_ascii=False)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st7yL4cAneyn"
      },
      "source": [
        "# import pickle\n",
        "# file = open(\"output-distil-covid.pickle\",'rb')\n",
        "# object_file = pickle.load(file)\n",
        "# file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Kd5usCPiBp"
      },
      "source": [
        "# import pickle\n",
        "\n",
        "\n",
        "# with open('output-distil-covid.pickle', 'wb') as handle:\n",
        "#     pickle.dump(final_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('{}-covid-1.json'.format(\"distil\"), 'w', encoding='utf-8') as f:\n",
        "#     json.dump(object_file, f, indent=4, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln2JjDYzFv4S"
      },
      "source": [
        "from __future__ import print_function\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klQXV54yNVhX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHiyOSR7NZ84"
      },
      "source": [
        "my_predictions = list(final_predictions.items())\n",
        "for i in range(0,len(my_predictions)):\n",
        "  my_predictions[i] = normalize_answer(my_predictions[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGuX984OK_X"
      },
      "source": [
        "orig = list(datasets[\"validation\"])\n",
        "for i in range(0,len(orig)):\n",
        "  orig[i] = normalize_answer(orig[i][\"answers\"][\"text\"][0])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMXarARSRbWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91a2b259-cc66-4282-c2e6-a53bbd5b56b7"
      },
      "source": [
        "my_predictions[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'placentas from wt individuals 27816638 p'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_9p7DHTyJ1Vi",
        "outputId": "c08a22eb-3c4e-44c0-d051-e0b076ca200a"
      },
      "source": [
        "orig[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dcsignr plays crucial role in mtct of hiv1 and that impaired placental dcsignr expression increases risk of transmission'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPmQAa-5J3tr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}